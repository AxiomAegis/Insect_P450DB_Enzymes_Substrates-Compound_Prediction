Namespace(batch_size=72, binary_task=True, embed_path='data/training_data/embeddings', learning_rate=1e-05, model_prefix='p450_ESP', num_hidden_layers=6, num_train_epochs=100, port=12558, pretrained_model='pretrained_model/pretraining_IC50_6gpus_bs144_1.5e-05_layers6.txt.pkl', save_model_path='saved_model', start_epoch=0, train_dir='data/training_data/train_val_p450/train.csv', val_dir='data/training_data/train_val_p450/val.csv', warmup_proportion=0.1, world_size=1)
Added key: store_based_barrier_key:1 to store for rank: 0
Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
Loading model
Loading model
Updatete key: module.s_pooler.dense.weight
Updatete key: module.s_pooler.dense.bias
Updatete key: module.p_pooler.dense.weight
Updatete key: module.p_pooler.dense.bias
Updatete key: module.main_bert.transformer_layers.0.self_attn.in_proj_weight
Updatete key: module.main_bert.transformer_layers.0.self_attn.in_proj_bias
Updatete key: module.main_bert.transformer_layers.0.self_attn.out_proj.weight
Updatete key: module.main_bert.transformer_layers.0.self_attn.out_proj.bias
Updatete key: module.main_bert.transformer_layers.0.linear1.weight
Updatete key: module.main_bert.transformer_layers.0.linear1.bias
Updatete key: module.main_bert.transformer_layers.0.linear2.weight
Updatete key: module.main_bert.transformer_layers.0.linear2.bias
Updatete key: module.main_bert.transformer_layers.0.norm1.weight
Updatete key: module.main_bert.transformer_layers.0.norm1.bias
Updatete key: module.main_bert.transformer_layers.0.norm2.weight
Updatete key: module.main_bert.transformer_layers.0.norm2.bias
Updatete key: module.main_bert.transformer_layers.1.self_attn.in_proj_weight
Updatete key: module.main_bert.transformer_layers.1.self_attn.in_proj_bias
Updatete key: module.main_bert.transformer_layers.1.self_attn.out_proj.weight
Updatete key: module.main_bert.transformer_layers.1.self_attn.out_proj.bias
Updatete key: module.main_bert.transformer_layers.1.linear1.weight
Updatete key: module.main_bert.transformer_layers.1.linear1.bias
Updatete key: module.main_bert.transformer_layers.1.linear2.weight
Updatete key: module.main_bert.transformer_layers.1.linear2.bias
Updatete key: module.main_bert.transformer_layers.1.norm1.weight
Updatete key: module.main_bert.transformer_layers.1.norm1.bias
Updatete key: module.main_bert.transformer_layers.1.norm2.weight
Updatete key: module.main_bert.transformer_layers.1.norm2.bias
Updatete key: module.main_bert.transformer_layers.2.self_attn.in_proj_weight
Updatete key: module.main_bert.transformer_layers.2.self_attn.in_proj_bias
Updatete key: module.main_bert.transformer_layers.2.self_attn.out_proj.weight
Updatete key: module.main_bert.transformer_layers.2.self_attn.out_proj.bias
Updatete key: module.main_bert.transformer_layers.2.linear1.weight
Updatete key: module.main_bert.transformer_layers.2.linear1.bias
Updatete key: module.main_bert.transformer_layers.2.linear2.weight
Updatete key: module.main_bert.transformer_layers.2.linear2.bias
Updatete key: module.main_bert.transformer_layers.2.norm1.weight
Updatete key: module.main_bert.transformer_layers.2.norm1.bias
Updatete key: module.main_bert.transformer_layers.2.norm2.weight
Updatete key: module.main_bert.transformer_layers.2.norm2.bias
Updatete key: module.main_bert.transformer_layers.3.self_attn.in_proj_weight
Updatete key: module.main_bert.transformer_layers.3.self_attn.in_proj_bias
Updatete key: module.main_bert.transformer_layers.3.self_attn.out_proj.weight
Updatete key: module.main_bert.transformer_layers.3.self_attn.out_proj.bias
Updatete key: module.main_bert.transformer_layers.3.linear1.weight
Updatete key: module.main_bert.transformer_layers.3.linear1.bias
Updatete key: module.main_bert.transformer_layers.3.linear2.weight
Updatete key: module.main_bert.transformer_layers.3.linear2.bias
Updatete key: module.main_bert.transformer_layers.3.norm1.weight
Updatete key: module.main_bert.transformer_layers.3.norm1.bias
Updatete key: module.main_bert.transformer_layers.3.norm2.weight
Updatete key: module.main_bert.transformer_layers.3.norm2.bias
Updatete key: module.main_bert.transformer_layers.4.self_attn.in_proj_weight
Updatete key: module.main_bert.transformer_layers.4.self_attn.in_proj_bias
Updatete key: module.main_bert.transformer_layers.4.self_attn.out_proj.weight
Updatete key: module.main_bert.transformer_layers.4.self_attn.out_proj.bias
Updatete key: module.main_bert.transformer_layers.4.linear1.weight
Updatete key: module.main_bert.transformer_layers.4.linear1.bias
Updatete key: module.main_bert.transformer_layers.4.linear2.weight
Updatete key: module.main_bert.transformer_layers.4.linear2.bias
Updatete key: module.main_bert.transformer_layers.4.norm1.weight
Updatete key: module.main_bert.transformer_layers.4.norm1.bias
Updatete key: module.main_bert.transformer_layers.4.norm2.weight
Updatete key: module.main_bert.transformer_layers.4.norm2.bias
Updatete key: module.main_bert.transformer_layers.5.self_attn.in_proj_weight
Updatete key: module.main_bert.transformer_layers.5.self_attn.in_proj_bias
Updatete key: module.main_bert.transformer_layers.5.self_attn.out_proj.weight
Updatete key: module.main_bert.transformer_layers.5.self_attn.out_proj.bias
Updatete key: module.main_bert.transformer_layers.5.linear1.weight
Updatete key: module.main_bert.transformer_layers.5.linear1.bias
Updatete key: module.main_bert.transformer_layers.5.linear2.weight
Updatete key: module.main_bert.transformer_layers.5.linear2.bias
Updatete key: module.main_bert.transformer_layers.5.norm1.weight
Updatete key: module.main_bert.transformer_layers.5.norm1.bias
Updatete key: module.main_bert.transformer_layers.5.norm2.weight
Updatete key: module.main_bert.transformer_layers.5.norm2.bias
Updatete key: module.main_bert.hidden_layer.weight
Updatete key: module.main_bert.hidden_layer.bias
Updatete key: module.main_bert.output_layer.weight
Updatete key: module.main_bert.output_layer.bias
Successfully loaded pretrained model
Start training
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 1
Training for epoch 1
Epoch [1/100], Step [1/735], Loss: 0.6977
Reducer buckets have been rebuilt in this iteration.
Epoch [1/100], Step [11/735], Loss: 0.2134
Epoch [1/100], Step [21/735], Loss: 0.2119
Epoch [1/100], Step [31/735], Loss: 0.1629
Epoch [1/100], Step [41/735], Loss: 0.2139
Epoch [1/100], Step [51/735], Loss: 0.1912
Epoch [1/100], Step [61/735], Loss: 0.1941
Epoch [1/100], Step [71/735], Loss: 0.1830
Epoch [1/100], Step [81/735], Loss: 0.2079
Epoch [1/100], Step [91/735], Loss: 0.2210
Epoch [1/100], Step [101/735], Loss: 0.2139
Epoch [1/100], Step [111/735], Loss: 0.2359
Epoch [1/100], Step [121/735], Loss: 0.2085
Epoch [1/100], Step [131/735], Loss: 0.1523
Epoch [1/100], Step [141/735], Loss: 0.2084
Epoch [1/100], Step [151/735], Loss: 0.2025
Epoch [1/100], Step [161/735], Loss: 0.2014
Epoch [1/100], Step [171/735], Loss: 0.2077
Epoch [1/100], Step [181/735], Loss: 0.1734
Epoch [1/100], Step [191/735], Loss: 0.1944
Epoch [1/100], Step [201/735], Loss: 0.1767
Epoch [1/100], Step [211/735], Loss: 0.1774
Epoch [1/100], Step [221/735], Loss: 0.2062
Epoch [1/100], Step [231/735], Loss: 0.1640
Epoch [1/100], Step [241/735], Loss: 0.1561
Epoch [1/100], Step [251/735], Loss: 0.2083
Epoch [1/100], Step [261/735], Loss: 0.1511
Epoch [1/100], Step [271/735], Loss: 0.1894
Epoch [1/100], Step [281/735], Loss: 0.1734
Epoch [1/100], Step [291/735], Loss: 0.1965
Epoch [1/100], Step [301/735], Loss: 0.2066
Epoch [1/100], Step [311/735], Loss: 0.1979
Epoch [1/100], Step [321/735], Loss: 0.1580
Epoch [1/100], Step [331/735], Loss: 0.1615
Epoch [1/100], Step [341/735], Loss: 0.2304
Epoch [1/100], Step [351/735], Loss: 0.1756
Epoch [1/100], Step [361/735], Loss: 0.1340
Epoch [1/100], Step [371/735], Loss: 0.2064
Epoch [1/100], Step [381/735], Loss: 0.1631
Epoch [1/100], Step [391/735], Loss: 0.2117
Epoch [1/100], Step [401/735], Loss: 0.1592
Epoch [1/100], Step [411/735], Loss: 0.1635
Epoch [1/100], Step [421/735], Loss: 0.2143
Epoch [1/100], Step [431/735], Loss: 0.1709
Epoch [1/100], Step [441/735], Loss: 0.1683
Epoch [1/100], Step [451/735], Loss: 0.1542
Epoch [1/100], Step [461/735], Loss: 0.1750
Epoch [1/100], Step [471/735], Loss: 0.1360
Epoch [1/100], Step [481/735], Loss: 0.1631
Epoch [1/100], Step [491/735], Loss: 0.1566
Epoch [1/100], Step [501/735], Loss: 0.1792
Epoch [1/100], Step [511/735], Loss: 0.1806
Epoch [1/100], Step [521/735], Loss: 0.1791
Epoch [1/100], Step [531/735], Loss: 0.2085
Epoch [1/100], Step [541/735], Loss: 0.1772
Epoch [1/100], Step [551/735], Loss: 0.1453
Epoch [1/100], Step [561/735], Loss: 0.1724
Epoch [1/100], Step [571/735], Loss: 0.1661
Epoch [1/100], Step [581/735], Loss: 0.1730
Epoch [1/100], Step [591/735], Loss: 0.1646
Epoch [1/100], Step [601/735], Loss: 0.1326
Epoch [1/100], Step [611/735], Loss: 0.1039
Epoch [1/100], Step [621/735], Loss: 0.1118
Epoch [1/100], Step [631/735], Loss: 0.2184
Epoch [1/100], Step [641/735], Loss: 0.1459
Epoch [1/100], Step [651/735], Loss: 0.1614
Epoch [1/100], Step [661/735], Loss: 0.1972
Epoch [1/100], Step [671/735], Loss: 0.1921
Epoch [1/100], Step [681/735], Loss: 0.1344
Epoch [1/100], Step [691/735], Loss: 0.1536
Epoch [1/100], Step [701/735], Loss: 0.1946
Epoch [1/100], Step [711/735], Loss: 0.1175
Epoch [1/100], Step [721/735], Loss: 0.2144
Epoch [1/100], Step [731/735], Loss: 0.1283
Training complete
Val performance:
Evaluating
Val Accuracy: 0.7844,Val AUC: 0.7601,Val precision: 0.9187, Val recall: 0.2571, Val Loss: 0.1543
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 1 | Time taken: 2259.36s |
| Val CE loss: 0.15431 | Val MSE 0.78438 | Train Loss 0.18147 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 2
Training for epoch 2
Epoch [2/100], Step [1/735], Loss: 0.1622
Epoch [2/100], Step [11/735], Loss: 0.2136
Epoch [2/100], Step [21/735], Loss: 0.1970
Epoch [2/100], Step [31/735], Loss: 0.1270
Epoch [2/100], Step [41/735], Loss: 0.1554
Epoch [2/100], Step [51/735], Loss: 0.1616
Epoch [2/100], Step [61/735], Loss: 0.1469
Epoch [2/100], Step [71/735], Loss: 0.1399
Epoch [2/100], Step [81/735], Loss: 0.1216
Epoch [2/100], Step [91/735], Loss: 0.2009
Epoch [2/100], Step [101/735], Loss: 0.2066
Epoch [2/100], Step [111/735], Loss: 0.1865
Epoch [2/100], Step [121/735], Loss: 0.1843
Epoch [2/100], Step [131/735], Loss: 0.1426
Epoch [2/100], Step [141/735], Loss: 0.1851
Epoch [2/100], Step [151/735], Loss: 0.1823
Epoch [2/100], Step [161/735], Loss: 0.1688
Epoch [2/100], Step [171/735], Loss: 0.1712
Epoch [2/100], Step [181/735], Loss: 0.1657
Epoch [2/100], Step [191/735], Loss: 0.1606
Epoch [2/100], Step [201/735], Loss: 0.2657
Epoch [2/100], Step [211/735], Loss: 0.1426
Epoch [2/100], Step [221/735], Loss: 0.1448
Epoch [2/100], Step [231/735], Loss: 0.2022
Epoch [2/100], Step [241/735], Loss: 0.1317
Epoch [2/100], Step [251/735], Loss: 0.0997
Epoch [2/100], Step [261/735], Loss: 0.1831
Epoch [2/100], Step [271/735], Loss: 0.1376
Epoch [2/100], Step [281/735], Loss: 0.1785
Epoch [2/100], Step [291/735], Loss: 0.1470
Epoch [2/100], Step [301/735], Loss: 0.1471
Epoch [2/100], Step [311/735], Loss: 0.1522
Epoch [2/100], Step [321/735], Loss: 0.1671
Epoch [2/100], Step [331/735], Loss: 0.1589
Epoch [2/100], Step [341/735], Loss: 0.1323
Epoch [2/100], Step [351/735], Loss: 0.1836
Epoch [2/100], Step [361/735], Loss: 0.1144
Epoch [2/100], Step [371/735], Loss: 0.2321
Epoch [2/100], Step [381/735], Loss: 0.1600
Epoch [2/100], Step [391/735], Loss: 0.1327
Epoch [2/100], Step [401/735], Loss: 0.1370
Epoch [2/100], Step [411/735], Loss: 0.1204
Epoch [2/100], Step [421/735], Loss: 0.1339
Epoch [2/100], Step [431/735], Loss: 0.1362
Epoch [2/100], Step [441/735], Loss: 0.1304
Epoch [2/100], Step [451/735], Loss: 0.1304
Epoch [2/100], Step [461/735], Loss: 0.0905
Epoch [2/100], Step [471/735], Loss: 0.1365
Epoch [2/100], Step [481/735], Loss: 0.1348
Epoch [2/100], Step [491/735], Loss: 0.1271
Epoch [2/100], Step [501/735], Loss: 0.1476
Epoch [2/100], Step [511/735], Loss: 0.1601
Epoch [2/100], Step [521/735], Loss: 0.1502
Epoch [2/100], Step [531/735], Loss: 0.1351
Epoch [2/100], Step [541/735], Loss: 0.1093
Epoch [2/100], Step [551/735], Loss: 0.1463
Epoch [2/100], Step [561/735], Loss: 0.1232
Epoch [2/100], Step [571/735], Loss: 0.1345
Epoch [2/100], Step [581/735], Loss: 0.1498
Epoch [2/100], Step [591/735], Loss: 0.1820
Epoch [2/100], Step [601/735], Loss: 0.1546
Epoch [2/100], Step [611/735], Loss: 0.1513
Epoch [2/100], Step [621/735], Loss: 0.2302
Epoch [2/100], Step [631/735], Loss: 0.1404
Epoch [2/100], Step [641/735], Loss: 0.1541
Epoch [2/100], Step [651/735], Loss: 0.1599
Epoch [2/100], Step [661/735], Loss: 0.0870
Epoch [2/100], Step [671/735], Loss: 0.1463
Epoch [2/100], Step [681/735], Loss: 0.1747
Epoch [2/100], Step [691/735], Loss: 0.1154
Epoch [2/100], Step [701/735], Loss: 0.1398
Epoch [2/100], Step [711/735], Loss: 0.1459
Epoch [2/100], Step [721/735], Loss: 0.1470
Epoch [2/100], Step [731/735], Loss: 0.1204
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8072,Val AUC: 0.8180,Val precision: 0.7853, Val recall: 0.4342, Val Loss: 0.1389
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 2 | Time taken: 2233.29s |
| Val CE loss: 0.13889 | Val MSE 0.80724 | Train Loss 0.15006 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 3
Training for epoch 3
Epoch [3/100], Step [1/735], Loss: 0.0976
Epoch [3/100], Step [11/735], Loss: 0.1424
Epoch [3/100], Step [21/735], Loss: 0.1681
Epoch [3/100], Step [31/735], Loss: 0.1644
Epoch [3/100], Step [41/735], Loss: 0.1328
Epoch [3/100], Step [51/735], Loss: 0.1457
Epoch [3/100], Step [61/735], Loss: 0.1432
Epoch [3/100], Step [71/735], Loss: 0.1542
Epoch [3/100], Step [81/735], Loss: 0.1139
Epoch [3/100], Step [91/735], Loss: 0.1359
Epoch [3/100], Step [101/735], Loss: 0.1853
Epoch [3/100], Step [111/735], Loss: 0.1477
Epoch [3/100], Step [121/735], Loss: 0.0975
Epoch [3/100], Step [131/735], Loss: 0.1482
Epoch [3/100], Step [141/735], Loss: 0.1570
Epoch [3/100], Step [151/735], Loss: 0.1305
Epoch [3/100], Step [161/735], Loss: 0.1216
Epoch [3/100], Step [171/735], Loss: 0.1420
Epoch [3/100], Step [181/735], Loss: 0.1972
Epoch [3/100], Step [191/735], Loss: 0.0926
Epoch [3/100], Step [201/735], Loss: 0.1257
Epoch [3/100], Step [211/735], Loss: 0.1501
Epoch [3/100], Step [221/735], Loss: 0.1451
Epoch [3/100], Step [231/735], Loss: 0.1159
Epoch [3/100], Step [241/735], Loss: 0.1406
Epoch [3/100], Step [251/735], Loss: 0.1190
Epoch [3/100], Step [261/735], Loss: 0.1112
Epoch [3/100], Step [271/735], Loss: 0.1164
Epoch [3/100], Step [281/735], Loss: 0.1376
Epoch [3/100], Step [291/735], Loss: 0.1247
Epoch [3/100], Step [301/735], Loss: 0.1360
Epoch [3/100], Step [311/735], Loss: 0.1074
Epoch [3/100], Step [321/735], Loss: 0.1351
Epoch [3/100], Step [331/735], Loss: 0.1215
Epoch [3/100], Step [341/735], Loss: 0.1309
Epoch [3/100], Step [351/735], Loss: 0.0715
Epoch [3/100], Step [361/735], Loss: 0.0927
Epoch [3/100], Step [371/735], Loss: 0.1247
Epoch [3/100], Step [381/735], Loss: 0.1098
Epoch [3/100], Step [391/735], Loss: 0.1412
Epoch [3/100], Step [401/735], Loss: 0.1248
Epoch [3/100], Step [411/735], Loss: 0.1778
Epoch [3/100], Step [421/735], Loss: 0.1611
Epoch [3/100], Step [431/735], Loss: 0.1289
Epoch [3/100], Step [441/735], Loss: 0.1307
Epoch [3/100], Step [451/735], Loss: 0.1015
Epoch [3/100], Step [461/735], Loss: 0.1530
Epoch [3/100], Step [471/735], Loss: 0.1335
Epoch [3/100], Step [481/735], Loss: 0.1092
Epoch [3/100], Step [491/735], Loss: 0.1366
Epoch [3/100], Step [501/735], Loss: 0.1367
Epoch [3/100], Step [511/735], Loss: 0.1323
Epoch [3/100], Step [521/735], Loss: 0.0943
Epoch [3/100], Step [531/735], Loss: 0.1419
Epoch [3/100], Step [541/735], Loss: 0.1135
Epoch [3/100], Step [551/735], Loss: 0.1030
Epoch [3/100], Step [561/735], Loss: 0.0781
Epoch [3/100], Step [571/735], Loss: 0.1401
Epoch [3/100], Step [581/735], Loss: 0.1006
Epoch [3/100], Step [591/735], Loss: 0.0663
Epoch [3/100], Step [601/735], Loss: 0.1098
Epoch [3/100], Step [611/735], Loss: 0.1159
Epoch [3/100], Step [621/735], Loss: 0.0972
Epoch [3/100], Step [631/735], Loss: 0.1156
Epoch [3/100], Step [641/735], Loss: 0.1296
Epoch [3/100], Step [651/735], Loss: 0.1200
Epoch [3/100], Step [661/735], Loss: 0.1496
Epoch [3/100], Step [671/735], Loss: 0.1296
Epoch [3/100], Step [681/735], Loss: 0.1576
Epoch [3/100], Step [691/735], Loss: 0.1244
Epoch [3/100], Step [701/735], Loss: 0.1195
Epoch [3/100], Step [711/735], Loss: 0.1380
Epoch [3/100], Step [721/735], Loss: 0.1225
Epoch [3/100], Step [731/735], Loss: 0.0855
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8322,Val AUC: 0.8596,Val precision: 0.8476, Val recall: 0.4926, Val Loss: 0.1210
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 3 | Time taken: 2246.93s |
| Val CE loss: 0.12104 | Val MSE 0.83218 | Train Loss 0.12854 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 4
Training for epoch 4
Epoch [4/100], Step [1/735], Loss: 0.1195
Epoch [4/100], Step [11/735], Loss: 0.1138
Epoch [4/100], Step [21/735], Loss: 0.0963
Epoch [4/100], Step [31/735], Loss: 0.1196
Epoch [4/100], Step [41/735], Loss: 0.1170
Epoch [4/100], Step [51/735], Loss: 0.1354
Epoch [4/100], Step [61/735], Loss: 0.1415
Epoch [4/100], Step [71/735], Loss: 0.1744
Epoch [4/100], Step [81/735], Loss: 0.1342
Epoch [4/100], Step [91/735], Loss: 0.1308
Epoch [4/100], Step [101/735], Loss: 0.1000
Epoch [4/100], Step [111/735], Loss: 0.1340
Epoch [4/100], Step [121/735], Loss: 0.1268
Epoch [4/100], Step [131/735], Loss: 0.1260
Epoch [4/100], Step [141/735], Loss: 0.1177
Epoch [4/100], Step [151/735], Loss: 0.1565
Epoch [4/100], Step [161/735], Loss: 0.1489
Epoch [4/100], Step [171/735], Loss: 0.1066
Epoch [4/100], Step [181/735], Loss: 0.1308
Epoch [4/100], Step [191/735], Loss: 0.1054
Epoch [4/100], Step [201/735], Loss: 0.0824
Epoch [4/100], Step [211/735], Loss: 0.1123
Epoch [4/100], Step [221/735], Loss: 0.1283
Epoch [4/100], Step [231/735], Loss: 0.1281
Epoch [4/100], Step [241/735], Loss: 0.1166
Epoch [4/100], Step [251/735], Loss: 0.0940
Epoch [4/100], Step [261/735], Loss: 0.1249
Epoch [4/100], Step [271/735], Loss: 0.0677
Epoch [4/100], Step [281/735], Loss: 0.0924
Epoch [4/100], Step [291/735], Loss: 0.1083
Epoch [4/100], Step [301/735], Loss: 0.1343
Epoch [4/100], Step [311/735], Loss: 0.1041
Epoch [4/100], Step [321/735], Loss: 0.0738
Epoch [4/100], Step [331/735], Loss: 0.1408
Epoch [4/100], Step [341/735], Loss: 0.1253
Epoch [4/100], Step [351/735], Loss: 0.1241
Epoch [4/100], Step [361/735], Loss: 0.1051
Epoch [4/100], Step [371/735], Loss: 0.1235
Epoch [4/100], Step [381/735], Loss: 0.1103
Epoch [4/100], Step [391/735], Loss: 0.1441
Epoch [4/100], Step [401/735], Loss: 0.0963
Epoch [4/100], Step [411/735], Loss: 0.0812
Epoch [4/100], Step [421/735], Loss: 0.0993
Epoch [4/100], Step [431/735], Loss: 0.1028
Epoch [4/100], Step [441/735], Loss: 0.1521
Epoch [4/100], Step [451/735], Loss: 0.1060
Epoch [4/100], Step [461/735], Loss: 0.1262
Epoch [4/100], Step [471/735], Loss: 0.1469
Epoch [4/100], Step [481/735], Loss: 0.0970
Epoch [4/100], Step [491/735], Loss: 0.1348
Epoch [4/100], Step [501/735], Loss: 0.0740
Epoch [4/100], Step [511/735], Loss: 0.0784
Epoch [4/100], Step [521/735], Loss: 0.0996
Epoch [4/100], Step [531/735], Loss: 0.1151
Epoch [4/100], Step [541/735], Loss: 0.1123
Epoch [4/100], Step [551/735], Loss: 0.1350
Epoch [4/100], Step [561/735], Loss: 0.1239
Epoch [4/100], Step [571/735], Loss: 0.1104
Epoch [4/100], Step [581/735], Loss: 0.1408
Epoch [4/100], Step [591/735], Loss: 0.0587
Epoch [4/100], Step [601/735], Loss: 0.0779
Epoch [4/100], Step [611/735], Loss: 0.1046
Epoch [4/100], Step [621/735], Loss: 0.0746
Epoch [4/100], Step [631/735], Loss: 0.1017
Epoch [4/100], Step [641/735], Loss: 0.1074
Epoch [4/100], Step [651/735], Loss: 0.0828
Epoch [4/100], Step [661/735], Loss: 0.0972
Epoch [4/100], Step [671/735], Loss: 0.1233
Epoch [4/100], Step [681/735], Loss: 0.1101
Epoch [4/100], Step [691/735], Loss: 0.1320
Epoch [4/100], Step [701/735], Loss: 0.0868
Epoch [4/100], Step [711/735], Loss: 0.1428
Epoch [4/100], Step [721/735], Loss: 0.0751
Epoch [4/100], Step [731/735], Loss: 0.1156
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8388,Val AUC: 0.8788,Val precision: 0.7903, Val recall: 0.5818, Val Loss: 0.1153
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 4 | Time taken: 2228.12s |
| Val CE loss: 0.11532 | Val MSE 0.83876 | Train Loss 0.11253 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 5
Training for epoch 5
Epoch [5/100], Step [1/735], Loss: 0.2010
Epoch [5/100], Step [11/735], Loss: 0.1056
Epoch [5/100], Step [21/735], Loss: 0.0834
Epoch [5/100], Step [31/735], Loss: 0.0681
Epoch [5/100], Step [41/735], Loss: 0.0855
Epoch [5/100], Step [51/735], Loss: 0.1173
Epoch [5/100], Step [61/735], Loss: 0.1148
Epoch [5/100], Step [71/735], Loss: 0.0943
Epoch [5/100], Step [81/735], Loss: 0.1206
Epoch [5/100], Step [91/735], Loss: 0.0886
Epoch [5/100], Step [101/735], Loss: 0.1412
Epoch [5/100], Step [111/735], Loss: 0.1043
Epoch [5/100], Step [121/735], Loss: 0.1123
Epoch [5/100], Step [131/735], Loss: 0.0636
Epoch [5/100], Step [141/735], Loss: 0.0589
Epoch [5/100], Step [151/735], Loss: 0.1453
Epoch [5/100], Step [161/735], Loss: 0.1306
Epoch [5/100], Step [171/735], Loss: 0.1300
Epoch [5/100], Step [181/735], Loss: 0.1073
Epoch [5/100], Step [191/735], Loss: 0.0950
Epoch [5/100], Step [201/735], Loss: 0.1127
Epoch [5/100], Step [211/735], Loss: 0.1324
Epoch [5/100], Step [221/735], Loss: 0.0822
Epoch [5/100], Step [231/735], Loss: 0.1179
Epoch [5/100], Step [241/735], Loss: 0.1405
Epoch [5/100], Step [251/735], Loss: 0.0823
Epoch [5/100], Step [261/735], Loss: 0.0987
Epoch [5/100], Step [271/735], Loss: 0.1492
Epoch [5/100], Step [281/735], Loss: 0.0979
Epoch [5/100], Step [291/735], Loss: 0.0464
Epoch [5/100], Step [301/735], Loss: 0.1001
Epoch [5/100], Step [311/735], Loss: 0.1103
Epoch [5/100], Step [321/735], Loss: 0.1240
Epoch [5/100], Step [331/735], Loss: 0.0783
Epoch [5/100], Step [341/735], Loss: 0.0899
Epoch [5/100], Step [351/735], Loss: 0.0954
Epoch [5/100], Step [361/735], Loss: 0.0962
Epoch [5/100], Step [371/735], Loss: 0.1144
Epoch [5/100], Step [381/735], Loss: 0.1149
Epoch [5/100], Step [391/735], Loss: 0.1311
Epoch [5/100], Step [401/735], Loss: 0.0825
Epoch [5/100], Step [411/735], Loss: 0.0850
Epoch [5/100], Step [421/735], Loss: 0.1302
Epoch [5/100], Step [431/735], Loss: 0.0982
Epoch [5/100], Step [441/735], Loss: 0.0328
Epoch [5/100], Step [451/735], Loss: 0.1017
Epoch [5/100], Step [461/735], Loss: 0.1047
Epoch [5/100], Step [471/735], Loss: 0.1020
Epoch [5/100], Step [481/735], Loss: 0.0735
Epoch [5/100], Step [491/735], Loss: 0.1085
Epoch [5/100], Step [501/735], Loss: 0.0937
Epoch [5/100], Step [511/735], Loss: 0.0923
Epoch [5/100], Step [521/735], Loss: 0.0777
Epoch [5/100], Step [531/735], Loss: 0.0762
Epoch [5/100], Step [541/735], Loss: 0.0667
Epoch [5/100], Step [551/735], Loss: 0.1081
Epoch [5/100], Step [561/735], Loss: 0.0875
Epoch [5/100], Step [571/735], Loss: 0.0726
Epoch [5/100], Step [581/735], Loss: 0.1245
Epoch [5/100], Step [591/735], Loss: 0.0686
Epoch [5/100], Step [601/735], Loss: 0.0582
Epoch [5/100], Step [611/735], Loss: 0.1027
Epoch [5/100], Step [621/735], Loss: 0.0612
Epoch [5/100], Step [631/735], Loss: 0.0655
Epoch [5/100], Step [641/735], Loss: 0.1155
Epoch [5/100], Step [651/735], Loss: 0.0743
Epoch [5/100], Step [661/735], Loss: 0.1093
Epoch [5/100], Step [671/735], Loss: 0.0508
Epoch [5/100], Step [681/735], Loss: 0.1097
Epoch [5/100], Step [691/735], Loss: 0.0981
Epoch [5/100], Step [701/735], Loss: 0.0979
Epoch [5/100], Step [711/735], Loss: 0.0786
Epoch [5/100], Step [721/735], Loss: 0.1024
Epoch [5/100], Step [731/735], Loss: 0.0951
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8644,Val AUC: 0.9019,Val precision: 0.8250, Val recall: 0.6581, Val Loss: 0.1021
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 5 | Time taken: 2215.05s |
| Val CE loss: 0.10207 | Val MSE 0.86439 | Train Loss 0.10087 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 6
Training for epoch 6
Epoch [6/100], Step [1/735], Loss: 0.1013
Epoch [6/100], Step [11/735], Loss: 0.1208
Epoch [6/100], Step [21/735], Loss: 0.0985
Epoch [6/100], Step [31/735], Loss: 0.1444
Epoch [6/100], Step [41/735], Loss: 0.0636
Epoch [6/100], Step [51/735], Loss: 0.0784
Epoch [6/100], Step [61/735], Loss: 0.1068
Epoch [6/100], Step [71/735], Loss: 0.1386
Epoch [6/100], Step [81/735], Loss: 0.0784
Epoch [6/100], Step [91/735], Loss: 0.1067
Epoch [6/100], Step [101/735], Loss: 0.0462
Epoch [6/100], Step [111/735], Loss: 0.0462
Epoch [6/100], Step [121/735], Loss: 0.1238
Epoch [6/100], Step [131/735], Loss: 0.0821
Epoch [6/100], Step [141/735], Loss: 0.0830
Epoch [6/100], Step [151/735], Loss: 0.0767
Epoch [6/100], Step [161/735], Loss: 0.1408
Epoch [6/100], Step [171/735], Loss: 0.0688
Epoch [6/100], Step [181/735], Loss: 0.0918
Epoch [6/100], Step [191/735], Loss: 0.1102
Epoch [6/100], Step [201/735], Loss: 0.1081
Epoch [6/100], Step [211/735], Loss: 0.1370
Epoch [6/100], Step [221/735], Loss: 0.0753
Epoch [6/100], Step [231/735], Loss: 0.0963
Epoch [6/100], Step [241/735], Loss: 0.1184
Epoch [6/100], Step [251/735], Loss: 0.0904
Epoch [6/100], Step [261/735], Loss: 0.1091
Epoch [6/100], Step [271/735], Loss: 0.0685
Epoch [6/100], Step [281/735], Loss: 0.0648
Epoch [6/100], Step [291/735], Loss: 0.0797
Epoch [6/100], Step [301/735], Loss: 0.0866
Epoch [6/100], Step [311/735], Loss: 0.0780
Epoch [6/100], Step [321/735], Loss: 0.0622
Epoch [6/100], Step [331/735], Loss: 0.0803
Epoch [6/100], Step [341/735], Loss: 0.0850
Epoch [6/100], Step [351/735], Loss: 0.0836
Epoch [6/100], Step [361/735], Loss: 0.0660
Epoch [6/100], Step [371/735], Loss: 0.0713
Epoch [6/100], Step [381/735], Loss: 0.0809
Epoch [6/100], Step [391/735], Loss: 0.1119
Epoch [6/100], Step [401/735], Loss: 0.1118
Epoch [6/100], Step [411/735], Loss: 0.1119
Epoch [6/100], Step [421/735], Loss: 0.0615
Epoch [6/100], Step [431/735], Loss: 0.0987
Epoch [6/100], Step [441/735], Loss: 0.0937
Epoch [6/100], Step [451/735], Loss: 0.0648
Epoch [6/100], Step [461/735], Loss: 0.0783
Epoch [6/100], Step [471/735], Loss: 0.0919
Epoch [6/100], Step [481/735], Loss: 0.0837
Epoch [6/100], Step [491/735], Loss: 0.0806
Epoch [6/100], Step [501/735], Loss: 0.0648
Epoch [6/100], Step [511/735], Loss: 0.0873
Epoch [6/100], Step [521/735], Loss: 0.0982
Epoch [6/100], Step [531/735], Loss: 0.1497
Epoch [6/100], Step [541/735], Loss: 0.1052
Epoch [6/100], Step [551/735], Loss: 0.1003
Epoch [6/100], Step [561/735], Loss: 0.0968
Epoch [6/100], Step [571/735], Loss: 0.0621
Epoch [6/100], Step [581/735], Loss: 0.0891
Epoch [6/100], Step [591/735], Loss: 0.0769
Epoch [6/100], Step [601/735], Loss: 0.0823
Epoch [6/100], Step [611/735], Loss: 0.0380
Epoch [6/100], Step [621/735], Loss: 0.0709
Epoch [6/100], Step [631/735], Loss: 0.0662
Epoch [6/100], Step [641/735], Loss: 0.0969
Epoch [6/100], Step [651/735], Loss: 0.1279
Epoch [6/100], Step [661/735], Loss: 0.0726
Epoch [6/100], Step [671/735], Loss: 0.0729
Epoch [6/100], Step [681/735], Loss: 0.0569
Epoch [6/100], Step [691/735], Loss: 0.0847
Epoch [6/100], Step [701/735], Loss: 0.0684
Epoch [6/100], Step [711/735], Loss: 0.0738
Epoch [6/100], Step [721/735], Loss: 0.0829
Epoch [6/100], Step [731/735], Loss: 0.0890
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8620,Val AUC: 0.9121,Val precision: 0.8389, Val recall: 0.6310, Val Loss: 0.0985
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 6 | Time taken: 2220.59s |
| Val CE loss: 0.09854 | Val MSE 0.86197 | Train Loss 0.09019 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 7
Training for epoch 7
Epoch [7/100], Step [1/735], Loss: 0.1081
Epoch [7/100], Step [11/735], Loss: 0.0629
Epoch [7/100], Step [21/735], Loss: 0.0707
Epoch [7/100], Step [31/735], Loss: 0.1085
Epoch [7/100], Step [41/735], Loss: 0.0771
Epoch [7/100], Step [51/735], Loss: 0.0563
Epoch [7/100], Step [61/735], Loss: 0.1002
Epoch [7/100], Step [71/735], Loss: 0.0918
Epoch [7/100], Step [81/735], Loss: 0.0793
Epoch [7/100], Step [91/735], Loss: 0.0969
Epoch [7/100], Step [101/735], Loss: 0.0631
Epoch [7/100], Step [111/735], Loss: 0.0660
Epoch [7/100], Step [121/735], Loss: 0.1121
Epoch [7/100], Step [131/735], Loss: 0.1561
Epoch [7/100], Step [141/735], Loss: 0.1044
Epoch [7/100], Step [151/735], Loss: 0.1052
Epoch [7/100], Step [161/735], Loss: 0.0874
Epoch [7/100], Step [171/735], Loss: 0.0938
Epoch [7/100], Step [181/735], Loss: 0.1109
Epoch [7/100], Step [191/735], Loss: 0.1308
Epoch [7/100], Step [201/735], Loss: 0.0314
Epoch [7/100], Step [211/735], Loss: 0.1186
Epoch [7/100], Step [221/735], Loss: 0.0636
Epoch [7/100], Step [231/735], Loss: 0.1189
Epoch [7/100], Step [241/735], Loss: 0.0907
Epoch [7/100], Step [251/735], Loss: 0.0915
Epoch [7/100], Step [261/735], Loss: 0.0799
Epoch [7/100], Step [271/735], Loss: 0.0737
Epoch [7/100], Step [281/735], Loss: 0.0900
Epoch [7/100], Step [291/735], Loss: 0.0543
Epoch [7/100], Step [301/735], Loss: 0.0941
Epoch [7/100], Step [311/735], Loss: 0.0670
Epoch [7/100], Step [321/735], Loss: 0.0717
Epoch [7/100], Step [331/735], Loss: 0.0924
Epoch [7/100], Step [341/735], Loss: 0.0614
Epoch [7/100], Step [351/735], Loss: 0.0734
Epoch [7/100], Step [361/735], Loss: 0.1220
Epoch [7/100], Step [371/735], Loss: 0.0890
Epoch [7/100], Step [381/735], Loss: 0.0903
Epoch [7/100], Step [391/735], Loss: 0.0969
Epoch [7/100], Step [401/735], Loss: 0.1019
Epoch [7/100], Step [411/735], Loss: 0.0391
Epoch [7/100], Step [421/735], Loss: 0.1063
Epoch [7/100], Step [431/735], Loss: 0.0816
Epoch [7/100], Step [441/735], Loss: 0.0525
Epoch [7/100], Step [451/735], Loss: 0.1037
Epoch [7/100], Step [461/735], Loss: 0.0683
Epoch [7/100], Step [471/735], Loss: 0.0631
Epoch [7/100], Step [481/735], Loss: 0.0492
Epoch [7/100], Step [491/735], Loss: 0.0704
Epoch [7/100], Step [501/735], Loss: 0.0894
Epoch [7/100], Step [511/735], Loss: 0.1121
Epoch [7/100], Step [521/735], Loss: 0.0721
Epoch [7/100], Step [531/735], Loss: 0.0834
Epoch [7/100], Step [541/735], Loss: 0.0612
Epoch [7/100], Step [551/735], Loss: 0.1128
Epoch [7/100], Step [561/735], Loss: 0.0369
Epoch [7/100], Step [571/735], Loss: 0.1002
Epoch [7/100], Step [581/735], Loss: 0.0525
Epoch [7/100], Step [591/735], Loss: 0.0992
Epoch [7/100], Step [601/735], Loss: 0.0933
Epoch [7/100], Step [611/735], Loss: 0.0813
Epoch [7/100], Step [621/735], Loss: 0.0922
Epoch [7/100], Step [631/735], Loss: 0.1072
Epoch [7/100], Step [641/735], Loss: 0.0292
Epoch [7/100], Step [651/735], Loss: 0.0999
Epoch [7/100], Step [661/735], Loss: 0.0568
Epoch [7/100], Step [671/735], Loss: 0.0772
Epoch [7/100], Step [681/735], Loss: 0.0614
Epoch [7/100], Step [691/735], Loss: 0.0992
Epoch [7/100], Step [701/735], Loss: 0.0739
Epoch [7/100], Step [711/735], Loss: 0.0904
Epoch [7/100], Step [721/735], Loss: 0.0886
Epoch [7/100], Step [731/735], Loss: 0.1448
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8803,Val AUC: 0.9219,Val precision: 0.8375, Val recall: 0.7134, Val Loss: 0.0917
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 7 | Time taken: 2229.90s |
| Val CE loss: 0.09170 | Val MSE 0.88033 | Train Loss 0.08080 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 8
Training for epoch 8
Epoch [8/100], Step [1/735], Loss: 0.0467
Epoch [8/100], Step [11/735], Loss: 0.0586
Epoch [8/100], Step [21/735], Loss: 0.0656
Epoch [8/100], Step [31/735], Loss: 0.0890
Epoch [8/100], Step [41/735], Loss: 0.0633
Epoch [8/100], Step [51/735], Loss: 0.1015
Epoch [8/100], Step [61/735], Loss: 0.0966
Epoch [8/100], Step [71/735], Loss: 0.0941
Epoch [8/100], Step [81/735], Loss: 0.0471
Epoch [8/100], Step [91/735], Loss: 0.0473
Epoch [8/100], Step [101/735], Loss: 0.0755
Epoch [8/100], Step [111/735], Loss: 0.0935
Epoch [8/100], Step [121/735], Loss: 0.0710
Epoch [8/100], Step [131/735], Loss: 0.0575
Epoch [8/100], Step [141/735], Loss: 0.0719
Epoch [8/100], Step [151/735], Loss: 0.1066
Epoch [8/100], Step [161/735], Loss: 0.0700
Epoch [8/100], Step [171/735], Loss: 0.0951
Epoch [8/100], Step [181/735], Loss: 0.0468
Epoch [8/100], Step [191/735], Loss: 0.0567
Epoch [8/100], Step [201/735], Loss: 0.0860
Epoch [8/100], Step [211/735], Loss: 0.0874
Epoch [8/100], Step [221/735], Loss: 0.1360
Epoch [8/100], Step [231/735], Loss: 0.0751
Epoch [8/100], Step [241/735], Loss: 0.1370
Epoch [8/100], Step [251/735], Loss: 0.1111
Epoch [8/100], Step [261/735], Loss: 0.0883
Epoch [8/100], Step [271/735], Loss: 0.0873
Epoch [8/100], Step [281/735], Loss: 0.0501
Epoch [8/100], Step [291/735], Loss: 0.0483
Epoch [8/100], Step [301/735], Loss: 0.1013
Epoch [8/100], Step [311/735], Loss: 0.0621
Epoch [8/100], Step [321/735], Loss: 0.0881
Epoch [8/100], Step [331/735], Loss: 0.0758
Epoch [8/100], Step [341/735], Loss: 0.0844
Epoch [8/100], Step [351/735], Loss: 0.0696
Epoch [8/100], Step [361/735], Loss: 0.0758
Epoch [8/100], Step [371/735], Loss: 0.0748
Epoch [8/100], Step [381/735], Loss: 0.1042
Epoch [8/100], Step [391/735], Loss: 0.0868
Epoch [8/100], Step [401/735], Loss: 0.0741
Epoch [8/100], Step [411/735], Loss: 0.0717
Epoch [8/100], Step [421/735], Loss: 0.0920
Epoch [8/100], Step [431/735], Loss: 0.0451
Epoch [8/100], Step [441/735], Loss: 0.0632
Epoch [8/100], Step [451/735], Loss: 0.1074
Epoch [8/100], Step [461/735], Loss: 0.0494
Epoch [8/100], Step [471/735], Loss: 0.0905
Epoch [8/100], Step [481/735], Loss: 0.1079
Epoch [8/100], Step [491/735], Loss: 0.0795
Epoch [8/100], Step [501/735], Loss: 0.0330
Epoch [8/100], Step [511/735], Loss: 0.0879
Epoch [8/100], Step [521/735], Loss: 0.0602
Epoch [8/100], Step [531/735], Loss: 0.0342
Epoch [8/100], Step [541/735], Loss: 0.0741
Epoch [8/100], Step [551/735], Loss: 0.0519
Epoch [8/100], Step [561/735], Loss: 0.0613
Epoch [8/100], Step [571/735], Loss: 0.0454
Epoch [8/100], Step [581/735], Loss: 0.0412
Epoch [8/100], Step [591/735], Loss: 0.1016
Epoch [8/100], Step [601/735], Loss: 0.0494
Epoch [8/100], Step [611/735], Loss: 0.0588
Epoch [8/100], Step [621/735], Loss: 0.0499
Epoch [8/100], Step [631/735], Loss: 0.0563
Epoch [8/100], Step [641/735], Loss: 0.0760
Epoch [8/100], Step [651/735], Loss: 0.0511
Epoch [8/100], Step [661/735], Loss: 0.0933
Epoch [8/100], Step [671/735], Loss: 0.0842
Epoch [8/100], Step [681/735], Loss: 0.0772
Epoch [8/100], Step [691/735], Loss: 0.0880
Epoch [8/100], Step [701/735], Loss: 0.0968
Epoch [8/100], Step [711/735], Loss: 0.0397
Epoch [8/100], Step [721/735], Loss: 0.1182
Epoch [8/100], Step [731/735], Loss: 0.0933
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8769,Val AUC: 0.9213,Val precision: 0.8322, Val recall: 0.7048, Val Loss: 0.0939
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 8 | Time taken: 2227.69s |
| Val CE loss: 0.09386 | Val MSE 0.87686 | Train Loss 0.07262 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 9
Training for epoch 9
Epoch [9/100], Step [1/735], Loss: 0.0986
Epoch [9/100], Step [11/735], Loss: 0.0679
Epoch [9/100], Step [21/735], Loss: 0.0714
Epoch [9/100], Step [31/735], Loss: 0.0562
Epoch [9/100], Step [41/735], Loss: 0.0604
Epoch [9/100], Step [51/735], Loss: 0.0663
Epoch [9/100], Step [61/735], Loss: 0.0601
Epoch [9/100], Step [71/735], Loss: 0.0873
Epoch [9/100], Step [81/735], Loss: 0.0571
Epoch [9/100], Step [91/735], Loss: 0.0599
Epoch [9/100], Step [101/735], Loss: 0.0880
Epoch [9/100], Step [111/735], Loss: 0.0826
Epoch [9/100], Step [121/735], Loss: 0.0389
Epoch [9/100], Step [131/735], Loss: 0.0651
Epoch [9/100], Step [141/735], Loss: 0.0788
Epoch [9/100], Step [151/735], Loss: 0.0956
Epoch [9/100], Step [161/735], Loss: 0.0421
Epoch [9/100], Step [171/735], Loss: 0.0394
Epoch [9/100], Step [181/735], Loss: 0.0851
Epoch [9/100], Step [191/735], Loss: 0.0475
Epoch [9/100], Step [201/735], Loss: 0.0607
Epoch [9/100], Step [211/735], Loss: 0.0675
Epoch [9/100], Step [221/735], Loss: 0.0723
Epoch [9/100], Step [231/735], Loss: 0.1032
Epoch [9/100], Step [241/735], Loss: 0.0560
Epoch [9/100], Step [251/735], Loss: 0.0903
Epoch [9/100], Step [261/735], Loss: 0.1428
Epoch [9/100], Step [271/735], Loss: 0.0550
Epoch [9/100], Step [281/735], Loss: 0.0642
Epoch [9/100], Step [291/735], Loss: 0.0607
Epoch [9/100], Step [301/735], Loss: 0.0641
Epoch [9/100], Step [311/735], Loss: 0.0582
Epoch [9/100], Step [321/735], Loss: 0.0983
Epoch [9/100], Step [331/735], Loss: 0.0761
Epoch [9/100], Step [341/735], Loss: 0.0664
Epoch [9/100], Step [351/735], Loss: 0.0625
Epoch [9/100], Step [361/735], Loss: 0.0453
Epoch [9/100], Step [371/735], Loss: 0.0568
Epoch [9/100], Step [381/735], Loss: 0.0524
Epoch [9/100], Step [391/735], Loss: 0.0833
Epoch [9/100], Step [401/735], Loss: 0.0491
Epoch [9/100], Step [411/735], Loss: 0.0607
Epoch [9/100], Step [421/735], Loss: 0.0848
Epoch [9/100], Step [431/735], Loss: 0.0865
Epoch [9/100], Step [441/735], Loss: 0.0371
Epoch [9/100], Step [451/735], Loss: 0.0723
Epoch [9/100], Step [461/735], Loss: 0.0664
Epoch [9/100], Step [471/735], Loss: 0.0627
Epoch [9/100], Step [481/735], Loss: 0.0893
Epoch [9/100], Step [491/735], Loss: 0.0589
Epoch [9/100], Step [501/735], Loss: 0.0913
Epoch [9/100], Step [511/735], Loss: 0.0545
Epoch [9/100], Step [521/735], Loss: 0.0681
Epoch [9/100], Step [531/735], Loss: 0.0816
Epoch [9/100], Step [541/735], Loss: 0.0649
Epoch [9/100], Step [551/735], Loss: 0.0475
Epoch [9/100], Step [561/735], Loss: 0.0811
Epoch [9/100], Step [571/735], Loss: 0.0484
Epoch [9/100], Step [581/735], Loss: 0.0717
Epoch [9/100], Step [591/735], Loss: 0.0547
Epoch [9/100], Step [601/735], Loss: 0.0618
Epoch [9/100], Step [611/735], Loss: 0.0983
Epoch [9/100], Step [621/735], Loss: 0.0832
Epoch [9/100], Step [631/735], Loss: 0.0603
Epoch [9/100], Step [641/735], Loss: 0.0734
Epoch [9/100], Step [651/735], Loss: 0.0443
Epoch [9/100], Step [661/735], Loss: 0.0802
Epoch [9/100], Step [671/735], Loss: 0.0581
Epoch [9/100], Step [681/735], Loss: 0.1029
Epoch [9/100], Step [691/735], Loss: 0.0920
Epoch [9/100], Step [701/735], Loss: 0.0777
Epoch [9/100], Step [711/735], Loss: 0.0538
Epoch [9/100], Step [721/735], Loss: 0.0430
Epoch [9/100], Step [731/735], Loss: 0.0387
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8866,Val AUC: 0.9305,Val precision: 0.8200, Val recall: 0.7651, Val Loss: 0.0866
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 9 | Time taken: 2232.38s |
| Val CE loss: 0.08657 | Val MSE 0.88656 | Train Loss 0.06537 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 10
Training for epoch 10
Epoch [10/100], Step [1/735], Loss: 0.0594
Epoch [10/100], Step [11/735], Loss: 0.0750
Epoch [10/100], Step [21/735], Loss: 0.0693
Epoch [10/100], Step [31/735], Loss: 0.0468
Epoch [10/100], Step [41/735], Loss: 0.0658
Epoch [10/100], Step [51/735], Loss: 0.0274
Epoch [10/100], Step [61/735], Loss: 0.0370
Epoch [10/100], Step [71/735], Loss: 0.0662
Epoch [10/100], Step [81/735], Loss: 0.0654
Epoch [10/100], Step [91/735], Loss: 0.0538
Epoch [10/100], Step [101/735], Loss: 0.0649
Epoch [10/100], Step [111/735], Loss: 0.0522
Epoch [10/100], Step [121/735], Loss: 0.0695
Epoch [10/100], Step [131/735], Loss: 0.0717
Epoch [10/100], Step [141/735], Loss: 0.0871
Epoch [10/100], Step [151/735], Loss: 0.0503
Epoch [10/100], Step [161/735], Loss: 0.0494
Epoch [10/100], Step [171/735], Loss: 0.0266
Epoch [10/100], Step [181/735], Loss: 0.0712
Epoch [10/100], Step [191/735], Loss: 0.0769
Epoch [10/100], Step [201/735], Loss: 0.0538
Epoch [10/100], Step [211/735], Loss: 0.0483
Epoch [10/100], Step [221/735], Loss: 0.0454
Epoch [10/100], Step [231/735], Loss: 0.0853
Epoch [10/100], Step [241/735], Loss: 0.0484
Epoch [10/100], Step [251/735], Loss: 0.0510
Epoch [10/100], Step [261/735], Loss: 0.0769
Epoch [10/100], Step [271/735], Loss: 0.0459
Epoch [10/100], Step [281/735], Loss: 0.0368
Epoch [10/100], Step [291/735], Loss: 0.0406
Epoch [10/100], Step [301/735], Loss: 0.0558
Epoch [10/100], Step [311/735], Loss: 0.0509
Epoch [10/100], Step [321/735], Loss: 0.0520
Epoch [10/100], Step [331/735], Loss: 0.0256
Epoch [10/100], Step [341/735], Loss: 0.0630
Epoch [10/100], Step [351/735], Loss: 0.0482
Epoch [10/100], Step [361/735], Loss: 0.0744
Epoch [10/100], Step [371/735], Loss: 0.0504
Epoch [10/100], Step [381/735], Loss: 0.0337
Epoch [10/100], Step [391/735], Loss: 0.0723
Epoch [10/100], Step [401/735], Loss: 0.0910
Epoch [10/100], Step [411/735], Loss: 0.0557
Epoch [10/100], Step [421/735], Loss: 0.0572
Epoch [10/100], Step [431/735], Loss: 0.0558
Epoch [10/100], Step [441/735], Loss: 0.1040
Epoch [10/100], Step [451/735], Loss: 0.0415
Epoch [10/100], Step [461/735], Loss: 0.0368
Epoch [10/100], Step [471/735], Loss: 0.0652
Epoch [10/100], Step [481/735], Loss: 0.0577
Epoch [10/100], Step [491/735], Loss: 0.0418
Epoch [10/100], Step [501/735], Loss: 0.0479
Epoch [10/100], Step [511/735], Loss: 0.0642
Epoch [10/100], Step [521/735], Loss: 0.0311
Epoch [10/100], Step [531/735], Loss: 0.0712
Epoch [10/100], Step [541/735], Loss: 0.0571
Epoch [10/100], Step [551/735], Loss: 0.0577
Epoch [10/100], Step [561/735], Loss: 0.0573
Epoch [10/100], Step [571/735], Loss: 0.1221
Epoch [10/100], Step [581/735], Loss: 0.0790
Epoch [10/100], Step [591/735], Loss: 0.1013
Epoch [10/100], Step [601/735], Loss: 0.0625
Epoch [10/100], Step [611/735], Loss: 0.0368
Epoch [10/100], Step [621/735], Loss: 0.0816
Epoch [10/100], Step [631/735], Loss: 0.0693
Epoch [10/100], Step [641/735], Loss: 0.0860
Epoch [10/100], Step [651/735], Loss: 0.0252
Epoch [10/100], Step [661/735], Loss: 0.0698
Epoch [10/100], Step [671/735], Loss: 0.0443
Epoch [10/100], Step [681/735], Loss: 0.0778
Epoch [10/100], Step [691/735], Loss: 0.0620
Epoch [10/100], Step [701/735], Loss: 0.0465
Epoch [10/100], Step [711/735], Loss: 0.0552
Epoch [10/100], Step [721/735], Loss: 0.0304
Epoch [10/100], Step [731/735], Loss: 0.0423
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8876,Val AUC: 0.9354,Val precision: 0.8182, Val recall: 0.7724, Val Loss: 0.0839
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 10 | Time taken: 2230.90s |
| Val CE loss: 0.08386 | Val MSE 0.88760 | Train Loss 0.05982 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 11
Training for epoch 11
Epoch [11/100], Step [1/735], Loss: 0.0716
Epoch [11/100], Step [11/735], Loss: 0.0819
Epoch [11/100], Step [21/735], Loss: 0.0732
Epoch [11/100], Step [31/735], Loss: 0.0281
Epoch [11/100], Step [41/735], Loss: 0.0759
Epoch [11/100], Step [51/735], Loss: 0.0852
Epoch [11/100], Step [61/735], Loss: 0.0391
Epoch [11/100], Step [71/735], Loss: 0.0719
Epoch [11/100], Step [81/735], Loss: 0.0678
Epoch [11/100], Step [91/735], Loss: 0.0620
Epoch [11/100], Step [101/735], Loss: 0.0405
Epoch [11/100], Step [111/735], Loss: 0.0638
Epoch [11/100], Step [121/735], Loss: 0.0618
Epoch [11/100], Step [131/735], Loss: 0.0512
Epoch [11/100], Step [141/735], Loss: 0.0603
Epoch [11/100], Step [151/735], Loss: 0.0606
Epoch [11/100], Step [161/735], Loss: 0.0726
Epoch [11/100], Step [171/735], Loss: 0.0407
Epoch [11/100], Step [181/735], Loss: 0.0673
Epoch [11/100], Step [191/735], Loss: 0.0554
Epoch [11/100], Step [201/735], Loss: 0.0832
Epoch [11/100], Step [211/735], Loss: 0.0558
Epoch [11/100], Step [221/735], Loss: 0.0213
Epoch [11/100], Step [231/735], Loss: 0.0387
Epoch [11/100], Step [241/735], Loss: 0.0817
Epoch [11/100], Step [251/735], Loss: 0.0464
Epoch [11/100], Step [261/735], Loss: 0.0845
Epoch [11/100], Step [271/735], Loss: 0.0191
Epoch [11/100], Step [281/735], Loss: 0.0599
Epoch [11/100], Step [291/735], Loss: 0.0717
Epoch [11/100], Step [301/735], Loss: 0.0517
Epoch [11/100], Step [311/735], Loss: 0.0631
Epoch [11/100], Step [321/735], Loss: 0.0523
Epoch [11/100], Step [331/735], Loss: 0.0268
Epoch [11/100], Step [341/735], Loss: 0.0496
Epoch [11/100], Step [351/735], Loss: 0.0630
Epoch [11/100], Step [361/735], Loss: 0.0420
Epoch [11/100], Step [371/735], Loss: 0.0436
Epoch [11/100], Step [381/735], Loss: 0.0366
Epoch [11/100], Step [391/735], Loss: 0.0553
Epoch [11/100], Step [401/735], Loss: 0.0624
Epoch [11/100], Step [411/735], Loss: 0.0351
Epoch [11/100], Step [421/735], Loss: 0.0626
Epoch [11/100], Step [431/735], Loss: 0.0526
Epoch [11/100], Step [441/735], Loss: 0.0769
Epoch [11/100], Step [451/735], Loss: 0.0514
Epoch [11/100], Step [461/735], Loss: 0.0377
Epoch [11/100], Step [471/735], Loss: 0.0856
Epoch [11/100], Step [481/735], Loss: 0.0442
Epoch [11/100], Step [491/735], Loss: 0.0309
Epoch [11/100], Step [501/735], Loss: 0.0435
Epoch [11/100], Step [511/735], Loss: 0.0660
Epoch [11/100], Step [521/735], Loss: 0.0776
Epoch [11/100], Step [531/735], Loss: 0.0418
Epoch [11/100], Step [541/735], Loss: 0.0526
Epoch [11/100], Step [551/735], Loss: 0.0244
Epoch [11/100], Step [561/735], Loss: 0.0500
Epoch [11/100], Step [571/735], Loss: 0.0298
Epoch [11/100], Step [581/735], Loss: 0.0438
Epoch [11/100], Step [591/735], Loss: 0.0930
Epoch [11/100], Step [601/735], Loss: 0.0313
Epoch [11/100], Step [611/735], Loss: 0.0724
Epoch [11/100], Step [621/735], Loss: 0.0579
Epoch [11/100], Step [631/735], Loss: 0.0445
Epoch [11/100], Step [641/735], Loss: 0.0781
Epoch [11/100], Step [651/735], Loss: 0.0607
Epoch [11/100], Step [661/735], Loss: 0.0294
Epoch [11/100], Step [671/735], Loss: 0.0507
Epoch [11/100], Step [681/735], Loss: 0.0397
Epoch [11/100], Step [691/735], Loss: 0.0333
Epoch [11/100], Step [701/735], Loss: 0.0569
Epoch [11/100], Step [711/735], Loss: 0.0439
Epoch [11/100], Step [721/735], Loss: 0.0574
Epoch [11/100], Step [731/735], Loss: 0.0721
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8949,Val AUC: 0.9384,Val precision: 0.8483, Val recall: 0.7632, Val Loss: 0.0822
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 11 | Time taken: 2225.65s |
| Val CE loss: 0.08221 | Val MSE 0.89487 | Train Loss 0.05413 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 12
Training for epoch 12
Epoch [12/100], Step [1/735], Loss: 0.0433
Epoch [12/100], Step [11/735], Loss: 0.0251
Epoch [12/100], Step [21/735], Loss: 0.0396
Epoch [12/100], Step [31/735], Loss: 0.0630
Epoch [12/100], Step [41/735], Loss: 0.0250
Epoch [12/100], Step [51/735], Loss: 0.0709
Epoch [12/100], Step [61/735], Loss: 0.0471
Epoch [12/100], Step [71/735], Loss: 0.0626
Epoch [12/100], Step [81/735], Loss: 0.0279
Epoch [12/100], Step [91/735], Loss: 0.0652
Epoch [12/100], Step [101/735], Loss: 0.0227
Epoch [12/100], Step [111/735], Loss: 0.0426
Epoch [12/100], Step [121/735], Loss: 0.0544
Epoch [12/100], Step [131/735], Loss: 0.0339
Epoch [12/100], Step [141/735], Loss: 0.0810
Epoch [12/100], Step [151/735], Loss: 0.0643
Epoch [12/100], Step [161/735], Loss: 0.0466
Epoch [12/100], Step [171/735], Loss: 0.0519
Epoch [12/100], Step [181/735], Loss: 0.0459
Epoch [12/100], Step [191/735], Loss: 0.0174
Epoch [12/100], Step [201/735], Loss: 0.0441
Epoch [12/100], Step [211/735], Loss: 0.0663
Epoch [12/100], Step [221/735], Loss: 0.0574
Epoch [12/100], Step [231/735], Loss: 0.0471
Epoch [12/100], Step [241/735], Loss: 0.0366
Epoch [12/100], Step [251/735], Loss: 0.0078
Epoch [12/100], Step [261/735], Loss: 0.0570
Epoch [12/100], Step [271/735], Loss: 0.0470
Epoch [12/100], Step [281/735], Loss: 0.0363
Epoch [12/100], Step [291/735], Loss: 0.0821
Epoch [12/100], Step [301/735], Loss: 0.0379
Epoch [12/100], Step [311/735], Loss: 0.0636
Epoch [12/100], Step [321/735], Loss: 0.0404
Epoch [12/100], Step [331/735], Loss: 0.1063
Epoch [12/100], Step [341/735], Loss: 0.0324
Epoch [12/100], Step [351/735], Loss: 0.0408
Epoch [12/100], Step [361/735], Loss: 0.0435
Epoch [12/100], Step [371/735], Loss: 0.0506
Epoch [12/100], Step [381/735], Loss: 0.0441
Epoch [12/100], Step [391/735], Loss: 0.0428
Epoch [12/100], Step [401/735], Loss: 0.0376
Epoch [12/100], Step [411/735], Loss: 0.0594
Epoch [12/100], Step [421/735], Loss: 0.0353
Epoch [12/100], Step [431/735], Loss: 0.0445
Epoch [12/100], Step [441/735], Loss: 0.0349
Epoch [12/100], Step [451/735], Loss: 0.0422
Epoch [12/100], Step [461/735], Loss: 0.0555
Epoch [12/100], Step [471/735], Loss: 0.0355
Epoch [12/100], Step [481/735], Loss: 0.0280
Epoch [12/100], Step [491/735], Loss: 0.0214
Epoch [12/100], Step [501/735], Loss: 0.0357
Epoch [12/100], Step [511/735], Loss: 0.0558
Epoch [12/100], Step [521/735], Loss: 0.0369
Epoch [12/100], Step [531/735], Loss: 0.0216
Epoch [12/100], Step [541/735], Loss: 0.0671
Epoch [12/100], Step [551/735], Loss: 0.0528
Epoch [12/100], Step [561/735], Loss: 0.0187
Epoch [12/100], Step [571/735], Loss: 0.0815
Epoch [12/100], Step [581/735], Loss: 0.0612
Epoch [12/100], Step [591/735], Loss: 0.0433
Epoch [12/100], Step [601/735], Loss: 0.0301
Epoch [12/100], Step [611/735], Loss: 0.0669
Epoch [12/100], Step [621/735], Loss: 0.0377
Epoch [12/100], Step [631/735], Loss: 0.0553
Epoch [12/100], Step [641/735], Loss: 0.0392
Epoch [12/100], Step [651/735], Loss: 0.0602
Epoch [12/100], Step [661/735], Loss: 0.0231
Epoch [12/100], Step [671/735], Loss: 0.0326
Epoch [12/100], Step [681/735], Loss: 0.0241
Epoch [12/100], Step [691/735], Loss: 0.0685
Epoch [12/100], Step [701/735], Loss: 0.0495
Epoch [12/100], Step [711/735], Loss: 0.0306
Epoch [12/100], Step [721/735], Loss: 0.0179
Epoch [12/100], Step [731/735], Loss: 0.0628
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8949,Val AUC: 0.9362,Val precision: 0.8251, Val recall: 0.7952, Val Loss: 0.0822
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 12 | Time taken: 2250.36s |
| Val CE loss: 0.08225 | Val MSE 0.89487 | Train Loss 0.04805 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 13
Training for epoch 13
Epoch [13/100], Step [1/735], Loss: 0.0452
Epoch [13/100], Step [11/735], Loss: 0.0344
Epoch [13/100], Step [21/735], Loss: 0.0552
Epoch [13/100], Step [31/735], Loss: 0.0451
Epoch [13/100], Step [41/735], Loss: 0.0401
Epoch [13/100], Step [51/735], Loss: 0.0417
Epoch [13/100], Step [61/735], Loss: 0.0643
Epoch [13/100], Step [71/735], Loss: 0.0504
Epoch [13/100], Step [81/735], Loss: 0.0251
Epoch [13/100], Step [91/735], Loss: 0.0256
Epoch [13/100], Step [101/735], Loss: 0.0551
Epoch [13/100], Step [111/735], Loss: 0.0418
Epoch [13/100], Step [121/735], Loss: 0.0307
Epoch [13/100], Step [131/735], Loss: 0.0261
Epoch [13/100], Step [141/735], Loss: 0.0445
Epoch [13/100], Step [151/735], Loss: 0.0133
Epoch [13/100], Step [161/735], Loss: 0.0250
Epoch [13/100], Step [171/735], Loss: 0.0639
Epoch [13/100], Step [181/735], Loss: 0.0680
Epoch [13/100], Step [191/735], Loss: 0.0090
Epoch [13/100], Step [201/735], Loss: 0.0122
Epoch [13/100], Step [211/735], Loss: 0.0422
Epoch [13/100], Step [221/735], Loss: 0.0528
Epoch [13/100], Step [231/735], Loss: 0.0396
Epoch [13/100], Step [241/735], Loss: 0.0362
Epoch [13/100], Step [251/735], Loss: 0.0514
Epoch [13/100], Step [261/735], Loss: 0.0401
Epoch [13/100], Step [271/735], Loss: 0.0222
Epoch [13/100], Step [281/735], Loss: 0.0383
Epoch [13/100], Step [291/735], Loss: 0.0888
Epoch [13/100], Step [301/735], Loss: 0.0721
Epoch [13/100], Step [311/735], Loss: 0.0848
Epoch [13/100], Step [321/735], Loss: 0.0862
Epoch [13/100], Step [331/735], Loss: 0.0429
Epoch [13/100], Step [341/735], Loss: 0.1083
Epoch [13/100], Step [351/735], Loss: 0.0361
Epoch [13/100], Step [361/735], Loss: 0.0480
Epoch [13/100], Step [371/735], Loss: 0.0497
Epoch [13/100], Step [381/735], Loss: 0.0539
Epoch [13/100], Step [391/735], Loss: 0.0235
Epoch [13/100], Step [401/735], Loss: 0.0632
Epoch [13/100], Step [411/735], Loss: 0.0685
Epoch [13/100], Step [421/735], Loss: 0.0215
Epoch [13/100], Step [431/735], Loss: 0.0363
Epoch [13/100], Step [441/735], Loss: 0.0176
Epoch [13/100], Step [451/735], Loss: 0.0451
Epoch [13/100], Step [461/735], Loss: 0.0335
Epoch [13/100], Step [471/735], Loss: 0.0438
Epoch [13/100], Step [481/735], Loss: 0.0669
Epoch [13/100], Step [491/735], Loss: 0.0097
Epoch [13/100], Step [501/735], Loss: 0.0373
Epoch [13/100], Step [511/735], Loss: 0.0350
Epoch [13/100], Step [521/735], Loss: 0.0536
Epoch [13/100], Step [531/735], Loss: 0.0521
Epoch [13/100], Step [541/735], Loss: 0.0447
Epoch [13/100], Step [551/735], Loss: 0.0563
Epoch [13/100], Step [561/735], Loss: 0.0659
Epoch [13/100], Step [571/735], Loss: 0.0369
Epoch [13/100], Step [581/735], Loss: 0.0229
Epoch [13/100], Step [591/735], Loss: 0.0447
Epoch [13/100], Step [601/735], Loss: 0.0337
Epoch [13/100], Step [611/735], Loss: 0.0313
Epoch [13/100], Step [621/735], Loss: 0.0893
Epoch [13/100], Step [631/735], Loss: 0.0259
Epoch [13/100], Step [641/735], Loss: 0.0332
Epoch [13/100], Step [651/735], Loss: 0.0419
Epoch [13/100], Step [661/735], Loss: 0.0577
Epoch [13/100], Step [671/735], Loss: 0.0167
Epoch [13/100], Step [681/735], Loss: 0.0146
Epoch [13/100], Step [691/735], Loss: 0.0333
Epoch [13/100], Step [701/735], Loss: 0.0347
Epoch [13/100], Step [711/735], Loss: 0.0360
Epoch [13/100], Step [721/735], Loss: 0.0327
Epoch [13/100], Step [731/735], Loss: 0.0337
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8952,Val AUC: 0.9380,Val precision: 0.8339, Val recall: 0.7841, Val Loss: 0.0838
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 13 | Time taken: 2240.69s |
| Val CE loss: 0.08379 | Val MSE 0.89522 | Train Loss 0.04503 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 14
Training for epoch 14
Epoch [14/100], Step [1/735], Loss: 0.0282
Epoch [14/100], Step [11/735], Loss: 0.0317
Epoch [14/100], Step [21/735], Loss: 0.0455
Epoch [14/100], Step [31/735], Loss: 0.0543
Epoch [14/100], Step [41/735], Loss: 0.0415
Epoch [14/100], Step [51/735], Loss: 0.0672
Epoch [14/100], Step [61/735], Loss: 0.1047
Epoch [14/100], Step [71/735], Loss: 0.0331
Epoch [14/100], Step [81/735], Loss: 0.0363
Epoch [14/100], Step [91/735], Loss: 0.0250
Epoch [14/100], Step [101/735], Loss: 0.0402
Epoch [14/100], Step [111/735], Loss: 0.0313
Epoch [14/100], Step [121/735], Loss: 0.0466
Epoch [14/100], Step [131/735], Loss: 0.0377
Epoch [14/100], Step [141/735], Loss: 0.0361
Epoch [14/100], Step [151/735], Loss: 0.0401
Epoch [14/100], Step [161/735], Loss: 0.0524
Epoch [14/100], Step [171/735], Loss: 0.0334
Epoch [14/100], Step [181/735], Loss: 0.0421
Epoch [14/100], Step [191/735], Loss: 0.0250
Epoch [14/100], Step [201/735], Loss: 0.0481
Epoch [14/100], Step [211/735], Loss: 0.0417
Epoch [14/100], Step [221/735], Loss: 0.0704
Epoch [14/100], Step [231/735], Loss: 0.0228
Epoch [14/100], Step [241/735], Loss: 0.0212
Epoch [14/100], Step [251/735], Loss: 0.0569
Epoch [14/100], Step [261/735], Loss: 0.0160
Epoch [14/100], Step [271/735], Loss: 0.0551
Epoch [14/100], Step [281/735], Loss: 0.0681
Epoch [14/100], Step [291/735], Loss: 0.0630
Epoch [14/100], Step [301/735], Loss: 0.0287
Epoch [14/100], Step [311/735], Loss: 0.0691
Epoch [14/100], Step [321/735], Loss: 0.0511
Epoch [14/100], Step [331/735], Loss: 0.0405
Epoch [14/100], Step [341/735], Loss: 0.0449
Epoch [14/100], Step [351/735], Loss: 0.0234
Epoch [14/100], Step [361/735], Loss: 0.0310
Epoch [14/100], Step [371/735], Loss: 0.0339
Epoch [14/100], Step [381/735], Loss: 0.0310
Epoch [14/100], Step [391/735], Loss: 0.0091
Epoch [14/100], Step [401/735], Loss: 0.0291
Epoch [14/100], Step [411/735], Loss: 0.0373
Epoch [14/100], Step [421/735], Loss: 0.0342
Epoch [14/100], Step [431/735], Loss: 0.0618
Epoch [14/100], Step [441/735], Loss: 0.0677
Epoch [14/100], Step [451/735], Loss: 0.0215
Epoch [14/100], Step [461/735], Loss: 0.0221
Epoch [14/100], Step [471/735], Loss: 0.0512
Epoch [14/100], Step [481/735], Loss: 0.0340
Epoch [14/100], Step [491/735], Loss: 0.0342
Epoch [14/100], Step [501/735], Loss: 0.0599
Epoch [14/100], Step [511/735], Loss: 0.0403
Epoch [14/100], Step [521/735], Loss: 0.0426
Epoch [14/100], Step [531/735], Loss: 0.0394
Epoch [14/100], Step [541/735], Loss: 0.0382
Epoch [14/100], Step [551/735], Loss: 0.0429
Epoch [14/100], Step [561/735], Loss: 0.0118
Epoch [14/100], Step [571/735], Loss: 0.0552
Epoch [14/100], Step [581/735], Loss: 0.0290
Epoch [14/100], Step [591/735], Loss: 0.0404
Epoch [14/100], Step [601/735], Loss: 0.0248
Epoch [14/100], Step [611/735], Loss: 0.0418
Epoch [14/100], Step [621/735], Loss: 0.0403
Epoch [14/100], Step [631/735], Loss: 0.0174
Epoch [14/100], Step [641/735], Loss: 0.0442
Epoch [14/100], Step [651/735], Loss: 0.0349
Epoch [14/100], Step [661/735], Loss: 0.0329
Epoch [14/100], Step [671/735], Loss: 0.0341
Epoch [14/100], Step [681/735], Loss: 0.0377
Epoch [14/100], Step [691/735], Loss: 0.0557
Epoch [14/100], Step [701/735], Loss: 0.0268
Epoch [14/100], Step [711/735], Loss: 0.0490
Epoch [14/100], Step [721/735], Loss: 0.0108
Epoch [14/100], Step [731/735], Loss: 0.0054
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8975,Val AUC: 0.9421,Val precision: 0.8264, Val recall: 0.8050, Val Loss: 0.0806
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 14 | Time taken: 2256.77s |
| Val CE loss: 0.08063 | Val MSE 0.89747 | Train Loss 0.04100 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 15
Training for epoch 15
Epoch [15/100], Step [1/735], Loss: 0.0241
Epoch [15/100], Step [11/735], Loss: 0.0375
Epoch [15/100], Step [21/735], Loss: 0.0171
Epoch [15/100], Step [31/735], Loss: 0.0371
Epoch [15/100], Step [41/735], Loss: 0.0308
Epoch [15/100], Step [51/735], Loss: 0.0269
Epoch [15/100], Step [61/735], Loss: 0.0541
Epoch [15/100], Step [71/735], Loss: 0.0535
Epoch [15/100], Step [81/735], Loss: 0.0436
Epoch [15/100], Step [91/735], Loss: 0.0448
Epoch [15/100], Step [101/735], Loss: 0.0632
Epoch [15/100], Step [111/735], Loss: 0.0486
Epoch [15/100], Step [121/735], Loss: 0.0563
Epoch [15/100], Step [131/735], Loss: 0.0364
Epoch [15/100], Step [141/735], Loss: 0.0455
Epoch [15/100], Step [151/735], Loss: 0.0348
Epoch [15/100], Step [161/735], Loss: 0.0506
Epoch [15/100], Step [171/735], Loss: 0.0380
Epoch [15/100], Step [181/735], Loss: 0.0574
Epoch [15/100], Step [191/735], Loss: 0.0368
Epoch [15/100], Step [201/735], Loss: 0.0342
Epoch [15/100], Step [211/735], Loss: 0.0306
Epoch [15/100], Step [221/735], Loss: 0.0514
Epoch [15/100], Step [231/735], Loss: 0.0527
Epoch [15/100], Step [241/735], Loss: 0.0344
Epoch [15/100], Step [251/735], Loss: 0.0387
Epoch [15/100], Step [261/735], Loss: 0.0615
Epoch [15/100], Step [271/735], Loss: 0.0167
Epoch [15/100], Step [281/735], Loss: 0.0456
Epoch [15/100], Step [291/735], Loss: 0.0266
Epoch [15/100], Step [301/735], Loss: 0.0228
Epoch [15/100], Step [311/735], Loss: 0.0818
Epoch [15/100], Step [321/735], Loss: 0.0369
Epoch [15/100], Step [331/735], Loss: 0.0499
Epoch [15/100], Step [341/735], Loss: 0.0472
Epoch [15/100], Step [351/735], Loss: 0.0287
Epoch [15/100], Step [361/735], Loss: 0.0171
Epoch [15/100], Step [371/735], Loss: 0.0154
Epoch [15/100], Step [381/735], Loss: 0.0577
Epoch [15/100], Step [391/735], Loss: 0.0548
Epoch [15/100], Step [401/735], Loss: 0.0373
Epoch [15/100], Step [411/735], Loss: 0.0472
Epoch [15/100], Step [421/735], Loss: 0.0912
Epoch [15/100], Step [431/735], Loss: 0.0488
Epoch [15/100], Step [441/735], Loss: 0.0426
Epoch [15/100], Step [451/735], Loss: 0.0639
Epoch [15/100], Step [461/735], Loss: 0.0745
Epoch [15/100], Step [471/735], Loss: 0.0224
Epoch [15/100], Step [481/735], Loss: 0.0193
Epoch [15/100], Step [491/735], Loss: 0.0271
Epoch [15/100], Step [501/735], Loss: 0.0129
Epoch [15/100], Step [511/735], Loss: 0.0089
Epoch [15/100], Step [521/735], Loss: 0.0159
Epoch [15/100], Step [531/735], Loss: 0.0231
Epoch [15/100], Step [541/735], Loss: 0.0421
Epoch [15/100], Step [551/735], Loss: 0.0200
Epoch [15/100], Step [561/735], Loss: 0.0242
Epoch [15/100], Step [571/735], Loss: 0.0369
Epoch [15/100], Step [581/735], Loss: 0.0164
Epoch [15/100], Step [591/735], Loss: 0.0229
Epoch [15/100], Step [601/735], Loss: 0.0486
Epoch [15/100], Step [611/735], Loss: 0.0316
Epoch [15/100], Step [621/735], Loss: 0.0393
Epoch [15/100], Step [631/735], Loss: 0.0211
Epoch [15/100], Step [641/735], Loss: 0.0266
Epoch [15/100], Step [651/735], Loss: 0.0304
Epoch [15/100], Step [661/735], Loss: 0.0250
Epoch [15/100], Step [671/735], Loss: 0.0162
Epoch [15/100], Step [681/735], Loss: 0.0281
Epoch [15/100], Step [691/735], Loss: 0.0301
Epoch [15/100], Step [701/735], Loss: 0.0399
Epoch [15/100], Step [711/735], Loss: 0.0273
Epoch [15/100], Step [721/735], Loss: 0.0432
Epoch [15/100], Step [731/735], Loss: 0.0250
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8919,Val AUC: 0.9419,Val precision: 0.8014, Val recall: 0.8192, Val Loss: 0.0840
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 15 | Time taken: 2288.58s |
| Val CE loss: 0.08399 | Val MSE 0.89193 | Train Loss 0.03741 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 16
Training for epoch 16
Epoch [16/100], Step [1/735], Loss: 0.0125
Epoch [16/100], Step [11/735], Loss: 0.0353
Epoch [16/100], Step [21/735], Loss: 0.0662
Epoch [16/100], Step [31/735], Loss: 0.0195
Epoch [16/100], Step [41/735], Loss: 0.0322
Epoch [16/100], Step [51/735], Loss: 0.0377
Epoch [16/100], Step [61/735], Loss: 0.0743
Epoch [16/100], Step [71/735], Loss: 0.0518
Epoch [16/100], Step [81/735], Loss: 0.0159
Epoch [16/100], Step [91/735], Loss: 0.0246
Epoch [16/100], Step [101/735], Loss: 0.0541
Epoch [16/100], Step [111/735], Loss: 0.0221
Epoch [16/100], Step [121/735], Loss: 0.0203
Epoch [16/100], Step [131/735], Loss: 0.0124
Epoch [16/100], Step [141/735], Loss: 0.0050
Epoch [16/100], Step [151/735], Loss: 0.0179
Epoch [16/100], Step [161/735], Loss: 0.0299
Epoch [16/100], Step [171/735], Loss: 0.0400
Epoch [16/100], Step [181/735], Loss: 0.0480
Epoch [16/100], Step [191/735], Loss: 0.0220
Epoch [16/100], Step [201/735], Loss: 0.0344
Epoch [16/100], Step [211/735], Loss: 0.0568
Epoch [16/100], Step [221/735], Loss: 0.0384
Epoch [16/100], Step [231/735], Loss: 0.0085
Epoch [16/100], Step [241/735], Loss: 0.0385
Epoch [16/100], Step [251/735], Loss: 0.0290
Epoch [16/100], Step [261/735], Loss: 0.0283
Epoch [16/100], Step [271/735], Loss: 0.0240
Epoch [16/100], Step [281/735], Loss: 0.0637
Epoch [16/100], Step [291/735], Loss: 0.0389
Epoch [16/100], Step [301/735], Loss: 0.0494
Epoch [16/100], Step [311/735], Loss: 0.0409
Epoch [16/100], Step [321/735], Loss: 0.0306
Epoch [16/100], Step [331/735], Loss: 0.0543
Epoch [16/100], Step [341/735], Loss: 0.0601
Epoch [16/100], Step [351/735], Loss: 0.0444
Epoch [16/100], Step [361/735], Loss: 0.0484
Epoch [16/100], Step [371/735], Loss: 0.0420
Epoch [16/100], Step [381/735], Loss: 0.0421
Epoch [16/100], Step [391/735], Loss: 0.0299
Epoch [16/100], Step [401/735], Loss: 0.0550
Epoch [16/100], Step [411/735], Loss: 0.0163
Epoch [16/100], Step [421/735], Loss: 0.0340
Epoch [16/100], Step [431/735], Loss: 0.0037
Epoch [16/100], Step [441/735], Loss: 0.0268
Epoch [16/100], Step [451/735], Loss: 0.0328
Epoch [16/100], Step [461/735], Loss: 0.0236
Epoch [16/100], Step [471/735], Loss: 0.0220
Epoch [16/100], Step [481/735], Loss: 0.0488
Epoch [16/100], Step [491/735], Loss: 0.0367
Epoch [16/100], Step [501/735], Loss: 0.0560
Epoch [16/100], Step [511/735], Loss: 0.0252
Epoch [16/100], Step [521/735], Loss: 0.0531
Epoch [16/100], Step [531/735], Loss: 0.0488
Epoch [16/100], Step [541/735], Loss: 0.0692
Epoch [16/100], Step [551/735], Loss: 0.0186
Epoch [16/100], Step [561/735], Loss: 0.0091
Epoch [16/100], Step [571/735], Loss: 0.0386
Epoch [16/100], Step [581/735], Loss: 0.0219
Epoch [16/100], Step [591/735], Loss: 0.0200
Epoch [16/100], Step [601/735], Loss: 0.0463
Epoch [16/100], Step [611/735], Loss: 0.0547
Epoch [16/100], Step [621/735], Loss: 0.0309
Epoch [16/100], Step [631/735], Loss: 0.0505
Epoch [16/100], Step [641/735], Loss: 0.0291
Epoch [16/100], Step [651/735], Loss: 0.0433
Epoch [16/100], Step [661/735], Loss: 0.0399
Epoch [16/100], Step [671/735], Loss: 0.0245
Epoch [16/100], Step [681/735], Loss: 0.0151
Epoch [16/100], Step [691/735], Loss: 0.0255
Epoch [16/100], Step [701/735], Loss: 0.0353
Epoch [16/100], Step [711/735], Loss: 0.0256
Epoch [16/100], Step [721/735], Loss: 0.0382
Epoch [16/100], Step [731/735], Loss: 0.0572
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8978,Val AUC: 0.9430,Val precision: 0.8069, Val recall: 0.8376, Val Loss: 0.0818
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 16 | Time taken: 2301.56s |
| Val CE loss: 0.08185 | Val MSE 0.89782 | Train Loss 0.03578 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 17
Training for epoch 17
Epoch [17/100], Step [1/735], Loss: 0.0644
Epoch [17/100], Step [11/735], Loss: 0.0368
Epoch [17/100], Step [21/735], Loss: 0.0407
Epoch [17/100], Step [31/735], Loss: 0.0272
Epoch [17/100], Step [41/735], Loss: 0.0119
Epoch [17/100], Step [51/735], Loss: 0.0114
Epoch [17/100], Step [61/735], Loss: 0.0196
Epoch [17/100], Step [71/735], Loss: 0.0471
Epoch [17/100], Step [81/735], Loss: 0.0137
Epoch [17/100], Step [91/735], Loss: 0.0220
Epoch [17/100], Step [101/735], Loss: 0.0137
Epoch [17/100], Step [111/735], Loss: 0.0357
Epoch [17/100], Step [121/735], Loss: 0.0580
Epoch [17/100], Step [131/735], Loss: 0.0462
Epoch [17/100], Step [141/735], Loss: 0.0333
Epoch [17/100], Step [151/735], Loss: 0.0384
Epoch [17/100], Step [161/735], Loss: 0.0418
Epoch [17/100], Step [171/735], Loss: 0.0095
Epoch [17/100], Step [181/735], Loss: 0.0345
Epoch [17/100], Step [191/735], Loss: 0.0237
Epoch [17/100], Step [201/735], Loss: 0.0429
Epoch [17/100], Step [211/735], Loss: 0.0127
Epoch [17/100], Step [221/735], Loss: 0.0343
Epoch [17/100], Step [231/735], Loss: 0.0649
Epoch [17/100], Step [241/735], Loss: 0.0302
Epoch [17/100], Step [251/735], Loss: 0.0337
Epoch [17/100], Step [261/735], Loss: 0.0491
Epoch [17/100], Step [271/735], Loss: 0.0660
Epoch [17/100], Step [281/735], Loss: 0.0271
Epoch [17/100], Step [291/735], Loss: 0.0484
Epoch [17/100], Step [301/735], Loss: 0.0355
Epoch [17/100], Step [311/735], Loss: 0.0090
Epoch [17/100], Step [321/735], Loss: 0.0329
Epoch [17/100], Step [331/735], Loss: 0.0320
Epoch [17/100], Step [341/735], Loss: 0.0331
Epoch [17/100], Step [351/735], Loss: 0.0580
Epoch [17/100], Step [361/735], Loss: 0.0211
Epoch [17/100], Step [371/735], Loss: 0.0285
Epoch [17/100], Step [381/735], Loss: 0.0141
Epoch [17/100], Step [391/735], Loss: 0.0554
Epoch [17/100], Step [401/735], Loss: 0.0043
Epoch [17/100], Step [411/735], Loss: 0.0516
Epoch [17/100], Step [421/735], Loss: 0.0438
Epoch [17/100], Step [431/735], Loss: 0.0287
Epoch [17/100], Step [441/735], Loss: 0.0304
Epoch [17/100], Step [451/735], Loss: 0.0060
Epoch [17/100], Step [461/735], Loss: 0.0239
Epoch [17/100], Step [471/735], Loss: 0.0714
Epoch [17/100], Step [481/735], Loss: 0.0183
Epoch [17/100], Step [491/735], Loss: 0.0272
Epoch [17/100], Step [501/735], Loss: 0.0339
Epoch [17/100], Step [511/735], Loss: 0.0132
Epoch [17/100], Step [521/735], Loss: 0.0167
Epoch [17/100], Step [531/735], Loss: 0.0153
Epoch [17/100], Step [541/735], Loss: 0.0268
Epoch [17/100], Step [551/735], Loss: 0.0385
Epoch [17/100], Step [561/735], Loss: 0.0383
Epoch [17/100], Step [571/735], Loss: 0.0279
Epoch [17/100], Step [581/735], Loss: 0.0197
Epoch [17/100], Step [591/735], Loss: 0.0270
Epoch [17/100], Step [601/735], Loss: 0.0757
Epoch [17/100], Step [611/735], Loss: 0.0427
Epoch [17/100], Step [621/735], Loss: 0.0920
Epoch [17/100], Step [631/735], Loss: 0.0277
Epoch [17/100], Step [641/735], Loss: 0.0389
Epoch [17/100], Step [651/735], Loss: 0.0160
Epoch [17/100], Step [661/735], Loss: 0.0594
Epoch [17/100], Step [671/735], Loss: 0.0316
Epoch [17/100], Step [681/735], Loss: 0.0167
Epoch [17/100], Step [691/735], Loss: 0.0282
Epoch [17/100], Step [701/735], Loss: 0.0220
Epoch [17/100], Step [711/735], Loss: 0.0151
Epoch [17/100], Step [721/735], Loss: 0.0444
Epoch [17/100], Step [731/735], Loss: 0.0105
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9065,Val AUC: 0.9465,Val precision: 0.8454, Val recall: 0.8173, Val Loss: 0.0758
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 17 | Time taken: 2274.12s |
| Val CE loss: 0.07585 | Val MSE 0.90648 | Train Loss 0.03245 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 18
Training for epoch 18
Epoch [18/100], Step [1/735], Loss: 0.0391
Epoch [18/100], Step [11/735], Loss: 0.0123
Epoch [18/100], Step [21/735], Loss: 0.0337
Epoch [18/100], Step [31/735], Loss: 0.0380
Epoch [18/100], Step [41/735], Loss: 0.0199
Epoch [18/100], Step [51/735], Loss: 0.0242
Epoch [18/100], Step [61/735], Loss: 0.0192
Epoch [18/100], Step [71/735], Loss: 0.0551
Epoch [18/100], Step [81/735], Loss: 0.0241
Epoch [18/100], Step [91/735], Loss: 0.0437
Epoch [18/100], Step [101/735], Loss: 0.0282
Epoch [18/100], Step [111/735], Loss: 0.0169
Epoch [18/100], Step [121/735], Loss: 0.0423
Epoch [18/100], Step [131/735], Loss: 0.0323
Epoch [18/100], Step [141/735], Loss: 0.0296
Epoch [18/100], Step [151/735], Loss: 0.0129
Epoch [18/100], Step [161/735], Loss: 0.0303
Epoch [18/100], Step [171/735], Loss: 0.0441
Epoch [18/100], Step [181/735], Loss: 0.0196
Epoch [18/100], Step [191/735], Loss: 0.0369
Epoch [18/100], Step [201/735], Loss: 0.0321
Epoch [18/100], Step [211/735], Loss: 0.0197
Epoch [18/100], Step [221/735], Loss: 0.0231
Epoch [18/100], Step [231/735], Loss: 0.0420
Epoch [18/100], Step [241/735], Loss: 0.0403
Epoch [18/100], Step [251/735], Loss: 0.0363
Epoch [18/100], Step [261/735], Loss: 0.0104
Epoch [18/100], Step [271/735], Loss: 0.0451
Epoch [18/100], Step [281/735], Loss: 0.0308
Epoch [18/100], Step [291/735], Loss: 0.0163
Epoch [18/100], Step [301/735], Loss: 0.0177
Epoch [18/100], Step [311/735], Loss: 0.0591
Epoch [18/100], Step [321/735], Loss: 0.0416
Epoch [18/100], Step [331/735], Loss: 0.0414
Epoch [18/100], Step [341/735], Loss: 0.0517
Epoch [18/100], Step [351/735], Loss: 0.0136
Epoch [18/100], Step [361/735], Loss: 0.0166
Epoch [18/100], Step [371/735], Loss: 0.0152
Epoch [18/100], Step [381/735], Loss: 0.0212
Epoch [18/100], Step [391/735], Loss: 0.0222
Epoch [18/100], Step [401/735], Loss: 0.0382
Epoch [18/100], Step [411/735], Loss: 0.0187
Epoch [18/100], Step [421/735], Loss: 0.0159
Epoch [18/100], Step [431/735], Loss: 0.0524
Epoch [18/100], Step [441/735], Loss: 0.0393
Epoch [18/100], Step [451/735], Loss: 0.0349
Epoch [18/100], Step [461/735], Loss: 0.0350
Epoch [18/100], Step [471/735], Loss: 0.0305
Epoch [18/100], Step [481/735], Loss: 0.0706
Epoch [18/100], Step [491/735], Loss: 0.1136
Epoch [18/100], Step [501/735], Loss: 0.0359
Epoch [18/100], Step [511/735], Loss: 0.0515
Epoch [18/100], Step [521/735], Loss: 0.0033
Epoch [18/100], Step [531/735], Loss: 0.0909
Epoch [18/100], Step [541/735], Loss: 0.0216
Epoch [18/100], Step [551/735], Loss: 0.0596
Epoch [18/100], Step [561/735], Loss: 0.0363
Epoch [18/100], Step [571/735], Loss: 0.0206
Epoch [18/100], Step [581/735], Loss: 0.0251
Epoch [18/100], Step [591/735], Loss: 0.0487
Epoch [18/100], Step [601/735], Loss: 0.0122
Epoch [18/100], Step [611/735], Loss: 0.0186
Epoch [18/100], Step [621/735], Loss: 0.0396
Epoch [18/100], Step [631/735], Loss: 0.0704
Epoch [18/100], Step [641/735], Loss: 0.0446
Epoch [18/100], Step [651/735], Loss: 0.0224
Epoch [18/100], Step [661/735], Loss: 0.0095
Epoch [18/100], Step [671/735], Loss: 0.0208
Epoch [18/100], Step [681/735], Loss: 0.0020
Epoch [18/100], Step [691/735], Loss: 0.0262
Epoch [18/100], Step [701/735], Loss: 0.0532
Epoch [18/100], Step [711/735], Loss: 0.0287
Epoch [18/100], Step [721/735], Loss: 0.0260
Epoch [18/100], Step [731/735], Loss: 0.0643
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8992,Val AUC: 0.9462,Val precision: 0.8060, Val recall: 0.8456, Val Loss: 0.0812
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 18 | Time taken: 2261.35s |
| Val CE loss: 0.08124 | Val MSE 0.89920 | Train Loss 0.03094 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 19
Training for epoch 19
Epoch [19/100], Step [1/735], Loss: 0.0234
Epoch [19/100], Step [11/735], Loss: 0.0203
Epoch [19/100], Step [21/735], Loss: 0.0116
Epoch [19/100], Step [31/735], Loss: 0.0284
Epoch [19/100], Step [41/735], Loss: 0.0156
Epoch [19/100], Step [51/735], Loss: 0.0249
Epoch [19/100], Step [61/735], Loss: 0.0253
Epoch [19/100], Step [71/735], Loss: 0.0461
Epoch [19/100], Step [81/735], Loss: 0.0269
Epoch [19/100], Step [91/735], Loss: 0.0219
Epoch [19/100], Step [101/735], Loss: 0.0184
Epoch [19/100], Step [111/735], Loss: 0.0392
Epoch [19/100], Step [121/735], Loss: 0.0214
Epoch [19/100], Step [131/735], Loss: 0.0154
Epoch [19/100], Step [141/735], Loss: 0.0188
Epoch [19/100], Step [151/735], Loss: 0.0243
Epoch [19/100], Step [161/735], Loss: 0.0337
Epoch [19/100], Step [171/735], Loss: 0.0322
Epoch [19/100], Step [181/735], Loss: 0.0417
Epoch [19/100], Step [191/735], Loss: 0.0130
Epoch [19/100], Step [201/735], Loss: 0.0292
Epoch [19/100], Step [211/735], Loss: 0.0115
Epoch [19/100], Step [221/735], Loss: 0.0144
Epoch [19/100], Step [231/735], Loss: 0.0134
Epoch [19/100], Step [241/735], Loss: 0.0112
Epoch [19/100], Step [251/735], Loss: 0.0147
Epoch [19/100], Step [261/735], Loss: 0.0292
Epoch [19/100], Step [271/735], Loss: 0.0219
Epoch [19/100], Step [281/735], Loss: 0.0628
Epoch [19/100], Step [291/735], Loss: 0.0044
Epoch [19/100], Step [301/735], Loss: 0.0122
Epoch [19/100], Step [311/735], Loss: 0.0203
Epoch [19/100], Step [321/735], Loss: 0.0511
Epoch [19/100], Step [331/735], Loss: 0.0115
Epoch [19/100], Step [341/735], Loss: 0.0271
Epoch [19/100], Step [351/735], Loss: 0.0223
Epoch [19/100], Step [361/735], Loss: 0.0087
Epoch [19/100], Step [371/735], Loss: 0.0513
Epoch [19/100], Step [381/735], Loss: 0.0295
Epoch [19/100], Step [391/735], Loss: 0.0211
Epoch [19/100], Step [401/735], Loss: 0.0671
Epoch [19/100], Step [411/735], Loss: 0.0048
Epoch [19/100], Step [421/735], Loss: 0.0271
Epoch [19/100], Step [431/735], Loss: 0.0305
Epoch [19/100], Step [441/735], Loss: 0.0540
Epoch [19/100], Step [451/735], Loss: 0.0113
Epoch [19/100], Step [461/735], Loss: 0.0477
Epoch [19/100], Step [471/735], Loss: 0.0141
Epoch [19/100], Step [481/735], Loss: 0.0111
Epoch [19/100], Step [491/735], Loss: 0.0187
Epoch [19/100], Step [501/735], Loss: 0.0043
Epoch [19/100], Step [511/735], Loss: 0.0299
Epoch [19/100], Step [521/735], Loss: 0.0234
Epoch [19/100], Step [531/735], Loss: 0.0241
Epoch [19/100], Step [541/735], Loss: 0.0101
Epoch [19/100], Step [551/735], Loss: 0.0163
Epoch [19/100], Step [561/735], Loss: 0.0456
Epoch [19/100], Step [571/735], Loss: 0.0193
Epoch [19/100], Step [581/735], Loss: 0.0223
Epoch [19/100], Step [591/735], Loss: 0.0242
Epoch [19/100], Step [601/735], Loss: 0.0456
Epoch [19/100], Step [611/735], Loss: 0.0349
Epoch [19/100], Step [621/735], Loss: 0.0600
Epoch [19/100], Step [631/735], Loss: 0.0125
Epoch [19/100], Step [641/735], Loss: 0.0109
Epoch [19/100], Step [651/735], Loss: 0.0331
Epoch [19/100], Step [661/735], Loss: 0.0296
Epoch [19/100], Step [671/735], Loss: 0.0395
Epoch [19/100], Step [681/735], Loss: 0.0024
Epoch [19/100], Step [691/735], Loss: 0.0286
Epoch [19/100], Step [701/735], Loss: 0.0409
Epoch [19/100], Step [711/735], Loss: 0.0153
Epoch [19/100], Step [721/735], Loss: 0.0329
Epoch [19/100], Step [731/735], Loss: 0.0361
Training complete
Val performance:
Evaluating
Val Accuracy: 0.8930,Val AUC: 0.9394,Val precision: 0.8198, Val recall: 0.7946, Val Loss: 0.0836
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 19 | Time taken: 2227.31s |
| Val CE loss: 0.08355 | Val MSE 0.89297 | Train Loss 0.02892 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 20
Training for epoch 20
Epoch [20/100], Step [1/735], Loss: 0.0208
Epoch [20/100], Step [11/735], Loss: 0.0032
Epoch [20/100], Step [21/735], Loss: 0.0609
Epoch [20/100], Step [31/735], Loss: 0.0257
Epoch [20/100], Step [41/735], Loss: 0.0295
Epoch [20/100], Step [51/735], Loss: 0.0048
Epoch [20/100], Step [61/735], Loss: 0.0379
Epoch [20/100], Step [71/735], Loss: 0.0129
Epoch [20/100], Step [81/735], Loss: 0.0078
Epoch [20/100], Step [91/735], Loss: 0.0271
Epoch [20/100], Step [101/735], Loss: 0.0412
Epoch [20/100], Step [111/735], Loss: 0.0157
Epoch [20/100], Step [121/735], Loss: 0.0793
Epoch [20/100], Step [131/735], Loss: 0.0477
Epoch [20/100], Step [141/735], Loss: 0.0105
Epoch [20/100], Step [151/735], Loss: 0.0548
Epoch [20/100], Step [161/735], Loss: 0.0305
Epoch [20/100], Step [171/735], Loss: 0.0584
Epoch [20/100], Step [181/735], Loss: 0.0268
Epoch [20/100], Step [191/735], Loss: 0.0411
Epoch [20/100], Step [201/735], Loss: 0.0465
Epoch [20/100], Step [211/735], Loss: 0.0170
Epoch [20/100], Step [221/735], Loss: 0.0303
Epoch [20/100], Step [231/735], Loss: 0.0424
Epoch [20/100], Step [241/735], Loss: 0.0142
Epoch [20/100], Step [251/735], Loss: 0.0300
Epoch [20/100], Step [261/735], Loss: 0.0070
Epoch [20/100], Step [271/735], Loss: 0.0099
Epoch [20/100], Step [281/735], Loss: 0.0252
Epoch [20/100], Step [291/735], Loss: 0.0374
Epoch [20/100], Step [301/735], Loss: 0.0151
Epoch [20/100], Step [311/735], Loss: 0.0208
Epoch [20/100], Step [321/735], Loss: 0.0104
Epoch [20/100], Step [331/735], Loss: 0.0330
Epoch [20/100], Step [341/735], Loss: 0.0248
Epoch [20/100], Step [351/735], Loss: 0.0181
Epoch [20/100], Step [361/735], Loss: 0.0461
Epoch [20/100], Step [371/735], Loss: 0.0320
Epoch [20/100], Step [381/735], Loss: 0.0067
Epoch [20/100], Step [391/735], Loss: 0.0170
Epoch [20/100], Step [401/735], Loss: 0.0531
Epoch [20/100], Step [411/735], Loss: 0.0260
Epoch [20/100], Step [421/735], Loss: 0.0178
Epoch [20/100], Step [431/735], Loss: 0.0141
Epoch [20/100], Step [441/735], Loss: 0.0289
Epoch [20/100], Step [451/735], Loss: 0.0369
Epoch [20/100], Step [461/735], Loss: 0.0213
Epoch [20/100], Step [471/735], Loss: 0.0228
Epoch [20/100], Step [481/735], Loss: 0.0207
Epoch [20/100], Step [491/735], Loss: 0.0293
Epoch [20/100], Step [501/735], Loss: 0.0186
Epoch [20/100], Step [511/735], Loss: 0.0227
Epoch [20/100], Step [521/735], Loss: 0.0368
Epoch [20/100], Step [531/735], Loss: 0.0134
Epoch [20/100], Step [541/735], Loss: 0.0091
Epoch [20/100], Step [551/735], Loss: 0.0545
Epoch [20/100], Step [561/735], Loss: 0.0511
Epoch [20/100], Step [571/735], Loss: 0.0576
Epoch [20/100], Step [581/735], Loss: 0.0254
Epoch [20/100], Step [591/735], Loss: 0.0072
Epoch [20/100], Step [601/735], Loss: 0.0241
Epoch [20/100], Step [611/735], Loss: 0.0231
Epoch [20/100], Step [621/735], Loss: 0.0089
Epoch [20/100], Step [631/735], Loss: 0.0066
Epoch [20/100], Step [641/735], Loss: 0.0567
Epoch [20/100], Step [651/735], Loss: 0.0500
Epoch [20/100], Step [661/735], Loss: 0.0242
Epoch [20/100], Step [671/735], Loss: 0.0468
Epoch [20/100], Step [681/735], Loss: 0.0261
Epoch [20/100], Step [691/735], Loss: 0.0162
Epoch [20/100], Step [701/735], Loss: 0.0166
Epoch [20/100], Step [711/735], Loss: 0.0320
Epoch [20/100], Step [721/735], Loss: 0.0167
Epoch [20/100], Step [731/735], Loss: 0.0453
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9051,Val AUC: 0.9479,Val precision: 0.8220, Val recall: 0.8462, Val Loss: 0.0777
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 20 | Time taken: 2231.60s |
| Val CE loss: 0.07769 | Val MSE 0.90509 | Train Loss 0.02632 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 21
Training for epoch 21
Epoch [21/100], Step [1/735], Loss: 0.0244
Epoch [21/100], Step [11/735], Loss: 0.0072
Epoch [21/100], Step [21/735], Loss: 0.0035
Epoch [21/100], Step [31/735], Loss: 0.0535
Epoch [21/100], Step [41/735], Loss: 0.0345
Epoch [21/100], Step [51/735], Loss: 0.0247
Epoch [21/100], Step [61/735], Loss: 0.0258
Epoch [21/100], Step [71/735], Loss: 0.0373
Epoch [21/100], Step [81/735], Loss: 0.0219
Epoch [21/100], Step [91/735], Loss: 0.0171
Epoch [21/100], Step [101/735], Loss: 0.0125
Epoch [21/100], Step [111/735], Loss: 0.0316
Epoch [21/100], Step [121/735], Loss: 0.0638
Epoch [21/100], Step [131/735], Loss: 0.0324
Epoch [21/100], Step [141/735], Loss: 0.0229
Epoch [21/100], Step [151/735], Loss: 0.0291
Epoch [21/100], Step [161/735], Loss: 0.0409
Epoch [21/100], Step [171/735], Loss: 0.0365
Epoch [21/100], Step [181/735], Loss: 0.0103
Epoch [21/100], Step [191/735], Loss: 0.0072
Epoch [21/100], Step [201/735], Loss: 0.0110
Epoch [21/100], Step [211/735], Loss: 0.0255
Epoch [21/100], Step [221/735], Loss: 0.0323
Epoch [21/100], Step [231/735], Loss: 0.0762
Epoch [21/100], Step [241/735], Loss: 0.0395
Epoch [21/100], Step [251/735], Loss: 0.0182
Epoch [21/100], Step [261/735], Loss: 0.0245
Epoch [21/100], Step [271/735], Loss: 0.0443
Epoch [21/100], Step [281/735], Loss: 0.0132
Epoch [21/100], Step [291/735], Loss: 0.0364
Epoch [21/100], Step [301/735], Loss: 0.0344
Epoch [21/100], Step [311/735], Loss: 0.0258
Epoch [21/100], Step [321/735], Loss: 0.0545
Epoch [21/100], Step [331/735], Loss: 0.0186
Epoch [21/100], Step [341/735], Loss: 0.0360
Epoch [21/100], Step [351/735], Loss: 0.0147
Epoch [21/100], Step [361/735], Loss: 0.0043
Epoch [21/100], Step [371/735], Loss: 0.0067
Epoch [21/100], Step [381/735], Loss: 0.0202
Epoch [21/100], Step [391/735], Loss: 0.0224
Epoch [21/100], Step [401/735], Loss: 0.0381
Epoch [21/100], Step [411/735], Loss: 0.0272
Epoch [21/100], Step [421/735], Loss: 0.0186
Epoch [21/100], Step [431/735], Loss: 0.0709
Epoch [21/100], Step [441/735], Loss: 0.0352
Epoch [21/100], Step [451/735], Loss: 0.0228
Epoch [21/100], Step [461/735], Loss: 0.0323
Epoch [21/100], Step [471/735], Loss: 0.0152
Epoch [21/100], Step [481/735], Loss: 0.0467
Epoch [21/100], Step [491/735], Loss: 0.0368
Epoch [21/100], Step [501/735], Loss: 0.0717
Epoch [21/100], Step [511/735], Loss: 0.0116
Epoch [21/100], Step [521/735], Loss: 0.0366
Epoch [21/100], Step [531/735], Loss: 0.0406
Epoch [21/100], Step [541/735], Loss: 0.0237
Epoch [21/100], Step [551/735], Loss: 0.0241
Epoch [21/100], Step [561/735], Loss: 0.0087
Epoch [21/100], Step [571/735], Loss: 0.0056
Epoch [21/100], Step [581/735], Loss: 0.0350
Epoch [21/100], Step [591/735], Loss: 0.0312
Epoch [21/100], Step [601/735], Loss: 0.0031
Epoch [21/100], Step [611/735], Loss: 0.0562
Epoch [21/100], Step [621/735], Loss: 0.0155
Epoch [21/100], Step [631/735], Loss: 0.0125
Epoch [21/100], Step [641/735], Loss: 0.0194
Epoch [21/100], Step [651/735], Loss: 0.0240
Epoch [21/100], Step [661/735], Loss: 0.0171
Epoch [21/100], Step [671/735], Loss: 0.0504
Epoch [21/100], Step [681/735], Loss: 0.0301
Epoch [21/100], Step [691/735], Loss: 0.0318
Epoch [21/100], Step [701/735], Loss: 0.0394
Epoch [21/100], Step [711/735], Loss: 0.0032
Epoch [21/100], Step [721/735], Loss: 0.0476
Epoch [21/100], Step [731/735], Loss: 0.0103
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9023,Val AUC: 0.9447,Val precision: 0.8382, Val recall: 0.8093, Val Loss: 0.0782
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 21 | Time taken: 2220.33s |
| Val CE loss: 0.07821 | Val MSE 0.90232 | Train Loss 0.02734 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 22
Training for epoch 22
Epoch [22/100], Step [1/735], Loss: 0.0150
Epoch [22/100], Step [11/735], Loss: 0.0283
Epoch [22/100], Step [21/735], Loss: 0.0391
Epoch [22/100], Step [31/735], Loss: 0.0094
Epoch [22/100], Step [41/735], Loss: 0.0270
Epoch [22/100], Step [51/735], Loss: 0.0255
Epoch [22/100], Step [61/735], Loss: 0.0342
Epoch [22/100], Step [71/735], Loss: 0.0171
Epoch [22/100], Step [81/735], Loss: 0.0009
Epoch [22/100], Step [91/735], Loss: 0.0120
Epoch [22/100], Step [101/735], Loss: 0.0271
Epoch [22/100], Step [111/735], Loss: 0.0129
Epoch [22/100], Step [121/735], Loss: 0.0381
Epoch [22/100], Step [131/735], Loss: 0.0490
Epoch [22/100], Step [141/735], Loss: 0.0156
Epoch [22/100], Step [151/735], Loss: 0.0100
Epoch [22/100], Step [161/735], Loss: 0.0244
Epoch [22/100], Step [171/735], Loss: 0.0326
Epoch [22/100], Step [181/735], Loss: 0.0196
Epoch [22/100], Step [191/735], Loss: 0.0327
Epoch [22/100], Step [201/735], Loss: 0.0246
Epoch [22/100], Step [211/735], Loss: 0.0113
Epoch [22/100], Step [221/735], Loss: 0.0286
Epoch [22/100], Step [231/735], Loss: 0.0042
Epoch [22/100], Step [241/735], Loss: 0.0143
Epoch [22/100], Step [251/735], Loss: 0.0124
Epoch [22/100], Step [261/735], Loss: 0.0412
Epoch [22/100], Step [271/735], Loss: 0.0181
Epoch [22/100], Step [281/735], Loss: 0.0027
Epoch [22/100], Step [291/735], Loss: 0.0075
Epoch [22/100], Step [301/735], Loss: 0.0176
Epoch [22/100], Step [311/735], Loss: 0.0150
Epoch [22/100], Step [321/735], Loss: 0.0060
Epoch [22/100], Step [331/735], Loss: 0.0390
Epoch [22/100], Step [341/735], Loss: 0.0169
Epoch [22/100], Step [351/735], Loss: 0.0223
Epoch [22/100], Step [361/735], Loss: 0.0174
Epoch [22/100], Step [371/735], Loss: 0.0411
Epoch [22/100], Step [381/735], Loss: 0.0321
Epoch [22/100], Step [391/735], Loss: 0.0101
Epoch [22/100], Step [401/735], Loss: 0.0307
Epoch [22/100], Step [411/735], Loss: 0.0189
Epoch [22/100], Step [421/735], Loss: 0.0347
Epoch [22/100], Step [431/735], Loss: 0.0056
Epoch [22/100], Step [441/735], Loss: 0.0269
Epoch [22/100], Step [451/735], Loss: 0.0738
Epoch [22/100], Step [461/735], Loss: 0.0423
Epoch [22/100], Step [471/735], Loss: 0.0393
Epoch [22/100], Step [481/735], Loss: 0.0120
Epoch [22/100], Step [491/735], Loss: 0.0311
Epoch [22/100], Step [501/735], Loss: 0.0341
Epoch [22/100], Step [511/735], Loss: 0.0106
Epoch [22/100], Step [521/735], Loss: 0.0376
Epoch [22/100], Step [531/735], Loss: 0.0173
Epoch [22/100], Step [541/735], Loss: 0.0324
Epoch [22/100], Step [551/735], Loss: 0.0374
Epoch [22/100], Step [561/735], Loss: 0.0098
Epoch [22/100], Step [571/735], Loss: 0.0557
Epoch [22/100], Step [581/735], Loss: 0.0735
Epoch [22/100], Step [591/735], Loss: 0.0269
Epoch [22/100], Step [601/735], Loss: 0.0493
Epoch [22/100], Step [611/735], Loss: 0.0433
Epoch [22/100], Step [621/735], Loss: 0.0266
Epoch [22/100], Step [631/735], Loss: 0.0249
Epoch [22/100], Step [641/735], Loss: 0.0071
Epoch [22/100], Step [651/735], Loss: 0.0295
Epoch [22/100], Step [661/735], Loss: 0.0239
Epoch [22/100], Step [671/735], Loss: 0.0339
Epoch [22/100], Step [681/735], Loss: 0.0258
Epoch [22/100], Step [691/735], Loss: 0.0385
Epoch [22/100], Step [701/735], Loss: 0.0262
Epoch [22/100], Step [711/735], Loss: 0.0123
Epoch [22/100], Step [721/735], Loss: 0.0193
Epoch [22/100], Step [731/735], Loss: 0.0278
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9030,Val AUC: 0.9487,Val precision: 0.8207, Val recall: 0.8389, Val Loss: 0.0794
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 22 | Time taken: 2234.50s |
| Val CE loss: 0.07941 | Val MSE 0.90301 | Train Loss 0.02532 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 23
Training for epoch 23
Epoch [23/100], Step [1/735], Loss: 0.0067
Epoch [23/100], Step [11/735], Loss: 0.0254
Epoch [23/100], Step [21/735], Loss: 0.0246
Epoch [23/100], Step [31/735], Loss: 0.0328
Epoch [23/100], Step [41/735], Loss: 0.0120
Epoch [23/100], Step [51/735], Loss: 0.0170
Epoch [23/100], Step [61/735], Loss: 0.0156
Epoch [23/100], Step [71/735], Loss: 0.0140
Epoch [23/100], Step [81/735], Loss: 0.0299
Epoch [23/100], Step [91/735], Loss: 0.0202
Epoch [23/100], Step [101/735], Loss: 0.0240
Epoch [23/100], Step [111/735], Loss: 0.0272
Epoch [23/100], Step [121/735], Loss: 0.0041
Epoch [23/100], Step [131/735], Loss: 0.0089
Epoch [23/100], Step [141/735], Loss: 0.0177
Epoch [23/100], Step [151/735], Loss: 0.0016
Epoch [23/100], Step [161/735], Loss: 0.0111
Epoch [23/100], Step [171/735], Loss: 0.0157
Epoch [23/100], Step [181/735], Loss: 0.0181
Epoch [23/100], Step [191/735], Loss: 0.0193
Epoch [23/100], Step [201/735], Loss: 0.0438
Epoch [23/100], Step [211/735], Loss: 0.0296
Epoch [23/100], Step [221/735], Loss: 0.0276
Epoch [23/100], Step [231/735], Loss: 0.0127
Epoch [23/100], Step [241/735], Loss: 0.0389
Epoch [23/100], Step [251/735], Loss: 0.0059
Epoch [23/100], Step [261/735], Loss: 0.0281
Epoch [23/100], Step [271/735], Loss: 0.0283
Epoch [23/100], Step [281/735], Loss: 0.0128
Epoch [23/100], Step [291/735], Loss: 0.0200
Epoch [23/100], Step [301/735], Loss: 0.0253
Epoch [23/100], Step [311/735], Loss: 0.0058
Epoch [23/100], Step [321/735], Loss: 0.0386
Epoch [23/100], Step [331/735], Loss: 0.0294
Epoch [23/100], Step [341/735], Loss: 0.0032
Epoch [23/100], Step [351/735], Loss: 0.0462
Epoch [23/100], Step [361/735], Loss: 0.0201
Epoch [23/100], Step [371/735], Loss: 0.0247
Epoch [23/100], Step [381/735], Loss: 0.0204
Epoch [23/100], Step [391/735], Loss: 0.0157
Epoch [23/100], Step [401/735], Loss: 0.0077
Epoch [23/100], Step [411/735], Loss: 0.0134
Epoch [23/100], Step [421/735], Loss: 0.0273
Epoch [23/100], Step [431/735], Loss: 0.0428
Epoch [23/100], Step [441/735], Loss: 0.0293
Epoch [23/100], Step [451/735], Loss: 0.0222
Epoch [23/100], Step [461/735], Loss: 0.0168
Epoch [23/100], Step [471/735], Loss: 0.0151
Epoch [23/100], Step [481/735], Loss: 0.0174
Epoch [23/100], Step [491/735], Loss: 0.0058
Epoch [23/100], Step [501/735], Loss: 0.0144
Epoch [23/100], Step [511/735], Loss: 0.0324
Epoch [23/100], Step [521/735], Loss: 0.0034
Epoch [23/100], Step [531/735], Loss: 0.0096
Epoch [23/100], Step [541/735], Loss: 0.0213
Epoch [23/100], Step [551/735], Loss: 0.0252
Epoch [23/100], Step [561/735], Loss: 0.0011
Epoch [23/100], Step [571/735], Loss: 0.0146
Epoch [23/100], Step [581/735], Loss: 0.0630
Epoch [23/100], Step [591/735], Loss: 0.0485
Epoch [23/100], Step [601/735], Loss: 0.0577
Epoch [23/100], Step [611/735], Loss: 0.0391
Epoch [23/100], Step [621/735], Loss: 0.0121
Epoch [23/100], Step [631/735], Loss: 0.0047
Epoch [23/100], Step [641/735], Loss: 0.0283
Epoch [23/100], Step [651/735], Loss: 0.0296
Epoch [23/100], Step [661/735], Loss: 0.0494
Epoch [23/100], Step [671/735], Loss: 0.0156
Epoch [23/100], Step [681/735], Loss: 0.0390
Epoch [23/100], Step [691/735], Loss: 0.0147
Epoch [23/100], Step [701/735], Loss: 0.0233
Epoch [23/100], Step [711/735], Loss: 0.0130
Epoch [23/100], Step [721/735], Loss: 0.0147
Epoch [23/100], Step [731/735], Loss: 0.0237
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9044,Val AUC: 0.9476,Val precision: 0.8299, Val recall: 0.8309, Val Loss: 0.0808
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 23 | Time taken: 2214.65s |
| Val CE loss: 0.08078 | Val MSE 0.90440 | Train Loss 0.02252 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 24
Training for epoch 24
Epoch [24/100], Step [1/735], Loss: 0.0267
Epoch [24/100], Step [11/735], Loss: 0.0449
Epoch [24/100], Step [21/735], Loss: 0.0132
Epoch [24/100], Step [31/735], Loss: 0.0049
Epoch [24/100], Step [41/735], Loss: 0.0066
Epoch [24/100], Step [51/735], Loss: 0.0263
Epoch [24/100], Step [61/735], Loss: 0.0244
Epoch [24/100], Step [71/735], Loss: 0.0154
Epoch [24/100], Step [81/735], Loss: 0.0501
Epoch [24/100], Step [91/735], Loss: 0.0081
Epoch [24/100], Step [101/735], Loss: 0.0256
Epoch [24/100], Step [111/735], Loss: 0.0251
Epoch [24/100], Step [121/735], Loss: 0.0152
Epoch [24/100], Step [131/735], Loss: 0.0414
Epoch [24/100], Step [141/735], Loss: 0.0517
Epoch [24/100], Step [151/735], Loss: 0.0268
Epoch [24/100], Step [161/735], Loss: 0.0136
Epoch [24/100], Step [171/735], Loss: 0.0166
Epoch [24/100], Step [181/735], Loss: 0.0294
Epoch [24/100], Step [191/735], Loss: 0.0334
Epoch [24/100], Step [201/735], Loss: 0.0463
Epoch [24/100], Step [211/735], Loss: 0.0436
Epoch [24/100], Step [221/735], Loss: 0.0090
Epoch [24/100], Step [231/735], Loss: 0.0356
Epoch [24/100], Step [241/735], Loss: 0.0222
Epoch [24/100], Step [251/735], Loss: 0.0566
Epoch [24/100], Step [261/735], Loss: 0.0143
Epoch [24/100], Step [271/735], Loss: 0.0240
Epoch [24/100], Step [281/735], Loss: 0.0019
Epoch [24/100], Step [291/735], Loss: 0.0311
Epoch [24/100], Step [301/735], Loss: 0.0125
Epoch [24/100], Step [311/735], Loss: 0.0326
Epoch [24/100], Step [321/735], Loss: 0.0206
Epoch [24/100], Step [331/735], Loss: 0.0367
Epoch [24/100], Step [341/735], Loss: 0.0251
Epoch [24/100], Step [351/735], Loss: 0.0484
Epoch [24/100], Step [361/735], Loss: 0.0221
Epoch [24/100], Step [371/735], Loss: 0.0276
Epoch [24/100], Step [381/735], Loss: 0.0404
Epoch [24/100], Step [391/735], Loss: 0.0194
Epoch [24/100], Step [401/735], Loss: 0.0169
Epoch [24/100], Step [411/735], Loss: 0.0129
Epoch [24/100], Step [421/735], Loss: 0.0106
Epoch [24/100], Step [431/735], Loss: 0.0236
Epoch [24/100], Step [441/735], Loss: 0.0420
Epoch [24/100], Step [451/735], Loss: 0.0262
Epoch [24/100], Step [461/735], Loss: 0.0452
Epoch [24/100], Step [471/735], Loss: 0.0191
Epoch [24/100], Step [481/735], Loss: 0.0164
Epoch [24/100], Step [491/735], Loss: 0.0029
Epoch [24/100], Step [501/735], Loss: 0.0345
Epoch [24/100], Step [511/735], Loss: 0.0015
Epoch [24/100], Step [521/735], Loss: 0.0113
Epoch [24/100], Step [531/735], Loss: 0.0279
Epoch [24/100], Step [541/735], Loss: 0.0333
Epoch [24/100], Step [551/735], Loss: 0.0234
Epoch [24/100], Step [561/735], Loss: 0.0020
Epoch [24/100], Step [571/735], Loss: 0.0245
Epoch [24/100], Step [581/735], Loss: 0.0329
Epoch [24/100], Step [591/735], Loss: 0.0250
Epoch [24/100], Step [601/735], Loss: 0.0187
Epoch [24/100], Step [611/735], Loss: 0.0143
Epoch [24/100], Step [621/735], Loss: 0.0042
Epoch [24/100], Step [631/735], Loss: 0.0327
Epoch [24/100], Step [641/735], Loss: 0.0344
Epoch [24/100], Step [651/735], Loss: 0.0258
Epoch [24/100], Step [661/735], Loss: 0.0272
Epoch [24/100], Step [671/735], Loss: 0.0375
Epoch [24/100], Step [681/735], Loss: 0.0330
Epoch [24/100], Step [691/735], Loss: 0.0415
Epoch [24/100], Step [701/735], Loss: 0.0273
Epoch [24/100], Step [711/735], Loss: 0.0442
Epoch [24/100], Step [721/735], Loss: 0.0216
Epoch [24/100], Step [731/735], Loss: 0.0065
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9004,Val AUC: 0.9475,Val precision: 0.8071, Val recall: 0.8493, Val Loss: 0.0825
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 24 | Time taken: 2209.37s |
| Val CE loss: 0.08255 | Val MSE 0.90042 | Train Loss 0.02150 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 25
Training for epoch 25
Epoch [25/100], Step [1/735], Loss: 0.0167
Epoch [25/100], Step [11/735], Loss: 0.0316
Epoch [25/100], Step [21/735], Loss: 0.0186
Epoch [25/100], Step [31/735], Loss: 0.0207
Epoch [25/100], Step [41/735], Loss: 0.0140
Epoch [25/100], Step [51/735], Loss: 0.0275
Epoch [25/100], Step [61/735], Loss: 0.0281
Epoch [25/100], Step [71/735], Loss: 0.0078
Epoch [25/100], Step [81/735], Loss: 0.0406
Epoch [25/100], Step [91/735], Loss: 0.0715
Epoch [25/100], Step [101/735], Loss: 0.0552
Epoch [25/100], Step [111/735], Loss: 0.0061
Epoch [25/100], Step [121/735], Loss: 0.0018
Epoch [25/100], Step [131/735], Loss: 0.0100
Epoch [25/100], Step [141/735], Loss: 0.0156
Epoch [25/100], Step [151/735], Loss: 0.0022
Epoch [25/100], Step [161/735], Loss: 0.0244
Epoch [25/100], Step [171/735], Loss: 0.0303
Epoch [25/100], Step [181/735], Loss: 0.0344
Epoch [25/100], Step [191/735], Loss: 0.0348
Epoch [25/100], Step [201/735], Loss: 0.0058
Epoch [25/100], Step [211/735], Loss: 0.0298
Epoch [25/100], Step [221/735], Loss: 0.0215
Epoch [25/100], Step [231/735], Loss: 0.0298
Epoch [25/100], Step [241/735], Loss: 0.0013
Epoch [25/100], Step [251/735], Loss: 0.0208
Epoch [25/100], Step [261/735], Loss: 0.0015
Epoch [25/100], Step [271/735], Loss: 0.0099
Epoch [25/100], Step [281/735], Loss: 0.0288
Epoch [25/100], Step [291/735], Loss: 0.0152
Epoch [25/100], Step [301/735], Loss: 0.0300
Epoch [25/100], Step [311/735], Loss: 0.0129
Epoch [25/100], Step [321/735], Loss: 0.0304
Epoch [25/100], Step [331/735], Loss: 0.0256
Epoch [25/100], Step [341/735], Loss: 0.0180
Epoch [25/100], Step [351/735], Loss: 0.0050
Epoch [25/100], Step [361/735], Loss: 0.0372
Epoch [25/100], Step [371/735], Loss: 0.0653
Epoch [25/100], Step [381/735], Loss: 0.0011
Epoch [25/100], Step [391/735], Loss: 0.0184
Epoch [25/100], Step [401/735], Loss: 0.0085
Epoch [25/100], Step [411/735], Loss: 0.0063
Epoch [25/100], Step [421/735], Loss: 0.0174
Epoch [25/100], Step [431/735], Loss: 0.0133
Epoch [25/100], Step [441/735], Loss: 0.0108
Epoch [25/100], Step [451/735], Loss: 0.0131
Epoch [25/100], Step [461/735], Loss: 0.0044
Epoch [25/100], Step [471/735], Loss: 0.0600
Epoch [25/100], Step [481/735], Loss: 0.0293
Epoch [25/100], Step [491/735], Loss: 0.0078
Epoch [25/100], Step [501/735], Loss: 0.0271
Epoch [25/100], Step [511/735], Loss: 0.0282
Epoch [25/100], Step [521/735], Loss: 0.0053
Epoch [25/100], Step [531/735], Loss: 0.0078
Epoch [25/100], Step [541/735], Loss: 0.0224
Epoch [25/100], Step [551/735], Loss: 0.0003
Epoch [25/100], Step [561/735], Loss: 0.0292
Epoch [25/100], Step [571/735], Loss: 0.0317
Epoch [25/100], Step [581/735], Loss: 0.0036
Epoch [25/100], Step [591/735], Loss: 0.0037
Epoch [25/100], Step [601/735], Loss: 0.0291
Epoch [25/100], Step [611/735], Loss: 0.0113
Epoch [25/100], Step [621/735], Loss: 0.0762
Epoch [25/100], Step [631/735], Loss: 0.0067
Epoch [25/100], Step [641/735], Loss: 0.0314
Epoch [25/100], Step [651/735], Loss: 0.0107
Epoch [25/100], Step [661/735], Loss: 0.0020
Epoch [25/100], Step [671/735], Loss: 0.0007
Epoch [25/100], Step [681/735], Loss: 0.0201
Epoch [25/100], Step [691/735], Loss: 0.0287
Epoch [25/100], Step [701/735], Loss: 0.0027
Epoch [25/100], Step [711/735], Loss: 0.0047
Epoch [25/100], Step [721/735], Loss: 0.0076
Epoch [25/100], Step [731/735], Loss: 0.0171
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9047,Val AUC: 0.9463,Val precision: 0.8367, Val recall: 0.8223, Val Loss: 0.0784
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 25 | Time taken: 2231.87s |
| Val CE loss: 0.07843 | Val MSE 0.90475 | Train Loss 0.02101 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 26
Training for epoch 26
Epoch [26/100], Step [1/735], Loss: 0.0164
Epoch [26/100], Step [11/735], Loss: 0.0220
Epoch [26/100], Step [21/735], Loss: 0.0647
Epoch [26/100], Step [31/735], Loss: 0.0020
Epoch [26/100], Step [41/735], Loss: 0.0217
Epoch [26/100], Step [51/735], Loss: 0.0056
Epoch [26/100], Step [61/735], Loss: 0.0495
Epoch [26/100], Step [71/735], Loss: 0.0187
Epoch [26/100], Step [81/735], Loss: 0.0147
Epoch [26/100], Step [91/735], Loss: 0.0066
Epoch [26/100], Step [101/735], Loss: 0.0007
Epoch [26/100], Step [111/735], Loss: 0.0277
Epoch [26/100], Step [121/735], Loss: 0.0109
Epoch [26/100], Step [131/735], Loss: 0.0087
Epoch [26/100], Step [141/735], Loss: 0.0070
Epoch [26/100], Step [151/735], Loss: 0.0205
Epoch [26/100], Step [161/735], Loss: 0.0149
Epoch [26/100], Step [171/735], Loss: 0.0168
Epoch [26/100], Step [181/735], Loss: 0.0510
Epoch [26/100], Step [191/735], Loss: 0.0192
Epoch [26/100], Step [201/735], Loss: 0.0303
Epoch [26/100], Step [211/735], Loss: 0.0217
Epoch [26/100], Step [221/735], Loss: 0.0173
Epoch [26/100], Step [231/735], Loss: 0.0150
Epoch [26/100], Step [241/735], Loss: 0.0103
Epoch [26/100], Step [251/735], Loss: 0.0194
Epoch [26/100], Step [261/735], Loss: 0.0015
Epoch [26/100], Step [271/735], Loss: 0.0189
Epoch [26/100], Step [281/735], Loss: 0.0201
Epoch [26/100], Step [291/735], Loss: 0.0332
Epoch [26/100], Step [301/735], Loss: 0.0269
Epoch [26/100], Step [311/735], Loss: 0.0156
Epoch [26/100], Step [321/735], Loss: 0.0144
Epoch [26/100], Step [331/735], Loss: 0.0271
Epoch [26/100], Step [341/735], Loss: 0.0498
Epoch [26/100], Step [351/735], Loss: 0.0354
Epoch [26/100], Step [361/735], Loss: 0.0351
Epoch [26/100], Step [371/735], Loss: 0.0494
Epoch [26/100], Step [381/735], Loss: 0.0246
Epoch [26/100], Step [391/735], Loss: 0.0156
Epoch [26/100], Step [401/735], Loss: 0.0421
Epoch [26/100], Step [411/735], Loss: 0.0132
Epoch [26/100], Step [421/735], Loss: 0.0244
Epoch [26/100], Step [431/735], Loss: 0.0054
Epoch [26/100], Step [441/735], Loss: 0.0206
Epoch [26/100], Step [451/735], Loss: 0.0344
Epoch [26/100], Step [461/735], Loss: 0.0134
Epoch [26/100], Step [471/735], Loss: 0.0459
Epoch [26/100], Step [481/735], Loss: 0.0085
Epoch [26/100], Step [491/735], Loss: 0.0231
Epoch [26/100], Step [501/735], Loss: 0.0250
Epoch [26/100], Step [511/735], Loss: 0.0265
Epoch [26/100], Step [521/735], Loss: 0.0148
Epoch [26/100], Step [531/735], Loss: 0.0103
Epoch [26/100], Step [541/735], Loss: 0.0141
Epoch [26/100], Step [551/735], Loss: 0.0200
Epoch [26/100], Step [561/735], Loss: 0.0200
Epoch [26/100], Step [571/735], Loss: 0.0121
Epoch [26/100], Step [581/735], Loss: 0.0086
Epoch [26/100], Step [591/735], Loss: 0.0384
Epoch [26/100], Step [601/735], Loss: 0.0082
Epoch [26/100], Step [611/735], Loss: 0.0275
Epoch [26/100], Step [621/735], Loss: 0.0007
Epoch [26/100], Step [631/735], Loss: 0.0057
Epoch [26/100], Step [641/735], Loss: 0.0023
Epoch [26/100], Step [651/735], Loss: 0.0184
Epoch [26/100], Step [661/735], Loss: 0.0408
Epoch [26/100], Step [671/735], Loss: 0.0141
Epoch [26/100], Step [681/735], Loss: 0.0139
Epoch [26/100], Step [691/735], Loss: 0.0198
Epoch [26/100], Step [701/735], Loss: 0.0665
Epoch [26/100], Step [711/735], Loss: 0.0010
Epoch [26/100], Step [721/735], Loss: 0.0107
Epoch [26/100], Step [731/735], Loss: 0.0112
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9020,Val AUC: 0.9507,Val precision: 0.8025, Val recall: 0.8647, Val Loss: 0.0800
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 26 | Time taken: 2228.84s |
| Val CE loss: 0.08000 | Val MSE 0.90197 | Train Loss 0.02122 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 27
Training for epoch 27
Epoch [27/100], Step [1/735], Loss: 0.0509
Epoch [27/100], Step [11/735], Loss: 0.0290
Epoch [27/100], Step [21/735], Loss: 0.0128
Epoch [27/100], Step [31/735], Loss: 0.0112
Epoch [27/100], Step [41/735], Loss: 0.0115
Epoch [27/100], Step [51/735], Loss: 0.0321
Epoch [27/100], Step [61/735], Loss: 0.0193
Epoch [27/100], Step [71/735], Loss: 0.0045
Epoch [27/100], Step [81/735], Loss: 0.0226
Epoch [27/100], Step [91/735], Loss: 0.0015
Epoch [27/100], Step [101/735], Loss: 0.0240
Epoch [27/100], Step [111/735], Loss: 0.0236
Epoch [27/100], Step [121/735], Loss: 0.0055
Epoch [27/100], Step [131/735], Loss: 0.0211
Epoch [27/100], Step [141/735], Loss: 0.0051
Epoch [27/100], Step [151/735], Loss: 0.0466
Epoch [27/100], Step [161/735], Loss: 0.0222
Epoch [27/100], Step [171/735], Loss: 0.0246
Epoch [27/100], Step [181/735], Loss: 0.0046
Epoch [27/100], Step [191/735], Loss: 0.0296
Epoch [27/100], Step [201/735], Loss: 0.0255
Epoch [27/100], Step [211/735], Loss: 0.0199
Epoch [27/100], Step [221/735], Loss: 0.0140
Epoch [27/100], Step [231/735], Loss: 0.0215
Epoch [27/100], Step [241/735], Loss: 0.0101
Epoch [27/100], Step [251/735], Loss: 0.0021
Epoch [27/100], Step [261/735], Loss: 0.0199
Epoch [27/100], Step [271/735], Loss: 0.0447
Epoch [27/100], Step [281/735], Loss: 0.0014
Epoch [27/100], Step [291/735], Loss: 0.0188
Epoch [27/100], Step [301/735], Loss: 0.0396
Epoch [27/100], Step [311/735], Loss: 0.0028
Epoch [27/100], Step [321/735], Loss: 0.0209
Epoch [27/100], Step [331/735], Loss: 0.0008
Epoch [27/100], Step [341/735], Loss: 0.0323
Epoch [27/100], Step [351/735], Loss: 0.0298
Epoch [27/100], Step [361/735], Loss: 0.0017
Epoch [27/100], Step [371/735], Loss: 0.0166
Epoch [27/100], Step [381/735], Loss: 0.0230
Epoch [27/100], Step [391/735], Loss: 0.0108
Epoch [27/100], Step [401/735], Loss: 0.0363
Epoch [27/100], Step [411/735], Loss: 0.0160
Epoch [27/100], Step [421/735], Loss: 0.0270
Epoch [27/100], Step [431/735], Loss: 0.0057
Epoch [27/100], Step [441/735], Loss: 0.0498
Epoch [27/100], Step [451/735], Loss: 0.0162
Epoch [27/100], Step [461/735], Loss: 0.0024
Epoch [27/100], Step [471/735], Loss: 0.0004
Epoch [27/100], Step [481/735], Loss: 0.0450
Epoch [27/100], Step [491/735], Loss: 0.0165
Epoch [27/100], Step [501/735], Loss: 0.0154
Epoch [27/100], Step [511/735], Loss: 0.0195
Epoch [27/100], Step [521/735], Loss: 0.0075
Epoch [27/100], Step [531/735], Loss: 0.0270
Epoch [27/100], Step [541/735], Loss: 0.0151
Epoch [27/100], Step [551/735], Loss: 0.0195
Epoch [27/100], Step [561/735], Loss: 0.0200
Epoch [27/100], Step [571/735], Loss: 0.0119
Epoch [27/100], Step [581/735], Loss: 0.0317
Epoch [27/100], Step [591/735], Loss: 0.0322
Epoch [27/100], Step [601/735], Loss: 0.0414
Epoch [27/100], Step [611/735], Loss: 0.0179
Epoch [27/100], Step [621/735], Loss: 0.0189
Epoch [27/100], Step [631/735], Loss: 0.0152
Epoch [27/100], Step [641/735], Loss: 0.0188
Epoch [27/100], Step [651/735], Loss: 0.0437
Epoch [27/100], Step [661/735], Loss: 0.0066
Epoch [27/100], Step [671/735], Loss: 0.0291
Epoch [27/100], Step [681/735], Loss: 0.0175
Epoch [27/100], Step [691/735], Loss: 0.0063
Epoch [27/100], Step [701/735], Loss: 0.0264
Epoch [27/100], Step [711/735], Loss: 0.0228
Epoch [27/100], Step [721/735], Loss: 0.0275
Epoch [27/100], Step [731/735], Loss: 0.0383
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9070,Val AUC: 0.9502,Val precision: 0.8322, Val recall: 0.8389, Val Loss: 0.0785
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 27 | Time taken: 2218.69s |
| Val CE loss: 0.07853 | Val MSE 0.90700 | Train Loss 0.01984 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 28
Training for epoch 28
Epoch [28/100], Step [1/735], Loss: 0.0062
Epoch [28/100], Step [11/735], Loss: 0.0194
Epoch [28/100], Step [21/735], Loss: 0.0030
Epoch [28/100], Step [31/735], Loss: 0.0343
Epoch [28/100], Step [41/735], Loss: 0.0011
Epoch [28/100], Step [51/735], Loss: 0.0207
Epoch [28/100], Step [61/735], Loss: 0.0144
Epoch [28/100], Step [71/735], Loss: 0.0148
Epoch [28/100], Step [81/735], Loss: 0.0200
Epoch [28/100], Step [91/735], Loss: 0.0250
Epoch [28/100], Step [101/735], Loss: 0.0523
Epoch [28/100], Step [111/735], Loss: 0.0227
Epoch [28/100], Step [121/735], Loss: 0.0530
Epoch [28/100], Step [131/735], Loss: 0.0184
Epoch [28/100], Step [141/735], Loss: 0.0328
Epoch [28/100], Step [151/735], Loss: 0.0212
Epoch [28/100], Step [161/735], Loss: 0.0196
Epoch [28/100], Step [171/735], Loss: 0.0153
Epoch [28/100], Step [181/735], Loss: 0.0025
Epoch [28/100], Step [191/735], Loss: 0.0299
Epoch [28/100], Step [201/735], Loss: 0.0389
Epoch [28/100], Step [211/735], Loss: 0.0159
Epoch [28/100], Step [221/735], Loss: 0.0102
Epoch [28/100], Step [231/735], Loss: 0.0151
Epoch [28/100], Step [241/735], Loss: 0.0111
Epoch [28/100], Step [251/735], Loss: 0.0053
Epoch [28/100], Step [261/735], Loss: 0.0284
Epoch [28/100], Step [271/735], Loss: 0.0101
Epoch [28/100], Step [281/735], Loss: 0.0140
Epoch [28/100], Step [291/735], Loss: 0.0172
Epoch [28/100], Step [301/735], Loss: 0.0177
Epoch [28/100], Step [311/735], Loss: 0.0213
Epoch [28/100], Step [321/735], Loss: 0.0387
Epoch [28/100], Step [331/735], Loss: 0.0188
Epoch [28/100], Step [341/735], Loss: 0.0317
Epoch [28/100], Step [351/735], Loss: 0.0147
Epoch [28/100], Step [361/735], Loss: 0.0206
Epoch [28/100], Step [371/735], Loss: 0.0256
Epoch [28/100], Step [381/735], Loss: 0.0173
Epoch [28/100], Step [391/735], Loss: 0.0106
Epoch [28/100], Step [401/735], Loss: 0.0097
Epoch [28/100], Step [411/735], Loss: 0.0081
Epoch [28/100], Step [421/735], Loss: 0.0290
Epoch [28/100], Step [431/735], Loss: 0.0212
Epoch [28/100], Step [441/735], Loss: 0.0031
Epoch [28/100], Step [451/735], Loss: 0.0070
Epoch [28/100], Step [461/735], Loss: 0.0233
Epoch [28/100], Step [471/735], Loss: 0.0008
Epoch [28/100], Step [481/735], Loss: 0.0404
Epoch [28/100], Step [491/735], Loss: 0.0310
Epoch [28/100], Step [501/735], Loss: 0.0073
Epoch [28/100], Step [511/735], Loss: 0.0273
Epoch [28/100], Step [521/735], Loss: 0.0461
Epoch [28/100], Step [531/735], Loss: 0.0086
Epoch [28/100], Step [541/735], Loss: 0.0372
Epoch [28/100], Step [551/735], Loss: 0.0527
Epoch [28/100], Step [561/735], Loss: 0.0145
Epoch [28/100], Step [571/735], Loss: 0.0411
Epoch [28/100], Step [581/735], Loss: 0.0021
Epoch [28/100], Step [591/735], Loss: 0.0050
Epoch [28/100], Step [601/735], Loss: 0.0272
Epoch [28/100], Step [611/735], Loss: 0.0020
Epoch [28/100], Step [621/735], Loss: 0.0228
Epoch [28/100], Step [631/735], Loss: 0.0046
Epoch [28/100], Step [641/735], Loss: 0.0081
Epoch [28/100], Step [651/735], Loss: 0.0171
Epoch [28/100], Step [661/735], Loss: 0.0043
Epoch [28/100], Step [671/735], Loss: 0.0557
Epoch [28/100], Step [681/735], Loss: 0.0047
Epoch [28/100], Step [691/735], Loss: 0.0120
Epoch [28/100], Step [701/735], Loss: 0.0249
Epoch [28/100], Step [711/735], Loss: 0.0394
Epoch [28/100], Step [721/735], Loss: 0.0148
Epoch [28/100], Step [731/735], Loss: 0.0090
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9080,Val AUC: 0.9507,Val precision: 0.8378, Val recall: 0.8352, Val Loss: 0.0777
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 28 | Time taken: 2228.61s |
| Val CE loss: 0.07768 | Val MSE 0.90804 | Train Loss 0.01928 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 29
Training for epoch 29
Epoch [29/100], Step [1/735], Loss: 0.0231
Epoch [29/100], Step [11/735], Loss: 0.0026
Epoch [29/100], Step [21/735], Loss: 0.0182
Epoch [29/100], Step [31/735], Loss: 0.0252
Epoch [29/100], Step [41/735], Loss: 0.0041
Epoch [29/100], Step [51/735], Loss: 0.0186
Epoch [29/100], Step [61/735], Loss: 0.0218
Epoch [29/100], Step [71/735], Loss: 0.0088
Epoch [29/100], Step [81/735], Loss: 0.0278
Epoch [29/100], Step [91/735], Loss: 0.0071
Epoch [29/100], Step [101/735], Loss: 0.0446
Epoch [29/100], Step [111/735], Loss: 0.0196
Epoch [29/100], Step [121/735], Loss: 0.0323
Epoch [29/100], Step [131/735], Loss: 0.0287
Epoch [29/100], Step [141/735], Loss: 0.0306
Epoch [29/100], Step [151/735], Loss: 0.0355
Epoch [29/100], Step [161/735], Loss: 0.0200
Epoch [29/100], Step [171/735], Loss: 0.0131
Epoch [29/100], Step [181/735], Loss: 0.0010
Epoch [29/100], Step [191/735], Loss: 0.0196
Epoch [29/100], Step [201/735], Loss: 0.0188
Epoch [29/100], Step [211/735], Loss: 0.0324
Epoch [29/100], Step [221/735], Loss: 0.0299
Epoch [29/100], Step [231/735], Loss: 0.0142
Epoch [29/100], Step [241/735], Loss: 0.0064
Epoch [29/100], Step [251/735], Loss: 0.0014
Epoch [29/100], Step [261/735], Loss: 0.0044
Epoch [29/100], Step [271/735], Loss: 0.0171
Epoch [29/100], Step [281/735], Loss: 0.0150
Epoch [29/100], Step [291/735], Loss: 0.0038
Epoch [29/100], Step [301/735], Loss: 0.0022
Epoch [29/100], Step [311/735], Loss: 0.0239
Epoch [29/100], Step [321/735], Loss: 0.0274
Epoch [29/100], Step [331/735], Loss: 0.0293
Epoch [29/100], Step [341/735], Loss: 0.0222
Epoch [29/100], Step [351/735], Loss: 0.0219
Epoch [29/100], Step [361/735], Loss: 0.0026
Epoch [29/100], Step [371/735], Loss: 0.0052
Epoch [29/100], Step [381/735], Loss: 0.0140
Epoch [29/100], Step [391/735], Loss: 0.0297
Epoch [29/100], Step [401/735], Loss: 0.0071
Epoch [29/100], Step [411/735], Loss: 0.0025
Epoch [29/100], Step [421/735], Loss: 0.0190
Epoch [29/100], Step [431/735], Loss: 0.0235
Epoch [29/100], Step [441/735], Loss: 0.0093
Epoch [29/100], Step [451/735], Loss: 0.0230
Epoch [29/100], Step [461/735], Loss: 0.0540
Epoch [29/100], Step [471/735], Loss: 0.0070
Epoch [29/100], Step [481/735], Loss: 0.0554
Epoch [29/100], Step [491/735], Loss: 0.0132
Epoch [29/100], Step [501/735], Loss: 0.0253
Epoch [29/100], Step [511/735], Loss: 0.0057
Epoch [29/100], Step [521/735], Loss: 0.0396
Epoch [29/100], Step [531/735], Loss: 0.0098
Epoch [29/100], Step [541/735], Loss: 0.0293
Epoch [29/100], Step [551/735], Loss: 0.0240
Epoch [29/100], Step [561/735], Loss: 0.0155
Epoch [29/100], Step [571/735], Loss: 0.0016
Epoch [29/100], Step [581/735], Loss: 0.0209
Epoch [29/100], Step [591/735], Loss: 0.0137
Epoch [29/100], Step [601/735], Loss: 0.0051
Epoch [29/100], Step [611/735], Loss: 0.0392
Epoch [29/100], Step [621/735], Loss: 0.0339
Epoch [29/100], Step [631/735], Loss: 0.0146
Epoch [29/100], Step [641/735], Loss: 0.0129
Epoch [29/100], Step [651/735], Loss: 0.0257
Epoch [29/100], Step [661/735], Loss: 0.0053
Epoch [29/100], Step [671/735], Loss: 0.0153
Epoch [29/100], Step [681/735], Loss: 0.0244
Epoch [29/100], Step [691/735], Loss: 0.0362
Epoch [29/100], Step [701/735], Loss: 0.0084
Epoch [29/100], Step [711/735], Loss: 0.0250
Epoch [29/100], Step [721/735], Loss: 0.0128
Epoch [29/100], Step [731/735], Loss: 0.0257
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9087,Val AUC: 0.9519,Val precision: 0.8292, Val recall: 0.8512, Val Loss: 0.0763
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 29 | Time taken: 2209.66s |
| Val CE loss: 0.07628 | Val MSE 0.90873 | Train Loss 0.01864 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 30
Training for epoch 30
Epoch [30/100], Step [1/735], Loss: 0.0018
Epoch [30/100], Step [11/735], Loss: 0.0140
Epoch [30/100], Step [21/735], Loss: 0.0380
Epoch [30/100], Step [31/735], Loss: 0.0063
Epoch [30/100], Step [41/735], Loss: 0.0316
Epoch [30/100], Step [51/735], Loss: 0.0134
Epoch [30/100], Step [61/735], Loss: 0.0118
Epoch [30/100], Step [71/735], Loss: 0.0009
Epoch [30/100], Step [81/735], Loss: 0.0331
Epoch [30/100], Step [91/735], Loss: 0.0076
Epoch [30/100], Step [101/735], Loss: 0.0175
Epoch [30/100], Step [111/735], Loss: 0.0103
Epoch [30/100], Step [121/735], Loss: 0.0126
Epoch [30/100], Step [131/735], Loss: 0.0283
Epoch [30/100], Step [141/735], Loss: 0.0157
Epoch [30/100], Step [151/735], Loss: 0.0157
Epoch [30/100], Step [161/735], Loss: 0.0166
Epoch [30/100], Step [171/735], Loss: 0.0169
Epoch [30/100], Step [181/735], Loss: 0.0010
Epoch [30/100], Step [191/735], Loss: 0.0299
Epoch [30/100], Step [201/735], Loss: 0.0164
Epoch [30/100], Step [211/735], Loss: 0.0136
Epoch [30/100], Step [221/735], Loss: 0.0194
Epoch [30/100], Step [231/735], Loss: 0.0020
Epoch [30/100], Step [241/735], Loss: 0.0033
Epoch [30/100], Step [251/735], Loss: 0.0179
Epoch [30/100], Step [261/735], Loss: 0.0059
Epoch [30/100], Step [271/735], Loss: 0.0233
Epoch [30/100], Step [281/735], Loss: 0.0357
Epoch [30/100], Step [291/735], Loss: 0.0390
Epoch [30/100], Step [301/735], Loss: 0.0125
Epoch [30/100], Step [311/735], Loss: 0.0139
Epoch [30/100], Step [321/735], Loss: 0.0288
Epoch [30/100], Step [331/735], Loss: 0.0041
Epoch [30/100], Step [341/735], Loss: 0.0175
Epoch [30/100], Step [351/735], Loss: 0.0599
Epoch [30/100], Step [361/735], Loss: 0.0254
Epoch [30/100], Step [371/735], Loss: 0.0076
Epoch [30/100], Step [381/735], Loss: 0.0170
Epoch [30/100], Step [391/735], Loss: 0.0138
Epoch [30/100], Step [401/735], Loss: 0.0093
Epoch [30/100], Step [411/735], Loss: 0.0074
Epoch [30/100], Step [421/735], Loss: 0.0159
Epoch [30/100], Step [431/735], Loss: 0.0035
Epoch [30/100], Step [441/735], Loss: 0.0050
Epoch [30/100], Step [451/735], Loss: 0.0444
Epoch [30/100], Step [461/735], Loss: 0.0007
Epoch [30/100], Step [471/735], Loss: 0.0207
Epoch [30/100], Step [481/735], Loss: 0.0050
Epoch [30/100], Step [491/735], Loss: 0.0346
Epoch [30/100], Step [501/735], Loss: 0.0330
Epoch [30/100], Step [511/735], Loss: 0.0277
Epoch [30/100], Step [521/735], Loss: 0.0226
Epoch [30/100], Step [531/735], Loss: 0.0253
Epoch [30/100], Step [541/735], Loss: 0.0354
Epoch [30/100], Step [551/735], Loss: 0.0279
Epoch [30/100], Step [561/735], Loss: 0.0377
Epoch [30/100], Step [571/735], Loss: 0.0120
Epoch [30/100], Step [581/735], Loss: 0.0163
Epoch [30/100], Step [591/735], Loss: 0.0252
Epoch [30/100], Step [601/735], Loss: 0.0141
Epoch [30/100], Step [611/735], Loss: 0.0059
Epoch [30/100], Step [621/735], Loss: 0.0320
Epoch [30/100], Step [631/735], Loss: 0.0151
Epoch [30/100], Step [641/735], Loss: 0.0410
Epoch [30/100], Step [651/735], Loss: 0.0156
Epoch [30/100], Step [661/735], Loss: 0.0269
Epoch [30/100], Step [671/735], Loss: 0.0202
Epoch [30/100], Step [681/735], Loss: 0.0135
Epoch [30/100], Step [691/735], Loss: 0.0106
Epoch [30/100], Step [701/735], Loss: 0.0149
Epoch [30/100], Step [711/735], Loss: 0.0038
Epoch [30/100], Step [721/735], Loss: 0.0162
Epoch [30/100], Step [731/735], Loss: 0.0030
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9117,Val AUC: 0.9492,Val precision: 0.8386, Val recall: 0.8499, Val Loss: 0.0748
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 30 | Time taken: 2202.19s |
| Val CE loss: 0.07475 | Val MSE 0.91167 | Train Loss 0.01797 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 31
Training for epoch 31
Epoch [31/100], Step [1/735], Loss: 0.0255
Epoch [31/100], Step [11/735], Loss: 0.0095
Epoch [31/100], Step [21/735], Loss: 0.0294
Epoch [31/100], Step [31/735], Loss: 0.0294
Epoch [31/100], Step [41/735], Loss: 0.0168
Epoch [31/100], Step [51/735], Loss: 0.0323
Epoch [31/100], Step [61/735], Loss: 0.0390
Epoch [31/100], Step [71/735], Loss: 0.0161
Epoch [31/100], Step [81/735], Loss: 0.0101
Epoch [31/100], Step [91/735], Loss: 0.0341
Epoch [31/100], Step [101/735], Loss: 0.0198
Epoch [31/100], Step [111/735], Loss: 0.0248
Epoch [31/100], Step [121/735], Loss: 0.0386
Epoch [31/100], Step [131/735], Loss: 0.0262
Epoch [31/100], Step [141/735], Loss: 0.0063
Epoch [31/100], Step [151/735], Loss: 0.0004
Epoch [31/100], Step [161/735], Loss: 0.0022
Epoch [31/100], Step [171/735], Loss: 0.0169
Epoch [31/100], Step [181/735], Loss: 0.0014
Epoch [31/100], Step [191/735], Loss: 0.0280
Epoch [31/100], Step [201/735], Loss: 0.0447
Epoch [31/100], Step [211/735], Loss: 0.0014
Epoch [31/100], Step [221/735], Loss: 0.0140
Epoch [31/100], Step [231/735], Loss: 0.0058
Epoch [31/100], Step [241/735], Loss: 0.0218
Epoch [31/100], Step [251/735], Loss: 0.0126
Epoch [31/100], Step [261/735], Loss: 0.0113
Epoch [31/100], Step [271/735], Loss: 0.0143
Epoch [31/100], Step [281/735], Loss: 0.0006
Epoch [31/100], Step [291/735], Loss: 0.0201
Epoch [31/100], Step [301/735], Loss: 0.0010
Epoch [31/100], Step [311/735], Loss: 0.0401
Epoch [31/100], Step [321/735], Loss: 0.0134
Epoch [31/100], Step [331/735], Loss: 0.0291
Epoch [31/100], Step [341/735], Loss: 0.0328
Epoch [31/100], Step [351/735], Loss: 0.0069
Epoch [31/100], Step [361/735], Loss: 0.0058
Epoch [31/100], Step [371/735], Loss: 0.0164
Epoch [31/100], Step [381/735], Loss: 0.0023
Epoch [31/100], Step [391/735], Loss: 0.0163
Epoch [31/100], Step [401/735], Loss: 0.0126
Epoch [31/100], Step [411/735], Loss: 0.0286
Epoch [31/100], Step [421/735], Loss: 0.0136
Epoch [31/100], Step [431/735], Loss: 0.0195
Epoch [31/100], Step [441/735], Loss: 0.0107
Epoch [31/100], Step [451/735], Loss: 0.0014
Epoch [31/100], Step [461/735], Loss: 0.0524
Epoch [31/100], Step [471/735], Loss: 0.0039
Epoch [31/100], Step [481/735], Loss: 0.0161
Epoch [31/100], Step [491/735], Loss: 0.0272
Epoch [31/100], Step [501/735], Loss: 0.0102
Epoch [31/100], Step [511/735], Loss: 0.0160
Epoch [31/100], Step [521/735], Loss: 0.0245
Epoch [31/100], Step [531/735], Loss: 0.0373
Epoch [31/100], Step [541/735], Loss: 0.0176
Epoch [31/100], Step [551/735], Loss: 0.0251
Epoch [31/100], Step [561/735], Loss: 0.0073
Epoch [31/100], Step [571/735], Loss: 0.0163
Epoch [31/100], Step [581/735], Loss: 0.0581
Epoch [31/100], Step [591/735], Loss: 0.0298
Epoch [31/100], Step [601/735], Loss: 0.0329
Epoch [31/100], Step [611/735], Loss: 0.0272
Epoch [31/100], Step [621/735], Loss: 0.0195
Epoch [31/100], Step [631/735], Loss: 0.0127
Epoch [31/100], Step [641/735], Loss: 0.0124
Epoch [31/100], Step [651/735], Loss: 0.0147
Epoch [31/100], Step [661/735], Loss: 0.0304
Epoch [31/100], Step [671/735], Loss: 0.0264
Epoch [31/100], Step [681/735], Loss: 0.0385
Epoch [31/100], Step [691/735], Loss: 0.0126
Epoch [31/100], Step [701/735], Loss: 0.0568
Epoch [31/100], Step [711/735], Loss: 0.0155
Epoch [31/100], Step [721/735], Loss: 0.0077
Epoch [31/100], Step [731/735], Loss: 0.0181
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9054,Val AUC: 0.9509,Val precision: 0.8075, Val recall: 0.8721, Val Loss: 0.0799
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 31 | Time taken: 2209.47s |
| Val CE loss: 0.07989 | Val MSE 0.90544 | Train Loss 0.01703 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 32
Training for epoch 32
Epoch [32/100], Step [1/735], Loss: 0.0063
Epoch [32/100], Step [11/735], Loss: 0.0057
Epoch [32/100], Step [21/735], Loss: 0.0324
Epoch [32/100], Step [31/735], Loss: 0.0137
Epoch [32/100], Step [41/735], Loss: 0.0054
Epoch [32/100], Step [51/735], Loss: 0.0205
Epoch [32/100], Step [61/735], Loss: 0.0182
Epoch [32/100], Step [71/735], Loss: 0.0212
Epoch [32/100], Step [81/735], Loss: 0.0243
Epoch [32/100], Step [91/735], Loss: 0.0068
Epoch [32/100], Step [101/735], Loss: 0.0020
Epoch [32/100], Step [111/735], Loss: 0.0209
Epoch [32/100], Step [121/735], Loss: 0.0173
Epoch [32/100], Step [131/735], Loss: 0.0323
Epoch [32/100], Step [141/735], Loss: 0.0250
Epoch [32/100], Step [151/735], Loss: 0.0069
Epoch [32/100], Step [161/735], Loss: 0.0149
Epoch [32/100], Step [171/735], Loss: 0.0291
Epoch [32/100], Step [181/735], Loss: 0.0546
Epoch [32/100], Step [191/735], Loss: 0.0131
Epoch [32/100], Step [201/735], Loss: 0.0238
Epoch [32/100], Step [211/735], Loss: 0.0193
Epoch [32/100], Step [221/735], Loss: 0.0175
Epoch [32/100], Step [231/735], Loss: 0.0028
Epoch [32/100], Step [241/735], Loss: 0.0002
Epoch [32/100], Step [251/735], Loss: 0.0201
Epoch [32/100], Step [261/735], Loss: 0.0350
Epoch [32/100], Step [271/735], Loss: 0.0084
Epoch [32/100], Step [281/735], Loss: 0.0021
Epoch [32/100], Step [291/735], Loss: 0.0132
Epoch [32/100], Step [301/735], Loss: 0.0079
Epoch [32/100], Step [311/735], Loss: 0.0078
Epoch [32/100], Step [321/735], Loss: 0.0578
Epoch [32/100], Step [331/735], Loss: 0.0107
Epoch [32/100], Step [341/735], Loss: 0.0178
Epoch [32/100], Step [351/735], Loss: 0.0138
Epoch [32/100], Step [361/735], Loss: 0.0350
Epoch [32/100], Step [371/735], Loss: 0.0287
Epoch [32/100], Step [381/735], Loss: 0.0025
Epoch [32/100], Step [391/735], Loss: 0.0247
Epoch [32/100], Step [401/735], Loss: 0.0011
Epoch [32/100], Step [411/735], Loss: 0.0095
Epoch [32/100], Step [421/735], Loss: 0.0100
Epoch [32/100], Step [431/735], Loss: 0.0331
Epoch [32/100], Step [441/735], Loss: 0.0251
Epoch [32/100], Step [451/735], Loss: 0.0055
Epoch [32/100], Step [461/735], Loss: 0.0013
Epoch [32/100], Step [471/735], Loss: 0.0259
Epoch [32/100], Step [481/735], Loss: 0.0094
Epoch [32/100], Step [491/735], Loss: 0.0013
Epoch [32/100], Step [501/735], Loss: 0.0017
Epoch [32/100], Step [511/735], Loss: 0.0002
Epoch [32/100], Step [521/735], Loss: 0.0200
Epoch [32/100], Step [531/735], Loss: 0.0397
Epoch [32/100], Step [541/735], Loss: 0.0262
Epoch [32/100], Step [551/735], Loss: 0.0204
Epoch [32/100], Step [561/735], Loss: 0.0154
Epoch [32/100], Step [571/735], Loss: 0.0343
Epoch [32/100], Step [581/735], Loss: 0.0006
Epoch [32/100], Step [591/735], Loss: 0.0379
Epoch [32/100], Step [601/735], Loss: 0.0207
Epoch [32/100], Step [611/735], Loss: 0.0434
Epoch [32/100], Step [621/735], Loss: 0.0139
Epoch [32/100], Step [631/735], Loss: 0.0014
Epoch [32/100], Step [641/735], Loss: 0.0228
Epoch [32/100], Step [651/735], Loss: 0.0090
Epoch [32/100], Step [661/735], Loss: 0.0157
Epoch [32/100], Step [671/735], Loss: 0.0014
Epoch [32/100], Step [681/735], Loss: 0.0430
Epoch [32/100], Step [691/735], Loss: 0.0108
Epoch [32/100], Step [701/735], Loss: 0.0179
Epoch [32/100], Step [711/735], Loss: 0.0192
Epoch [32/100], Step [721/735], Loss: 0.0034
Epoch [32/100], Step [731/735], Loss: 0.0157
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9054,Val AUC: 0.9491,Val precision: 0.8191, Val recall: 0.8524, Val Loss: 0.0788
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 32 | Time taken: 2243.55s |
| Val CE loss: 0.07878 | Val MSE 0.90544 | Train Loss 0.01625 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 33
Training for epoch 33
Epoch [33/100], Step [1/735], Loss: 0.0036
Epoch [33/100], Step [11/735], Loss: 0.0169
Epoch [33/100], Step [21/735], Loss: 0.0233
Epoch [33/100], Step [31/735], Loss: 0.0168
Epoch [33/100], Step [41/735], Loss: 0.0149
Epoch [33/100], Step [51/735], Loss: 0.0168
Epoch [33/100], Step [61/735], Loss: 0.0017
Epoch [33/100], Step [71/735], Loss: 0.0201
Epoch [33/100], Step [81/735], Loss: 0.0094
Epoch [33/100], Step [91/735], Loss: 0.0157
Epoch [33/100], Step [101/735], Loss: 0.0082
Epoch [33/100], Step [111/735], Loss: 0.0130
Epoch [33/100], Step [121/735], Loss: 0.0063
Epoch [33/100], Step [131/735], Loss: 0.0151
Epoch [33/100], Step [141/735], Loss: 0.0182
Epoch [33/100], Step [151/735], Loss: 0.0182
Epoch [33/100], Step [161/735], Loss: 0.0271
Epoch [33/100], Step [171/735], Loss: 0.0298
Epoch [33/100], Step [181/735], Loss: 0.0160
Epoch [33/100], Step [191/735], Loss: 0.0071
Epoch [33/100], Step [201/735], Loss: 0.0206
Epoch [33/100], Step [211/735], Loss: 0.0250
Epoch [33/100], Step [221/735], Loss: 0.0027
Epoch [33/100], Step [231/735], Loss: 0.0089
Epoch [33/100], Step [241/735], Loss: 0.0064
Epoch [33/100], Step [251/735], Loss: 0.0138
Epoch [33/100], Step [261/735], Loss: 0.0164
Epoch [33/100], Step [271/735], Loss: 0.0113
Epoch [33/100], Step [281/735], Loss: 0.0171
Epoch [33/100], Step [291/735], Loss: 0.0199
Epoch [33/100], Step [301/735], Loss: 0.0337
Epoch [33/100], Step [311/735], Loss: 0.0018
Epoch [33/100], Step [321/735], Loss: 0.0194
Epoch [33/100], Step [331/735], Loss: 0.0225
Epoch [33/100], Step [341/735], Loss: 0.0126
Epoch [33/100], Step [351/735], Loss: 0.0149
Epoch [33/100], Step [361/735], Loss: 0.0039
Epoch [33/100], Step [371/735], Loss: 0.0003
Epoch [33/100], Step [381/735], Loss: 0.0150
Epoch [33/100], Step [391/735], Loss: 0.0032
Epoch [33/100], Step [401/735], Loss: 0.0002
Epoch [33/100], Step [411/735], Loss: 0.0054
Epoch [33/100], Step [421/735], Loss: 0.0200
Epoch [33/100], Step [431/735], Loss: 0.0303
Epoch [33/100], Step [441/735], Loss: 0.0149
Epoch [33/100], Step [451/735], Loss: 0.0305
Epoch [33/100], Step [461/735], Loss: 0.0036
Epoch [33/100], Step [471/735], Loss: 0.0232
Epoch [33/100], Step [481/735], Loss: 0.0187
Epoch [33/100], Step [491/735], Loss: 0.0205
Epoch [33/100], Step [501/735], Loss: 0.0255
Epoch [33/100], Step [511/735], Loss: 0.0407
Epoch [33/100], Step [521/735], Loss: 0.0003
Epoch [33/100], Step [531/735], Loss: 0.0124
Epoch [33/100], Step [541/735], Loss: 0.0119
Epoch [33/100], Step [551/735], Loss: 0.0096
Epoch [33/100], Step [561/735], Loss: 0.0121
Epoch [33/100], Step [571/735], Loss: 0.0003
Epoch [33/100], Step [581/735], Loss: 0.0087
Epoch [33/100], Step [591/735], Loss: 0.0039
Epoch [33/100], Step [601/735], Loss: 0.0018
Epoch [33/100], Step [611/735], Loss: 0.0226
Epoch [33/100], Step [621/735], Loss: 0.0374
Epoch [33/100], Step [631/735], Loss: 0.0134
Epoch [33/100], Step [641/735], Loss: 0.0089
Epoch [33/100], Step [651/735], Loss: 0.0103
Epoch [33/100], Step [661/735], Loss: 0.0144
Epoch [33/100], Step [671/735], Loss: 0.0202
Epoch [33/100], Step [681/735], Loss: 0.0231
Epoch [33/100], Step [691/735], Loss: 0.0160
Epoch [33/100], Step [701/735], Loss: 0.0282
Epoch [33/100], Step [711/735], Loss: 0.0281
Epoch [33/100], Step [721/735], Loss: 0.0015
Epoch [33/100], Step [731/735], Loss: 0.0139
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9124,Val AUC: 0.9525,Val precision: 0.8398, Val recall: 0.8512, Val Loss: 0.0744
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 33 | Time taken: 2248.10s |
| Val CE loss: 0.07437 | Val MSE 0.91237 | Train Loss 0.01604 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 34
Training for epoch 34
Epoch [34/100], Step [1/735], Loss: 0.0211
Epoch [34/100], Step [11/735], Loss: 0.0078
Epoch [34/100], Step [21/735], Loss: 0.0159
Epoch [34/100], Step [31/735], Loss: 0.0076
Epoch [34/100], Step [41/735], Loss: 0.0195
Epoch [34/100], Step [51/735], Loss: 0.0011
Epoch [34/100], Step [61/735], Loss: 0.0187
Epoch [34/100], Step [71/735], Loss: 0.0020
Epoch [34/100], Step [81/735], Loss: 0.0169
Epoch [34/100], Step [91/735], Loss: 0.0359
Epoch [34/100], Step [101/735], Loss: 0.0150
Epoch [34/100], Step [111/735], Loss: 0.0269
Epoch [34/100], Step [121/735], Loss: 0.0130
Epoch [34/100], Step [131/735], Loss: 0.0001
Epoch [34/100], Step [141/735], Loss: 0.0057
Epoch [34/100], Step [151/735], Loss: 0.0113
Epoch [34/100], Step [161/735], Loss: 0.0221
Epoch [34/100], Step [171/735], Loss: 0.0004
Epoch [34/100], Step [181/735], Loss: 0.0458
Epoch [34/100], Step [191/735], Loss: 0.0342
Epoch [34/100], Step [201/735], Loss: 0.0227
Epoch [34/100], Step [211/735], Loss: 0.0169
Epoch [34/100], Step [221/735], Loss: 0.0280
Epoch [34/100], Step [231/735], Loss: 0.0340
Epoch [34/100], Step [241/735], Loss: 0.0022
Epoch [34/100], Step [251/735], Loss: 0.0037
Epoch [34/100], Step [261/735], Loss: 0.0422
Epoch [34/100], Step [271/735], Loss: 0.0297
Epoch [34/100], Step [281/735], Loss: 0.0096
Epoch [34/100], Step [291/735], Loss: 0.0042
Epoch [34/100], Step [301/735], Loss: 0.0308
Epoch [34/100], Step [311/735], Loss: 0.0313
Epoch [34/100], Step [321/735], Loss: 0.0130
Epoch [34/100], Step [331/735], Loss: 0.0139
Epoch [34/100], Step [341/735], Loss: 0.0211
Epoch [34/100], Step [351/735], Loss: 0.0203
Epoch [34/100], Step [361/735], Loss: 0.0165
Epoch [34/100], Step [371/735], Loss: 0.0185
Epoch [34/100], Step [381/735], Loss: 0.0032
Epoch [34/100], Step [391/735], Loss: 0.0198
Epoch [34/100], Step [401/735], Loss: 0.0209
Epoch [34/100], Step [411/735], Loss: 0.0008
Epoch [34/100], Step [421/735], Loss: 0.0015
Epoch [34/100], Step [431/735], Loss: 0.0352
Epoch [34/100], Step [441/735], Loss: 0.0085
Epoch [34/100], Step [451/735], Loss: 0.0145
Epoch [34/100], Step [461/735], Loss: 0.0016
Epoch [34/100], Step [471/735], Loss: 0.0074
Epoch [34/100], Step [481/735], Loss: 0.0143
Epoch [34/100], Step [491/735], Loss: 0.0122
Epoch [34/100], Step [501/735], Loss: 0.0072
Epoch [34/100], Step [511/735], Loss: 0.0164
Epoch [34/100], Step [521/735], Loss: 0.0256
Epoch [34/100], Step [531/735], Loss: 0.0146
Epoch [34/100], Step [541/735], Loss: 0.0100
Epoch [34/100], Step [551/735], Loss: 0.0255
Epoch [34/100], Step [561/735], Loss: 0.0454
Epoch [34/100], Step [571/735], Loss: 0.0310
Epoch [34/100], Step [581/735], Loss: 0.0356
Epoch [34/100], Step [591/735], Loss: 0.0133
Epoch [34/100], Step [601/735], Loss: 0.0320
Epoch [34/100], Step [611/735], Loss: 0.0240
Epoch [34/100], Step [621/735], Loss: 0.0270
Epoch [34/100], Step [631/735], Loss: 0.0009
Epoch [34/100], Step [641/735], Loss: 0.0024
Epoch [34/100], Step [651/735], Loss: 0.0028
Epoch [34/100], Step [661/735], Loss: 0.0140
Epoch [34/100], Step [671/735], Loss: 0.0223
Epoch [34/100], Step [681/735], Loss: 0.0290
Epoch [34/100], Step [691/735], Loss: 0.0304
Epoch [34/100], Step [701/735], Loss: 0.0361
Epoch [34/100], Step [711/735], Loss: 0.0045
Epoch [34/100], Step [721/735], Loss: 0.0280
Epoch [34/100], Step [731/735], Loss: 0.0227
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9112,Val AUC: 0.9529,Val precision: 0.8395, Val recall: 0.8462, Val Loss: 0.0755
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 34 | Time taken: 2281.84s |
| Val CE loss: 0.07549 | Val MSE 0.91115 | Train Loss 0.01628 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 35
Training for epoch 35
Epoch [35/100], Step [1/735], Loss: 0.0230
Epoch [35/100], Step [11/735], Loss: 0.0275
Epoch [35/100], Step [21/735], Loss: 0.0201
Epoch [35/100], Step [31/735], Loss: 0.0361
Epoch [35/100], Step [41/735], Loss: 0.0019
Epoch [35/100], Step [51/735], Loss: 0.0143
Epoch [35/100], Step [61/735], Loss: 0.0270
Epoch [35/100], Step [71/735], Loss: 0.0018
Epoch [35/100], Step [81/735], Loss: 0.0369
Epoch [35/100], Step [91/735], Loss: 0.0099
Epoch [35/100], Step [101/735], Loss: 0.0218
Epoch [35/100], Step [111/735], Loss: 0.0088
Epoch [35/100], Step [121/735], Loss: 0.0007
Epoch [35/100], Step [131/735], Loss: 0.0208
Epoch [35/100], Step [141/735], Loss: 0.0388
Epoch [35/100], Step [151/735], Loss: 0.0435
Epoch [35/100], Step [161/735], Loss: 0.0163
Epoch [35/100], Step [171/735], Loss: 0.0203
Epoch [35/100], Step [181/735], Loss: 0.0192
Epoch [35/100], Step [191/735], Loss: 0.0271
Epoch [35/100], Step [201/735], Loss: 0.0131
Epoch [35/100], Step [211/735], Loss: 0.0123
Epoch [35/100], Step [221/735], Loss: 0.0260
Epoch [35/100], Step [231/735], Loss: 0.0117
Epoch [35/100], Step [241/735], Loss: 0.0175
Epoch [35/100], Step [251/735], Loss: 0.0006
Epoch [35/100], Step [261/735], Loss: 0.0039
Epoch [35/100], Step [271/735], Loss: 0.0114
Epoch [35/100], Step [281/735], Loss: 0.0117
Epoch [35/100], Step [291/735], Loss: 0.0017
Epoch [35/100], Step [301/735], Loss: 0.0145
Epoch [35/100], Step [311/735], Loss: 0.0045
Epoch [35/100], Step [321/735], Loss: 0.0027
Epoch [35/100], Step [331/735], Loss: 0.0166
Epoch [35/100], Step [341/735], Loss: 0.0341
Epoch [35/100], Step [351/735], Loss: 0.0008
Epoch [35/100], Step [361/735], Loss: 0.0010
Epoch [35/100], Step [371/735], Loss: 0.0241
Epoch [35/100], Step [381/735], Loss: 0.0128
Epoch [35/100], Step [391/735], Loss: 0.0037
Epoch [35/100], Step [401/735], Loss: 0.0260
Epoch [35/100], Step [411/735], Loss: 0.0147
Epoch [35/100], Step [421/735], Loss: 0.0135
Epoch [35/100], Step [431/735], Loss: 0.0196
Epoch [35/100], Step [441/735], Loss: 0.0016
Epoch [35/100], Step [451/735], Loss: 0.0191
Epoch [35/100], Step [461/735], Loss: 0.0189
Epoch [35/100], Step [471/735], Loss: 0.0163
Epoch [35/100], Step [481/735], Loss: 0.0006
Epoch [35/100], Step [491/735], Loss: 0.0152
Epoch [35/100], Step [501/735], Loss: 0.0127
Epoch [35/100], Step [511/735], Loss: 0.0110
Epoch [35/100], Step [521/735], Loss: 0.0050
Epoch [35/100], Step [531/735], Loss: 0.0259
Epoch [35/100], Step [541/735], Loss: 0.0067
Epoch [35/100], Step [551/735], Loss: 0.0159
Epoch [35/100], Step [561/735], Loss: 0.0080
Epoch [35/100], Step [571/735], Loss: 0.0004
Epoch [35/100], Step [581/735], Loss: 0.0028
Epoch [35/100], Step [591/735], Loss: 0.0259
Epoch [35/100], Step [601/735], Loss: 0.0062
Epoch [35/100], Step [611/735], Loss: 0.0106
Epoch [35/100], Step [621/735], Loss: 0.0006
Epoch [35/100], Step [631/735], Loss: 0.0011
Epoch [35/100], Step [641/735], Loss: 0.0054
Epoch [35/100], Step [651/735], Loss: 0.0213
Epoch [35/100], Step [661/735], Loss: 0.0386
Epoch [35/100], Step [671/735], Loss: 0.0315
Epoch [35/100], Step [681/735], Loss: 0.0136
Epoch [35/100], Step [691/735], Loss: 0.0031
Epoch [35/100], Step [701/735], Loss: 0.0083
Epoch [35/100], Step [711/735], Loss: 0.0141
Epoch [35/100], Step [721/735], Loss: 0.0234
Epoch [35/100], Step [731/735], Loss: 0.0482
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9053,Val AUC: 0.9503,Val precision: 0.8113, Val recall: 0.8647, Val Loss: 0.0794
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 35 | Time taken: 2273.83s |
| Val CE loss: 0.07944 | Val MSE 0.90526 | Train Loss 0.01543 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 36
Training for epoch 36
Epoch [36/100], Step [1/735], Loss: 0.0014
Epoch [36/100], Step [11/735], Loss: 0.0141
Epoch [36/100], Step [21/735], Loss: 0.0327
Epoch [36/100], Step [31/735], Loss: 0.0152
Epoch [36/100], Step [41/735], Loss: 0.0442
Epoch [36/100], Step [51/735], Loss: 0.0158
Epoch [36/100], Step [61/735], Loss: 0.0002
Epoch [36/100], Step [71/735], Loss: 0.0102
Epoch [36/100], Step [81/735], Loss: 0.0173
Epoch [36/100], Step [91/735], Loss: 0.0335
Epoch [36/100], Step [101/735], Loss: 0.0391
Epoch [36/100], Step [111/735], Loss: 0.0008
Epoch [36/100], Step [121/735], Loss: 0.0124
Epoch [36/100], Step [131/735], Loss: 0.0224
Epoch [36/100], Step [141/735], Loss: 0.0171
Epoch [36/100], Step [151/735], Loss: 0.0189
Epoch [36/100], Step [161/735], Loss: 0.0033
Epoch [36/100], Step [171/735], Loss: 0.0048
Epoch [36/100], Step [181/735], Loss: 0.0129
Epoch [36/100], Step [191/735], Loss: 0.0026
Epoch [36/100], Step [201/735], Loss: 0.0408
Epoch [36/100], Step [211/735], Loss: 0.0182
Epoch [36/100], Step [221/735], Loss: 0.0025
Epoch [36/100], Step [231/735], Loss: 0.0217
Epoch [36/100], Step [241/735], Loss: 0.0127
Epoch [36/100], Step [251/735], Loss: 0.0034
Epoch [36/100], Step [261/735], Loss: 0.0037
Epoch [36/100], Step [271/735], Loss: 0.0250
Epoch [36/100], Step [281/735], Loss: 0.0132
Epoch [36/100], Step [291/735], Loss: 0.0136
Epoch [36/100], Step [301/735], Loss: 0.0134
Epoch [36/100], Step [311/735], Loss: 0.0030
Epoch [36/100], Step [321/735], Loss: 0.0006
Epoch [36/100], Step [331/735], Loss: 0.0013
Epoch [36/100], Step [341/735], Loss: 0.0224
Epoch [36/100], Step [351/735], Loss: 0.0194
Epoch [36/100], Step [361/735], Loss: 0.0235
Epoch [36/100], Step [371/735], Loss: 0.0005
Epoch [36/100], Step [381/735], Loss: 0.0026
Epoch [36/100], Step [391/735], Loss: 0.0181
Epoch [36/100], Step [401/735], Loss: 0.0279
Epoch [36/100], Step [411/735], Loss: 0.0277
Epoch [36/100], Step [421/735], Loss: 0.0145
Epoch [36/100], Step [431/735], Loss: 0.0085
Epoch [36/100], Step [441/735], Loss: 0.0154
Epoch [36/100], Step [451/735], Loss: 0.0271
Epoch [36/100], Step [461/735], Loss: 0.0130
Epoch [36/100], Step [471/735], Loss: 0.0145
Epoch [36/100], Step [481/735], Loss: 0.0305
Epoch [36/100], Step [491/735], Loss: 0.0135
Epoch [36/100], Step [501/735], Loss: 0.0051
Epoch [36/100], Step [511/735], Loss: 0.0259
Epoch [36/100], Step [521/735], Loss: 0.0154
Epoch [36/100], Step [531/735], Loss: 0.0217
Epoch [36/100], Step [541/735], Loss: 0.0307
Epoch [36/100], Step [551/735], Loss: 0.0125
Epoch [36/100], Step [561/735], Loss: 0.0171
Epoch [36/100], Step [571/735], Loss: 0.0002
Epoch [36/100], Step [581/735], Loss: 0.0027
Epoch [36/100], Step [591/735], Loss: 0.0002
Epoch [36/100], Step [601/735], Loss: 0.0336
Epoch [36/100], Step [611/735], Loss: 0.0150
Epoch [36/100], Step [621/735], Loss: 0.0155
Epoch [36/100], Step [631/735], Loss: 0.0353
Epoch [36/100], Step [641/735], Loss: 0.0146
Epoch [36/100], Step [651/735], Loss: 0.0115
Epoch [36/100], Step [661/735], Loss: 0.0350
Epoch [36/100], Step [671/735], Loss: 0.0043
Epoch [36/100], Step [681/735], Loss: 0.0002
Epoch [36/100], Step [691/735], Loss: 0.0243
Epoch [36/100], Step [701/735], Loss: 0.0054
Epoch [36/100], Step [711/735], Loss: 0.0018
Epoch [36/100], Step [721/735], Loss: 0.0146
Epoch [36/100], Step [731/735], Loss: 0.0018
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9084,Val AUC: 0.9504,Val precision: 0.8267, Val recall: 0.8536, Val Loss: 0.0772
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 36 | Time taken: 2249.63s |
| Val CE loss: 0.07719 | Val MSE 0.90838 | Train Loss 0.01541 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 37
Training for epoch 37
Epoch [37/100], Step [1/735], Loss: 0.0138
Epoch [37/100], Step [11/735], Loss: 0.0021
Epoch [37/100], Step [21/735], Loss: 0.0157
Epoch [37/100], Step [31/735], Loss: 0.0241
Epoch [37/100], Step [41/735], Loss: 0.0541
Epoch [37/100], Step [51/735], Loss: 0.0122
Epoch [37/100], Step [61/735], Loss: 0.0186
Epoch [37/100], Step [71/735], Loss: 0.0043
Epoch [37/100], Step [81/735], Loss: 0.0028
Epoch [37/100], Step [91/735], Loss: 0.0097
Epoch [37/100], Step [101/735], Loss: 0.0002
Epoch [37/100], Step [111/735], Loss: 0.0038
Epoch [37/100], Step [121/735], Loss: 0.0140
Epoch [37/100], Step [131/735], Loss: 0.0008
Epoch [37/100], Step [141/735], Loss: 0.0156
Epoch [37/100], Step [151/735], Loss: 0.0015
Epoch [37/100], Step [161/735], Loss: 0.0070
Epoch [37/100], Step [171/735], Loss: 0.0189
Epoch [37/100], Step [181/735], Loss: 0.0345
Epoch [37/100], Step [191/735], Loss: 0.0043
Epoch [37/100], Step [201/735], Loss: 0.0033
Epoch [37/100], Step [211/735], Loss: 0.0110
Epoch [37/100], Step [221/735], Loss: 0.0141
Epoch [37/100], Step [231/735], Loss: 0.0109
Epoch [37/100], Step [241/735], Loss: 0.0133
Epoch [37/100], Step [251/735], Loss: 0.0151
Epoch [37/100], Step [261/735], Loss: 0.0223
Epoch [37/100], Step [271/735], Loss: 0.0130
Epoch [37/100], Step [281/735], Loss: 0.0155
Epoch [37/100], Step [291/735], Loss: 0.0014
Epoch [37/100], Step [301/735], Loss: 0.0243
Epoch [37/100], Step [311/735], Loss: 0.0164
Epoch [37/100], Step [321/735], Loss: 0.0453
Epoch [37/100], Step [331/735], Loss: 0.0005
Epoch [37/100], Step [341/735], Loss: 0.0255
Epoch [37/100], Step [351/735], Loss: 0.0215
Epoch [37/100], Step [361/735], Loss: 0.0113
Epoch [37/100], Step [371/735], Loss: 0.0091
Epoch [37/100], Step [381/735], Loss: 0.0006
Epoch [37/100], Step [391/735], Loss: 0.0261
Epoch [37/100], Step [401/735], Loss: 0.0109
Epoch [37/100], Step [411/735], Loss: 0.0001
Epoch [37/100], Step [421/735], Loss: 0.0130
Epoch [37/100], Step [431/735], Loss: 0.0131
Epoch [37/100], Step [441/735], Loss: 0.0075
Epoch [37/100], Step [451/735], Loss: 0.0251
Epoch [37/100], Step [461/735], Loss: 0.0031
Epoch [37/100], Step [471/735], Loss: 0.0113
Epoch [37/100], Step [481/735], Loss: 0.0189
Epoch [37/100], Step [491/735], Loss: 0.0010
Epoch [37/100], Step [501/735], Loss: 0.0289
Epoch [37/100], Step [511/735], Loss: 0.0141
Epoch [37/100], Step [521/735], Loss: 0.0155
Epoch [37/100], Step [531/735], Loss: 0.0144
Epoch [37/100], Step [541/735], Loss: 0.0063
Epoch [37/100], Step [551/735], Loss: 0.0205
Epoch [37/100], Step [561/735], Loss: 0.0058
Epoch [37/100], Step [571/735], Loss: 0.0145
Epoch [37/100], Step [581/735], Loss: 0.0036
Epoch [37/100], Step [591/735], Loss: 0.0002
Epoch [37/100], Step [601/735], Loss: 0.0318
Epoch [37/100], Step [611/735], Loss: 0.0315
Epoch [37/100], Step [621/735], Loss: 0.0009
Epoch [37/100], Step [631/735], Loss: 0.0204
Epoch [37/100], Step [641/735], Loss: 0.0019
Epoch [37/100], Step [651/735], Loss: 0.0312
Epoch [37/100], Step [661/735], Loss: 0.0151
Epoch [37/100], Step [671/735], Loss: 0.0150
Epoch [37/100], Step [681/735], Loss: 0.0349
Epoch [37/100], Step [691/735], Loss: 0.0020
Epoch [37/100], Step [701/735], Loss: 0.0007
Epoch [37/100], Step [711/735], Loss: 0.0088
Epoch [37/100], Step [721/735], Loss: 0.0215
Epoch [37/100], Step [731/735], Loss: 0.0236
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9087,Val AUC: 0.9513,Val precision: 0.8246, Val recall: 0.8585, Val Loss: 0.0765
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 37 | Time taken: 2246.90s |
| Val CE loss: 0.07651 | Val MSE 0.90873 | Train Loss 0.01450 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 38
Training for epoch 38
Epoch [38/100], Step [1/735], Loss: 0.0044
Epoch [38/100], Step [11/735], Loss: 0.0012
Epoch [38/100], Step [21/735], Loss: 0.0024
Epoch [38/100], Step [31/735], Loss: 0.0125
Epoch [38/100], Step [41/735], Loss: 0.0060
Epoch [38/100], Step [51/735], Loss: 0.0154
Epoch [38/100], Step [61/735], Loss: 0.0207
Epoch [38/100], Step [71/735], Loss: 0.0196
Epoch [38/100], Step [81/735], Loss: 0.0182
Epoch [38/100], Step [91/735], Loss: 0.0146
Epoch [38/100], Step [101/735], Loss: 0.0008
Epoch [38/100], Step [111/735], Loss: 0.0281
Epoch [38/100], Step [121/735], Loss: 0.0144
Epoch [38/100], Step [131/735], Loss: 0.0286
Epoch [38/100], Step [141/735], Loss: 0.0282
Epoch [38/100], Step [151/735], Loss: 0.0259
Epoch [38/100], Step [161/735], Loss: 0.0270
Epoch [38/100], Step [171/735], Loss: 0.0057
Epoch [38/100], Step [181/735], Loss: 0.0031
Epoch [38/100], Step [191/735], Loss: 0.0236
Epoch [38/100], Step [201/735], Loss: 0.0432
Epoch [38/100], Step [211/735], Loss: 0.0186
Epoch [38/100], Step [221/735], Loss: 0.0016
Epoch [38/100], Step [231/735], Loss: 0.0171
Epoch [38/100], Step [241/735], Loss: 0.0066
Epoch [38/100], Step [251/735], Loss: 0.0025
Epoch [38/100], Step [261/735], Loss: 0.0038
Epoch [38/100], Step [271/735], Loss: 0.0287
Epoch [38/100], Step [281/735], Loss: 0.0181
Epoch [38/100], Step [291/735], Loss: 0.0114
Epoch [38/100], Step [301/735], Loss: 0.0210
Epoch [38/100], Step [311/735], Loss: 0.0170
Epoch [38/100], Step [321/735], Loss: 0.0393
Epoch [38/100], Step [331/735], Loss: 0.0013
Epoch [38/100], Step [341/735], Loss: 0.0125
Epoch [38/100], Step [351/735], Loss: 0.0307
Epoch [38/100], Step [361/735], Loss: 0.0116
Epoch [38/100], Step [371/735], Loss: 0.0163
Epoch [38/100], Step [381/735], Loss: 0.0008
Epoch [38/100], Step [391/735], Loss: 0.0105
Epoch [38/100], Step [401/735], Loss: 0.0078
Epoch [38/100], Step [411/735], Loss: 0.0553
Epoch [38/100], Step [421/735], Loss: 0.0137
Epoch [38/100], Step [431/735], Loss: 0.0152
Epoch [38/100], Step [441/735], Loss: 0.0142
Epoch [38/100], Step [451/735], Loss: 0.0304
Epoch [38/100], Step [461/735], Loss: 0.0031
Epoch [38/100], Step [471/735], Loss: 0.0081
Epoch [38/100], Step [481/735], Loss: 0.0094
Epoch [38/100], Step [491/735], Loss: 0.0396
Epoch [38/100], Step [501/735], Loss: 0.0126
Epoch [38/100], Step [511/735], Loss: 0.0084
Epoch [38/100], Step [521/735], Loss: 0.0193
Epoch [38/100], Step [531/735], Loss: 0.0145
Epoch [38/100], Step [541/735], Loss: 0.0066
Epoch [38/100], Step [551/735], Loss: 0.0003
Epoch [38/100], Step [561/735], Loss: 0.0182
Epoch [38/100], Step [571/735], Loss: 0.0072
Epoch [38/100], Step [581/735], Loss: 0.0044
Epoch [38/100], Step [591/735], Loss: 0.0082
Epoch [38/100], Step [601/735], Loss: 0.0201
Epoch [38/100], Step [611/735], Loss: 0.0136
Epoch [38/100], Step [621/735], Loss: 0.0271
Epoch [38/100], Step [631/735], Loss: 0.0026
Epoch [38/100], Step [641/735], Loss: 0.0276
Epoch [38/100], Step [651/735], Loss: 0.0153
Epoch [38/100], Step [661/735], Loss: 0.0146
Epoch [38/100], Step [671/735], Loss: 0.0072
Epoch [38/100], Step [681/735], Loss: 0.0110
Epoch [38/100], Step [691/735], Loss: 0.0235
Epoch [38/100], Step [701/735], Loss: 0.0444
Epoch [38/100], Step [711/735], Loss: 0.0017
Epoch [38/100], Step [721/735], Loss: 0.0013
Epoch [38/100], Step [731/735], Loss: 0.0005
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9061,Val AUC: 0.9545,Val precision: 0.8129, Val recall: 0.8659, Val Loss: 0.0777
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 38 | Time taken: 2249.90s |
| Val CE loss: 0.07771 | Val MSE 0.90613 | Train Loss 0.01428 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 39
Training for epoch 39
Epoch [39/100], Step [1/735], Loss: 0.0027
Epoch [39/100], Step [11/735], Loss: 0.0279
Epoch [39/100], Step [21/735], Loss: 0.0061
Epoch [39/100], Step [31/735], Loss: 0.0126
Epoch [39/100], Step [41/735], Loss: 0.0121
Epoch [39/100], Step [51/735], Loss: 0.0060
Epoch [39/100], Step [61/735], Loss: 0.0040
Epoch [39/100], Step [71/735], Loss: 0.0092
Epoch [39/100], Step [81/735], Loss: 0.0532
Epoch [39/100], Step [91/735], Loss: 0.0230
Epoch [39/100], Step [101/735], Loss: 0.0073
Epoch [39/100], Step [111/735], Loss: 0.0151
Epoch [39/100], Step [121/735], Loss: 0.0038
Epoch [39/100], Step [131/735], Loss: 0.0379
Epoch [39/100], Step [141/735], Loss: 0.0298
Epoch [39/100], Step [151/735], Loss: 0.0126
Epoch [39/100], Step [161/735], Loss: 0.0131
Epoch [39/100], Step [171/735], Loss: 0.0288
Epoch [39/100], Step [181/735], Loss: 0.0238
Epoch [39/100], Step [191/735], Loss: 0.0145
Epoch [39/100], Step [201/735], Loss: 0.0251
Epoch [39/100], Step [211/735], Loss: 0.0010
Epoch [39/100], Step [221/735], Loss: 0.0520
Epoch [39/100], Step [231/735], Loss: 0.0110
Epoch [39/100], Step [241/735], Loss: 0.0107
Epoch [39/100], Step [251/735], Loss: 0.0177
Epoch [39/100], Step [261/735], Loss: 0.0066
Epoch [39/100], Step [271/735], Loss: 0.0011
Epoch [39/100], Step [281/735], Loss: 0.0031
Epoch [39/100], Step [291/735], Loss: 0.0018
Epoch [39/100], Step [301/735], Loss: 0.0206
Epoch [39/100], Step [311/735], Loss: 0.0275
Epoch [39/100], Step [321/735], Loss: 0.0041
Epoch [39/100], Step [331/735], Loss: 0.0014
Epoch [39/100], Step [341/735], Loss: 0.0103
Epoch [39/100], Step [351/735], Loss: 0.0003
Epoch [39/100], Step [361/735], Loss: 0.0015
Epoch [39/100], Step [371/735], Loss: 0.0033
Epoch [39/100], Step [381/735], Loss: 0.0128
Epoch [39/100], Step [391/735], Loss: 0.0162
Epoch [39/100], Step [401/735], Loss: 0.0125
Epoch [39/100], Step [411/735], Loss: 0.0072
Epoch [39/100], Step [421/735], Loss: 0.0181
Epoch [39/100], Step [431/735], Loss: 0.0297
Epoch [39/100], Step [441/735], Loss: 0.0109
Epoch [39/100], Step [451/735], Loss: 0.0336
Epoch [39/100], Step [461/735], Loss: 0.0032
Epoch [39/100], Step [471/735], Loss: 0.0474
Epoch [39/100], Step [481/735], Loss: 0.0122
Epoch [39/100], Step [491/735], Loss: 0.0142
Epoch [39/100], Step [501/735], Loss: 0.0010
Epoch [39/100], Step [511/735], Loss: 0.0002
Epoch [39/100], Step [521/735], Loss: 0.0127
Epoch [39/100], Step [531/735], Loss: 0.0271
Epoch [39/100], Step [541/735], Loss: 0.0476
Epoch [39/100], Step [551/735], Loss: 0.0079
Epoch [39/100], Step [561/735], Loss: 0.0209
Epoch [39/100], Step [571/735], Loss: 0.0134
Epoch [39/100], Step [581/735], Loss: 0.0031
Epoch [39/100], Step [591/735], Loss: 0.0069
Epoch [39/100], Step [601/735], Loss: 0.0026
Epoch [39/100], Step [611/735], Loss: 0.0260
Epoch [39/100], Step [621/735], Loss: 0.0161
Epoch [39/100], Step [631/735], Loss: 0.0033
Epoch [39/100], Step [641/735], Loss: 0.0371
Epoch [39/100], Step [651/735], Loss: 0.0377
Epoch [39/100], Step [661/735], Loss: 0.0032
Epoch [39/100], Step [671/735], Loss: 0.0159
Epoch [39/100], Step [681/735], Loss: 0.0018
Epoch [39/100], Step [691/735], Loss: 0.0218
Epoch [39/100], Step [701/735], Loss: 0.0111
Epoch [39/100], Step [711/735], Loss: 0.0009
Epoch [39/100], Step [721/735], Loss: 0.0275
Epoch [39/100], Step [731/735], Loss: 0.0020
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9131,Val AUC: 0.9543,Val precision: 0.8333, Val recall: 0.8641, Val Loss: 0.0750
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 39 | Time taken: 2235.42s |
| Val CE loss: 0.07503 | Val MSE 0.91306 | Train Loss 0.01373 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 40
Training for epoch 40
Epoch [40/100], Step [1/735], Loss: 0.0006
Epoch [40/100], Step [11/735], Loss: 0.0015
Epoch [40/100], Step [21/735], Loss: 0.0012
Epoch [40/100], Step [31/735], Loss: 0.0421
Epoch [40/100], Step [41/735], Loss: 0.0214
Epoch [40/100], Step [51/735], Loss: 0.0028
Epoch [40/100], Step [61/735], Loss: 0.0309
Epoch [40/100], Step [71/735], Loss: 0.0218
Epoch [40/100], Step [81/735], Loss: 0.0058
Epoch [40/100], Step [91/735], Loss: 0.0005
Epoch [40/100], Step [101/735], Loss: 0.0158
Epoch [40/100], Step [111/735], Loss: 0.0260
Epoch [40/100], Step [121/735], Loss: 0.0276
Epoch [40/100], Step [131/735], Loss: 0.0035
Epoch [40/100], Step [141/735], Loss: 0.0226
Epoch [40/100], Step [151/735], Loss: 0.0046
Epoch [40/100], Step [161/735], Loss: 0.0261
Epoch [40/100], Step [171/735], Loss: 0.0308
Epoch [40/100], Step [181/735], Loss: 0.0020
Epoch [40/100], Step [191/735], Loss: 0.0002
Epoch [40/100], Step [201/735], Loss: 0.0103
Epoch [40/100], Step [211/735], Loss: 0.0066
Epoch [40/100], Step [221/735], Loss: 0.0231
Epoch [40/100], Step [231/735], Loss: 0.0004
Epoch [40/100], Step [241/735], Loss: 0.0003
Epoch [40/100], Step [251/735], Loss: 0.0322
Epoch [40/100], Step [261/735], Loss: 0.0167
Epoch [40/100], Step [271/735], Loss: 0.0319
Epoch [40/100], Step [281/735], Loss: 0.0126
Epoch [40/100], Step [291/735], Loss: 0.0220
Epoch [40/100], Step [301/735], Loss: 0.0474
Epoch [40/100], Step [311/735], Loss: 0.0040
Epoch [40/100], Step [321/735], Loss: 0.0205
Epoch [40/100], Step [331/735], Loss: 0.0431
Epoch [40/100], Step [341/735], Loss: 0.0039
Epoch [40/100], Step [351/735], Loss: 0.0055
Epoch [40/100], Step [361/735], Loss: 0.0014
Epoch [40/100], Step [371/735], Loss: 0.0142
Epoch [40/100], Step [381/735], Loss: 0.0147
Epoch [40/100], Step [391/735], Loss: 0.0205
Epoch [40/100], Step [401/735], Loss: 0.0151
Epoch [40/100], Step [411/735], Loss: 0.0011
Epoch [40/100], Step [421/735], Loss: 0.0138
Epoch [40/100], Step [431/735], Loss: 0.0184
Epoch [40/100], Step [441/735], Loss: 0.0072
Epoch [40/100], Step [451/735], Loss: 0.0255
Epoch [40/100], Step [461/735], Loss: 0.0186
Epoch [40/100], Step [471/735], Loss: 0.0352
Epoch [40/100], Step [481/735], Loss: 0.0097
Epoch [40/100], Step [491/735], Loss: 0.0065
Epoch [40/100], Step [501/735], Loss: 0.0289
Epoch [40/100], Step [511/735], Loss: 0.0019
Epoch [40/100], Step [521/735], Loss: 0.0077
Epoch [40/100], Step [531/735], Loss: 0.0197
Epoch [40/100], Step [541/735], Loss: 0.0002
Epoch [40/100], Step [551/735], Loss: 0.0145
Epoch [40/100], Step [561/735], Loss: 0.0005
Epoch [40/100], Step [571/735], Loss: 0.0223
Epoch [40/100], Step [581/735], Loss: 0.0049
Epoch [40/100], Step [591/735], Loss: 0.0169
Epoch [40/100], Step [601/735], Loss: 0.0154
Epoch [40/100], Step [611/735], Loss: 0.0154
Epoch [40/100], Step [621/735], Loss: 0.0171
Epoch [40/100], Step [631/735], Loss: 0.0001
Epoch [40/100], Step [641/735], Loss: 0.0132
Epoch [40/100], Step [651/735], Loss: 0.0301
Epoch [40/100], Step [661/735], Loss: 0.0382
Epoch [40/100], Step [671/735], Loss: 0.0019
Epoch [40/100], Step [681/735], Loss: 0.0119
Epoch [40/100], Step [691/735], Loss: 0.0020
Epoch [40/100], Step [701/735], Loss: 0.0220
Epoch [40/100], Step [711/735], Loss: 0.0257
Epoch [40/100], Step [721/735], Loss: 0.0004
Epoch [40/100], Step [731/735], Loss: 0.0290
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9181,Val AUC: 0.9528,Val precision: 0.8746, Val recall: 0.8278, Val Loss: 0.0705
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 40 | Time taken: 2215.14s |
| Val CE loss: 0.07053 | Val MSE 0.91808 | Train Loss 0.01374 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 41
Training for epoch 41
Epoch [41/100], Step [1/735], Loss: 0.0028
Epoch [41/100], Step [11/735], Loss: 0.0213
Epoch [41/100], Step [21/735], Loss: 0.0224
Epoch [41/100], Step [31/735], Loss: 0.0016
Epoch [41/100], Step [41/735], Loss: 0.0156
Epoch [41/100], Step [51/735], Loss: 0.0222
Epoch [41/100], Step [61/735], Loss: 0.0004
Epoch [41/100], Step [71/735], Loss: 0.0420
Epoch [41/100], Step [81/735], Loss: 0.0002
Epoch [41/100], Step [91/735], Loss: 0.0208
Epoch [41/100], Step [101/735], Loss: 0.0264
Epoch [41/100], Step [111/735], Loss: 0.0003
Epoch [41/100], Step [121/735], Loss: 0.0119
Epoch [41/100], Step [131/735], Loss: 0.0011
Epoch [41/100], Step [141/735], Loss: 0.0121
Epoch [41/100], Step [151/735], Loss: 0.0002
Epoch [41/100], Step [161/735], Loss: 0.0001
Epoch [41/100], Step [171/735], Loss: 0.0047
Epoch [41/100], Step [181/735], Loss: 0.0250
Epoch [41/100], Step [191/735], Loss: 0.0477
Epoch [41/100], Step [201/735], Loss: 0.0010
Epoch [41/100], Step [211/735], Loss: 0.0443
Epoch [41/100], Step [221/735], Loss: 0.0035
Epoch [41/100], Step [231/735], Loss: 0.0307
Epoch [41/100], Step [241/735], Loss: 0.0057
Epoch [41/100], Step [251/735], Loss: 0.0303
Epoch [41/100], Step [261/735], Loss: 0.0013
Epoch [41/100], Step [271/735], Loss: 0.0030
Epoch [41/100], Step [281/735], Loss: 0.0030
Epoch [41/100], Step [291/735], Loss: 0.0166
Epoch [41/100], Step [301/735], Loss: 0.0170
Epoch [41/100], Step [311/735], Loss: 0.0202
Epoch [41/100], Step [321/735], Loss: 0.0075
Epoch [41/100], Step [331/735], Loss: 0.0235
Epoch [41/100], Step [341/735], Loss: 0.0007
Epoch [41/100], Step [351/735], Loss: 0.0113
Epoch [41/100], Step [361/735], Loss: 0.0008
Epoch [41/100], Step [371/735], Loss: 0.0142
Epoch [41/100], Step [381/735], Loss: 0.0002
Epoch [41/100], Step [391/735], Loss: 0.0008
Epoch [41/100], Step [401/735], Loss: 0.0153
Epoch [41/100], Step [411/735], Loss: 0.0384
Epoch [41/100], Step [421/735], Loss: 0.0117
Epoch [41/100], Step [431/735], Loss: 0.0108
Epoch [41/100], Step [441/735], Loss: 0.0013
Epoch [41/100], Step [451/735], Loss: 0.0111
Epoch [41/100], Step [461/735], Loss: 0.0160
Epoch [41/100], Step [471/735], Loss: 0.0104
Epoch [41/100], Step [481/735], Loss: 0.0010
Epoch [41/100], Step [491/735], Loss: 0.0097
Epoch [41/100], Step [501/735], Loss: 0.0006
Epoch [41/100], Step [511/735], Loss: 0.0006
Epoch [41/100], Step [521/735], Loss: 0.0005
Epoch [41/100], Step [531/735], Loss: 0.0101
Epoch [41/100], Step [541/735], Loss: 0.0003
Epoch [41/100], Step [551/735], Loss: 0.0108
Epoch [41/100], Step [561/735], Loss: 0.0011
Epoch [41/100], Step [571/735], Loss: 0.0242
Epoch [41/100], Step [581/735], Loss: 0.0389
Epoch [41/100], Step [591/735], Loss: 0.0195
Epoch [41/100], Step [601/735], Loss: 0.0141
Epoch [41/100], Step [611/735], Loss: 0.0131
Epoch [41/100], Step [621/735], Loss: 0.0142
Epoch [41/100], Step [631/735], Loss: 0.0011
Epoch [41/100], Step [641/735], Loss: 0.0005
Epoch [41/100], Step [651/735], Loss: 0.0005
Epoch [41/100], Step [661/735], Loss: 0.0046
Epoch [41/100], Step [671/735], Loss: 0.0303
Epoch [41/100], Step [681/735], Loss: 0.0013
Epoch [41/100], Step [691/735], Loss: 0.0023
Epoch [41/100], Step [701/735], Loss: 0.0005
Epoch [41/100], Step [711/735], Loss: 0.0232
Epoch [41/100], Step [721/735], Loss: 0.0005
Epoch [41/100], Step [731/735], Loss: 0.0417
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9122,Val AUC: 0.9572,Val precision: 0.8229, Val recall: 0.8770, Val Loss: 0.0746
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 41 | Time taken: 2226.81s |
| Val CE loss: 0.07461 | Val MSE 0.91219 | Train Loss 0.01267 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 42
Training for epoch 42
Epoch [42/100], Step [1/735], Loss: 0.0021
Epoch [42/100], Step [11/735], Loss: 0.0002
Epoch [42/100], Step [21/735], Loss: 0.0065
Epoch [42/100], Step [31/735], Loss: 0.0102
Epoch [42/100], Step [41/735], Loss: 0.0229
Epoch [42/100], Step [51/735], Loss: 0.0306
Epoch [42/100], Step [61/735], Loss: 0.0005
Epoch [42/100], Step [71/735], Loss: 0.0173
Epoch [42/100], Step [81/735], Loss: 0.0041
Epoch [42/100], Step [91/735], Loss: 0.0140
Epoch [42/100], Step [101/735], Loss: 0.0188
Epoch [42/100], Step [111/735], Loss: 0.0212
Epoch [42/100], Step [121/735], Loss: 0.0044
Epoch [42/100], Step [131/735], Loss: 0.0019
Epoch [42/100], Step [141/735], Loss: 0.0035
Epoch [42/100], Step [151/735], Loss: 0.0139
Epoch [42/100], Step [161/735], Loss: 0.0067
Epoch [42/100], Step [171/735], Loss: 0.0029
Epoch [42/100], Step [181/735], Loss: 0.0068
Epoch [42/100], Step [191/735], Loss: 0.0018
Epoch [42/100], Step [201/735], Loss: 0.0194
Epoch [42/100], Step [211/735], Loss: 0.0133
Epoch [42/100], Step [221/735], Loss: 0.0352
Epoch [42/100], Step [231/735], Loss: 0.0224
Epoch [42/100], Step [241/735], Loss: 0.0150
Epoch [42/100], Step [251/735], Loss: 0.0149
Epoch [42/100], Step [261/735], Loss: 0.0143
Epoch [42/100], Step [271/735], Loss: 0.0017
Epoch [42/100], Step [281/735], Loss: 0.0153
Epoch [42/100], Step [291/735], Loss: 0.0098
Epoch [42/100], Step [301/735], Loss: 0.0004
Epoch [42/100], Step [311/735], Loss: 0.0143
Epoch [42/100], Step [321/735], Loss: 0.0400
Epoch [42/100], Step [331/735], Loss: 0.0004
Epoch [42/100], Step [341/735], Loss: 0.0123
Epoch [42/100], Step [351/735], Loss: 0.0076
Epoch [42/100], Step [361/735], Loss: 0.0005
Epoch [42/100], Step [371/735], Loss: 0.0084
Epoch [42/100], Step [381/735], Loss: 0.0087
Epoch [42/100], Step [391/735], Loss: 0.0063
Epoch [42/100], Step [401/735], Loss: 0.0137
Epoch [42/100], Step [411/735], Loss: 0.0022
Epoch [42/100], Step [421/735], Loss: 0.0001
Epoch [42/100], Step [431/735], Loss: 0.0021
Epoch [42/100], Step [441/735], Loss: 0.0036
Epoch [42/100], Step [451/735], Loss: 0.0034
Epoch [42/100], Step [461/735], Loss: 0.0023
Epoch [42/100], Step [471/735], Loss: 0.0139
Epoch [42/100], Step [481/735], Loss: 0.0155
Epoch [42/100], Step [491/735], Loss: 0.0007
Epoch [42/100], Step [501/735], Loss: 0.0106
Epoch [42/100], Step [511/735], Loss: 0.0325
Epoch [42/100], Step [521/735], Loss: 0.0213
Epoch [42/100], Step [531/735], Loss: 0.0089
Epoch [42/100], Step [541/735], Loss: 0.0013
Epoch [42/100], Step [551/735], Loss: 0.0271
Epoch [42/100], Step [561/735], Loss: 0.0004
Epoch [42/100], Step [571/735], Loss: 0.0277
Epoch [42/100], Step [581/735], Loss: 0.0035
Epoch [42/100], Step [591/735], Loss: 0.0002
Epoch [42/100], Step [601/735], Loss: 0.0127
Epoch [42/100], Step [611/735], Loss: 0.0271
Epoch [42/100], Step [621/735], Loss: 0.0009
Epoch [42/100], Step [631/735], Loss: 0.0062
Epoch [42/100], Step [641/735], Loss: 0.0146
Epoch [42/100], Step [651/735], Loss: 0.0143
Epoch [42/100], Step [661/735], Loss: 0.0175
Epoch [42/100], Step [671/735], Loss: 0.0113
Epoch [42/100], Step [681/735], Loss: 0.0143
Epoch [42/100], Step [691/735], Loss: 0.0091
Epoch [42/100], Step [701/735], Loss: 0.0221
Epoch [42/100], Step [711/735], Loss: 0.0011
Epoch [42/100], Step [721/735], Loss: 0.0158
Epoch [42/100], Step [731/735], Loss: 0.0319
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9065,Val AUC: 0.9504,Val precision: 0.8194, Val recall: 0.8567, Val Loss: 0.0806
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 42 | Time taken: 2246.86s |
| Val CE loss: 0.08060 | Val MSE 0.90648 | Train Loss 0.01297 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 43
Training for epoch 43
Epoch [43/100], Step [1/735], Loss: 0.0155
Epoch [43/100], Step [11/735], Loss: 0.0060
Epoch [43/100], Step [21/735], Loss: 0.0218
Epoch [43/100], Step [31/735], Loss: 0.0128
Epoch [43/100], Step [41/735], Loss: 0.0016
Epoch [43/100], Step [51/735], Loss: 0.0279
Epoch [43/100], Step [61/735], Loss: 0.0259
Epoch [43/100], Step [71/735], Loss: 0.0001
Epoch [43/100], Step [81/735], Loss: 0.0343
Epoch [43/100], Step [91/735], Loss: 0.0211
Epoch [43/100], Step [101/735], Loss: 0.0067
Epoch [43/100], Step [111/735], Loss: 0.0071
Epoch [43/100], Step [121/735], Loss: 0.0020
Epoch [43/100], Step [131/735], Loss: 0.0394
Epoch [43/100], Step [141/735], Loss: 0.0013
Epoch [43/100], Step [151/735], Loss: 0.0113
Epoch [43/100], Step [161/735], Loss: 0.0109
Epoch [43/100], Step [171/735], Loss: 0.0090
Epoch [43/100], Step [181/735], Loss: 0.0062
Epoch [43/100], Step [191/735], Loss: 0.0295
Epoch [43/100], Step [201/735], Loss: 0.0045
Epoch [43/100], Step [211/735], Loss: 0.0392
Epoch [43/100], Step [221/735], Loss: 0.0238
Epoch [43/100], Step [231/735], Loss: 0.0218
Epoch [43/100], Step [241/735], Loss: 0.0138
Epoch [43/100], Step [251/735], Loss: 0.0012
Epoch [43/100], Step [261/735], Loss: 0.0128
Epoch [43/100], Step [271/735], Loss: 0.0265
Epoch [43/100], Step [281/735], Loss: 0.0029
Epoch [43/100], Step [291/735], Loss: 0.0218
Epoch [43/100], Step [301/735], Loss: 0.0296
Epoch [43/100], Step [311/735], Loss: 0.0064
Epoch [43/100], Step [321/735], Loss: 0.0018
Epoch [43/100], Step [331/735], Loss: 0.0045
Epoch [43/100], Step [341/735], Loss: 0.0330
Epoch [43/100], Step [351/735], Loss: 0.0279
Epoch [43/100], Step [361/735], Loss: 0.0020
Epoch [43/100], Step [371/735], Loss: 0.0058
Epoch [43/100], Step [381/735], Loss: 0.0041
Epoch [43/100], Step [391/735], Loss: 0.0130
Epoch [43/100], Step [401/735], Loss: 0.0242
Epoch [43/100], Step [411/735], Loss: 0.0066
Epoch [43/100], Step [421/735], Loss: 0.0133
Epoch [43/100], Step [431/735], Loss: 0.0138
Epoch [43/100], Step [441/735], Loss: 0.0131
Epoch [43/100], Step [451/735], Loss: 0.0118
Epoch [43/100], Step [461/735], Loss: 0.0026
Epoch [43/100], Step [471/735], Loss: 0.0014
Epoch [43/100], Step [481/735], Loss: 0.0105
Epoch [43/100], Step [491/735], Loss: 0.0002
Epoch [43/100], Step [501/735], Loss: 0.0135
Epoch [43/100], Step [511/735], Loss: 0.0195
Epoch [43/100], Step [521/735], Loss: 0.0457
Epoch [43/100], Step [531/735], Loss: 0.0026
Epoch [43/100], Step [541/735], Loss: 0.0021
Epoch [43/100], Step [551/735], Loss: 0.0022
Epoch [43/100], Step [561/735], Loss: 0.0308
Epoch [43/100], Step [571/735], Loss: 0.0003
Epoch [43/100], Step [581/735], Loss: 0.0003
Epoch [43/100], Step [591/735], Loss: 0.0038
Epoch [43/100], Step [601/735], Loss: 0.0153
Epoch [43/100], Step [611/735], Loss: 0.0058
Epoch [43/100], Step [621/735], Loss: 0.0215
Epoch [43/100], Step [631/735], Loss: 0.0119
Epoch [43/100], Step [641/735], Loss: 0.0070
Epoch [43/100], Step [651/735], Loss: 0.0286
Epoch [43/100], Step [661/735], Loss: 0.0290
Epoch [43/100], Step [671/735], Loss: 0.0388
Epoch [43/100], Step [681/735], Loss: 0.0037
Epoch [43/100], Step [691/735], Loss: 0.0231
Epoch [43/100], Step [701/735], Loss: 0.0001
Epoch [43/100], Step [711/735], Loss: 0.0067
Epoch [43/100], Step [721/735], Loss: 0.0002
Epoch [43/100], Step [731/735], Loss: 0.0021
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9163,Val AUC: 0.9553,Val precision: 0.8483, Val recall: 0.8561, Val Loss: 0.0703
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 43 | Time taken: 2240.49s |
| Val CE loss: 0.07028 | Val MSE 0.91635 | Train Loss 0.01305 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 44
Training for epoch 44
Epoch [44/100], Step [1/735], Loss: 0.0274
Epoch [44/100], Step [11/735], Loss: 0.0011
Epoch [44/100], Step [21/735], Loss: 0.0004
Epoch [44/100], Step [31/735], Loss: 0.0075
Epoch [44/100], Step [41/735], Loss: 0.0002
Epoch [44/100], Step [51/735], Loss: 0.0170
Epoch [44/100], Step [61/735], Loss: 0.0010
Epoch [44/100], Step [71/735], Loss: 0.0111
Epoch [44/100], Step [81/735], Loss: 0.0156
Epoch [44/100], Step [91/735], Loss: 0.0005
Epoch [44/100], Step [101/735], Loss: 0.0005
Epoch [44/100], Step [111/735], Loss: 0.0026
Epoch [44/100], Step [121/735], Loss: 0.0163
Epoch [44/100], Step [131/735], Loss: 0.0002
Epoch [44/100], Step [141/735], Loss: 0.0267
Epoch [44/100], Step [151/735], Loss: 0.0148
Epoch [44/100], Step [161/735], Loss: 0.0158
Epoch [44/100], Step [171/735], Loss: 0.0147
Epoch [44/100], Step [181/735], Loss: 0.0082
Epoch [44/100], Step [191/735], Loss: 0.0075
Epoch [44/100], Step [201/735], Loss: 0.0225
Epoch [44/100], Step [211/735], Loss: 0.0109
Epoch [44/100], Step [221/735], Loss: 0.0092
Epoch [44/100], Step [231/735], Loss: 0.0241
Epoch [44/100], Step [241/735], Loss: 0.0011
Epoch [44/100], Step [251/735], Loss: 0.0183
Epoch [44/100], Step [261/735], Loss: 0.0103
Epoch [44/100], Step [271/735], Loss: 0.0064
Epoch [44/100], Step [281/735], Loss: 0.0014
Epoch [44/100], Step [291/735], Loss: 0.0492
Epoch [44/100], Step [301/735], Loss: 0.0319
Epoch [44/100], Step [311/735], Loss: 0.0009
Epoch [44/100], Step [321/735], Loss: 0.0004
Epoch [44/100], Step [331/735], Loss: 0.0166
Epoch [44/100], Step [341/735], Loss: 0.0045
Epoch [44/100], Step [351/735], Loss: 0.0215
Epoch [44/100], Step [361/735], Loss: 0.0261
Epoch [44/100], Step [371/735], Loss: 0.0145
Epoch [44/100], Step [381/735], Loss: 0.0041
Epoch [44/100], Step [391/735], Loss: 0.0113
Epoch [44/100], Step [401/735], Loss: 0.0137
Epoch [44/100], Step [411/735], Loss: 0.0111
Epoch [44/100], Step [421/735], Loss: 0.0042
Epoch [44/100], Step [431/735], Loss: 0.0153
Epoch [44/100], Step [441/735], Loss: 0.0043
Epoch [44/100], Step [451/735], Loss: 0.0114
Epoch [44/100], Step [461/735], Loss: 0.0051
Epoch [44/100], Step [471/735], Loss: 0.0140
Epoch [44/100], Step [481/735], Loss: 0.0144
Epoch [44/100], Step [491/735], Loss: 0.0009
Epoch [44/100], Step [501/735], Loss: 0.0043
Epoch [44/100], Step [511/735], Loss: 0.0211
Epoch [44/100], Step [521/735], Loss: 0.0002
Epoch [44/100], Step [531/735], Loss: 0.0019
Epoch [44/100], Step [541/735], Loss: 0.0092
Epoch [44/100], Step [551/735], Loss: 0.0009
Epoch [44/100], Step [561/735], Loss: 0.0149
Epoch [44/100], Step [571/735], Loss: 0.0133
Epoch [44/100], Step [581/735], Loss: 0.0159
Epoch [44/100], Step [591/735], Loss: 0.0192
Epoch [44/100], Step [601/735], Loss: 0.0052
Epoch [44/100], Step [611/735], Loss: 0.0265
Epoch [44/100], Step [621/735], Loss: 0.0260
Epoch [44/100], Step [631/735], Loss: 0.0001
Epoch [44/100], Step [641/735], Loss: 0.0011
Epoch [44/100], Step [651/735], Loss: 0.0026
Epoch [44/100], Step [661/735], Loss: 0.0080
Epoch [44/100], Step [671/735], Loss: 0.0015
Epoch [44/100], Step [681/735], Loss: 0.0012
Epoch [44/100], Step [691/735], Loss: 0.0268
Epoch [44/100], Step [701/735], Loss: 0.0309
Epoch [44/100], Step [711/735], Loss: 0.0215
Epoch [44/100], Step [721/735], Loss: 0.0051
Epoch [44/100], Step [731/735], Loss: 0.0175
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9200,Val AUC: 0.9530,Val precision: 0.8540, Val recall: 0.8635, Val Loss: 0.0689
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 44 | Time taken: 2251.32s |
| Val CE loss: 0.06893 | Val MSE 0.91999 | Train Loss 0.01247 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 45
Training for epoch 45
Epoch [45/100], Step [1/735], Loss: 0.0049
Epoch [45/100], Step [11/735], Loss: 0.0002
Epoch [45/100], Step [21/735], Loss: 0.0039
Epoch [45/100], Step [31/735], Loss: 0.0140
Epoch [45/100], Step [41/735], Loss: 0.0021
Epoch [45/100], Step [51/735], Loss: 0.0002
Epoch [45/100], Step [61/735], Loss: 0.0233
Epoch [45/100], Step [71/735], Loss: 0.0087
Epoch [45/100], Step [81/735], Loss: 0.0015
Epoch [45/100], Step [91/735], Loss: 0.0271
Epoch [45/100], Step [101/735], Loss: 0.0047
Epoch [45/100], Step [111/735], Loss: 0.0005
Epoch [45/100], Step [121/735], Loss: 0.0151
Epoch [45/100], Step [131/735], Loss: 0.0132
Epoch [45/100], Step [141/735], Loss: 0.0079
Epoch [45/100], Step [151/735], Loss: 0.0149
Epoch [45/100], Step [161/735], Loss: 0.0023
Epoch [45/100], Step [171/735], Loss: 0.0100
Epoch [45/100], Step [181/735], Loss: 0.0030
Epoch [45/100], Step [191/735], Loss: 0.0126
Epoch [45/100], Step [201/735], Loss: 0.0218
Epoch [45/100], Step [211/735], Loss: 0.0149
Epoch [45/100], Step [221/735], Loss: 0.0281
Epoch [45/100], Step [231/735], Loss: 0.0009
Epoch [45/100], Step [241/735], Loss: 0.0093
Epoch [45/100], Step [251/735], Loss: 0.0277
Epoch [45/100], Step [261/735], Loss: 0.0245
Epoch [45/100], Step [271/735], Loss: 0.0034
Epoch [45/100], Step [281/735], Loss: 0.0141
Epoch [45/100], Step [291/735], Loss: 0.0143
Epoch [45/100], Step [301/735], Loss: 0.0157
Epoch [45/100], Step [311/735], Loss: 0.0163
Epoch [45/100], Step [321/735], Loss: 0.0001
Epoch [45/100], Step [331/735], Loss: 0.0029
Epoch [45/100], Step [341/735], Loss: 0.0010
Epoch [45/100], Step [351/735], Loss: 0.0005
Epoch [45/100], Step [361/735], Loss: 0.0120
Epoch [45/100], Step [371/735], Loss: 0.0204
Epoch [45/100], Step [381/735], Loss: 0.0011
Epoch [45/100], Step [391/735], Loss: 0.0004
Epoch [45/100], Step [401/735], Loss: 0.0032
Epoch [45/100], Step [411/735], Loss: 0.0272
Epoch [45/100], Step [421/735], Loss: 0.0028
Epoch [45/100], Step [431/735], Loss: 0.0001
Epoch [45/100], Step [441/735], Loss: 0.0063
Epoch [45/100], Step [451/735], Loss: 0.0303
Epoch [45/100], Step [461/735], Loss: 0.0391
Epoch [45/100], Step [471/735], Loss: 0.0107
Epoch [45/100], Step [481/735], Loss: 0.0133
Epoch [45/100], Step [491/735], Loss: 0.0139
Epoch [45/100], Step [501/735], Loss: 0.0029
Epoch [45/100], Step [511/735], Loss: 0.0264
Epoch [45/100], Step [521/735], Loss: 0.0171
Epoch [45/100], Step [531/735], Loss: 0.0022
Epoch [45/100], Step [541/735], Loss: 0.0297
Epoch [45/100], Step [551/735], Loss: 0.0093
Epoch [45/100], Step [561/735], Loss: 0.0136
Epoch [45/100], Step [571/735], Loss: 0.0014
Epoch [45/100], Step [581/735], Loss: 0.0136
Epoch [45/100], Step [591/735], Loss: 0.0045
Epoch [45/100], Step [601/735], Loss: 0.0221
Epoch [45/100], Step [611/735], Loss: 0.0204
Epoch [45/100], Step [621/735], Loss: 0.0034
Epoch [45/100], Step [631/735], Loss: 0.0125
Epoch [45/100], Step [641/735], Loss: 0.0122
Epoch [45/100], Step [651/735], Loss: 0.0313
Epoch [45/100], Step [661/735], Loss: 0.0260
Epoch [45/100], Step [671/735], Loss: 0.0217
Epoch [45/100], Step [681/735], Loss: 0.0034
Epoch [45/100], Step [691/735], Loss: 0.0092
Epoch [45/100], Step [701/735], Loss: 0.0306
Epoch [45/100], Step [711/735], Loss: 0.0007
Epoch [45/100], Step [721/735], Loss: 0.0102
Epoch [45/100], Step [731/735], Loss: 0.0012
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9165,Val AUC: 0.9563,Val precision: 0.8433, Val recall: 0.8641, Val Loss: 0.0715
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 45 | Time taken: 2236.19s |
| Val CE loss: 0.07152 | Val MSE 0.91652 | Train Loss 0.01182 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 46
Training for epoch 46
Epoch [46/100], Step [1/735], Loss: 0.0006
Epoch [46/100], Step [11/735], Loss: 0.0134
Epoch [46/100], Step [21/735], Loss: 0.0182
Epoch [46/100], Step [31/735], Loss: 0.0029
Epoch [46/100], Step [41/735], Loss: 0.0074
Epoch [46/100], Step [51/735], Loss: 0.0232
Epoch [46/100], Step [61/735], Loss: 0.0025
Epoch [46/100], Step [71/735], Loss: 0.0005
Epoch [46/100], Step [81/735], Loss: 0.0278
Epoch [46/100], Step [91/735], Loss: 0.0073
Epoch [46/100], Step [101/735], Loss: 0.0249
Epoch [46/100], Step [111/735], Loss: 0.0261
Epoch [46/100], Step [121/735], Loss: 0.0138
Epoch [46/100], Step [131/735], Loss: 0.0022
Epoch [46/100], Step [141/735], Loss: 0.0014
Epoch [46/100], Step [151/735], Loss: 0.0148
Epoch [46/100], Step [161/735], Loss: 0.0005
Epoch [46/100], Step [171/735], Loss: 0.0237
Epoch [46/100], Step [181/735], Loss: 0.0218
Epoch [46/100], Step [191/735], Loss: 0.0075
Epoch [46/100], Step [201/735], Loss: 0.0115
Epoch [46/100], Step [211/735], Loss: 0.0013
Epoch [46/100], Step [221/735], Loss: 0.0032
Epoch [46/100], Step [231/735], Loss: 0.0070
Epoch [46/100], Step [241/735], Loss: 0.0281
Epoch [46/100], Step [251/735], Loss: 0.0085
Epoch [46/100], Step [261/735], Loss: 0.0442
Epoch [46/100], Step [271/735], Loss: 0.0140
Epoch [46/100], Step [281/735], Loss: 0.0163
Epoch [46/100], Step [291/735], Loss: 0.0017
Epoch [46/100], Step [301/735], Loss: 0.0264
Epoch [46/100], Step [311/735], Loss: 0.0101
Epoch [46/100], Step [321/735], Loss: 0.0064
Epoch [46/100], Step [331/735], Loss: 0.0290
Epoch [46/100], Step [341/735], Loss: 0.0068
Epoch [46/100], Step [351/735], Loss: 0.0059
Epoch [46/100], Step [361/735], Loss: 0.0131
Epoch [46/100], Step [371/735], Loss: 0.0165
Epoch [46/100], Step [381/735], Loss: 0.0178
Epoch [46/100], Step [391/735], Loss: 0.0006
Epoch [46/100], Step [401/735], Loss: 0.0226
Epoch [46/100], Step [411/735], Loss: 0.0332
Epoch [46/100], Step [421/735], Loss: 0.0453
Epoch [46/100], Step [431/735], Loss: 0.0013
Epoch [46/100], Step [441/735], Loss: 0.0140
Epoch [46/100], Step [451/735], Loss: 0.0025
Epoch [46/100], Step [461/735], Loss: 0.0131
Epoch [46/100], Step [471/735], Loss: 0.0098
Epoch [46/100], Step [481/735], Loss: 0.0312
Epoch [46/100], Step [491/735], Loss: 0.0062
Epoch [46/100], Step [501/735], Loss: 0.0043
Epoch [46/100], Step [511/735], Loss: 0.0070
Epoch [46/100], Step [521/735], Loss: 0.0167
Epoch [46/100], Step [531/735], Loss: 0.0173
Epoch [46/100], Step [541/735], Loss: 0.0151
Epoch [46/100], Step [551/735], Loss: 0.0040
Epoch [46/100], Step [561/735], Loss: 0.0252
Epoch [46/100], Step [571/735], Loss: 0.0274
Epoch [46/100], Step [581/735], Loss: 0.0003
Epoch [46/100], Step [591/735], Loss: 0.0150
Epoch [46/100], Step [601/735], Loss: 0.0370
Epoch [46/100], Step [611/735], Loss: 0.0061
Epoch [46/100], Step [621/735], Loss: 0.0237
Epoch [46/100], Step [631/735], Loss: 0.0061
Epoch [46/100], Step [641/735], Loss: 0.0175
Epoch [46/100], Step [651/735], Loss: 0.0282
Epoch [46/100], Step [661/735], Loss: 0.0030
Epoch [46/100], Step [671/735], Loss: 0.0013
Epoch [46/100], Step [681/735], Loss: 0.0175
Epoch [46/100], Step [691/735], Loss: 0.0074
Epoch [46/100], Step [701/735], Loss: 0.0007
Epoch [46/100], Step [711/735], Loss: 0.0037
Epoch [46/100], Step [721/735], Loss: 0.0001
Epoch [46/100], Step [731/735], Loss: 0.0001
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9155,Val AUC: 0.9530,Val precision: 0.8424, Val recall: 0.8610, Val Loss: 0.0726
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 46 | Time taken: 2241.70s |
| Val CE loss: 0.07256 | Val MSE 0.91548 | Train Loss 0.01253 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 47
Training for epoch 47
Epoch [47/100], Step [1/735], Loss: 0.0071
Epoch [47/100], Step [11/735], Loss: 0.0019
Epoch [47/100], Step [21/735], Loss: 0.0006
Epoch [47/100], Step [31/735], Loss: 0.0145
Epoch [47/100], Step [41/735], Loss: 0.0148
Epoch [47/100], Step [51/735], Loss: 0.0176
Epoch [47/100], Step [61/735], Loss: 0.0495
Epoch [47/100], Step [71/735], Loss: 0.0149
Epoch [47/100], Step [81/735], Loss: 0.0083
Epoch [47/100], Step [91/735], Loss: 0.0192
Epoch [47/100], Step [101/735], Loss: 0.0041
Epoch [47/100], Step [111/735], Loss: 0.0005
Epoch [47/100], Step [121/735], Loss: 0.0575
Epoch [47/100], Step [131/735], Loss: 0.0065
Epoch [47/100], Step [141/735], Loss: 0.0239
Epoch [47/100], Step [151/735], Loss: 0.0061
Epoch [47/100], Step [161/735], Loss: 0.0005
Epoch [47/100], Step [171/735], Loss: 0.0002
Epoch [47/100], Step [181/735], Loss: 0.0219
Epoch [47/100], Step [191/735], Loss: 0.0001
Epoch [47/100], Step [201/735], Loss: 0.0028
Epoch [47/100], Step [211/735], Loss: 0.0555
Epoch [47/100], Step [221/735], Loss: 0.0187
Epoch [47/100], Step [231/735], Loss: 0.0018
Epoch [47/100], Step [241/735], Loss: 0.0022
Epoch [47/100], Step [251/735], Loss: 0.0075
Epoch [47/100], Step [261/735], Loss: 0.0114
Epoch [47/100], Step [271/735], Loss: 0.0002
Epoch [47/100], Step [281/735], Loss: 0.0001
Epoch [47/100], Step [291/735], Loss: 0.0142
Epoch [47/100], Step [301/735], Loss: 0.0280
Epoch [47/100], Step [311/735], Loss: 0.0043
Epoch [47/100], Step [321/735], Loss: 0.0149
Epoch [47/100], Step [331/735], Loss: 0.0021
Epoch [47/100], Step [341/735], Loss: 0.0001
Epoch [47/100], Step [351/735], Loss: 0.0035
Epoch [47/100], Step [361/735], Loss: 0.0001
Epoch [47/100], Step [371/735], Loss: 0.0027
Epoch [47/100], Step [381/735], Loss: 0.0069
Epoch [47/100], Step [391/735], Loss: 0.0023
Epoch [47/100], Step [401/735], Loss: 0.0007
Epoch [47/100], Step [411/735], Loss: 0.0032
Epoch [47/100], Step [421/735], Loss: 0.0001
Epoch [47/100], Step [431/735], Loss: 0.0177
Epoch [47/100], Step [441/735], Loss: 0.0036
Epoch [47/100], Step [451/735], Loss: 0.0014
Epoch [47/100], Step [461/735], Loss: 0.0001
Epoch [47/100], Step [471/735], Loss: 0.0140
Epoch [47/100], Step [481/735], Loss: 0.0044
Epoch [47/100], Step [491/735], Loss: 0.0181
Epoch [47/100], Step [501/735], Loss: 0.0005
Epoch [47/100], Step [511/735], Loss: 0.0008
Epoch [47/100], Step [521/735], Loss: 0.0111
Epoch [47/100], Step [531/735], Loss: 0.0159
Epoch [47/100], Step [541/735], Loss: 0.0033
Epoch [47/100], Step [551/735], Loss: 0.0236
Epoch [47/100], Step [561/735], Loss: 0.0162
Epoch [47/100], Step [571/735], Loss: 0.0285
Epoch [47/100], Step [581/735], Loss: 0.0122
Epoch [47/100], Step [591/735], Loss: 0.0084
Epoch [47/100], Step [601/735], Loss: 0.0225
Epoch [47/100], Step [611/735], Loss: 0.0271
Epoch [47/100], Step [621/735], Loss: 0.0076
Epoch [47/100], Step [631/735], Loss: 0.0026
Epoch [47/100], Step [641/735], Loss: 0.0047
Epoch [47/100], Step [651/735], Loss: 0.0001
Epoch [47/100], Step [661/735], Loss: 0.0001
Epoch [47/100], Step [671/735], Loss: 0.0101
Epoch [47/100], Step [681/735], Loss: 0.0148
Epoch [47/100], Step [691/735], Loss: 0.0023
Epoch [47/100], Step [701/735], Loss: 0.0042
Epoch [47/100], Step [711/735], Loss: 0.0033
Epoch [47/100], Step [721/735], Loss: 0.0009
Epoch [47/100], Step [731/735], Loss: 0.0006
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9151,Val AUC: 0.9540,Val precision: 0.8329, Val recall: 0.8739, Val Loss: 0.0730
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 47 | Time taken: 2255.08s |
| Val CE loss: 0.07302 | Val MSE 0.91514 | Train Loss 0.01116 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 48
Training for epoch 48
Epoch [48/100], Step [1/735], Loss: 0.0147
Epoch [48/100], Step [11/735], Loss: 0.0164
Epoch [48/100], Step [21/735], Loss: 0.0100
Epoch [48/100], Step [31/735], Loss: 0.0040
Epoch [48/100], Step [41/735], Loss: 0.0019
Epoch [48/100], Step [51/735], Loss: 0.0003
Epoch [48/100], Step [61/735], Loss: 0.0150
Epoch [48/100], Step [71/735], Loss: 0.0165
Epoch [48/100], Step [81/735], Loss: 0.0149
Epoch [48/100], Step [91/735], Loss: 0.0160
Epoch [48/100], Step [101/735], Loss: 0.0112
Epoch [48/100], Step [111/735], Loss: 0.0233
Epoch [48/100], Step [121/735], Loss: 0.0181
Epoch [48/100], Step [131/735], Loss: 0.0004
Epoch [48/100], Step [141/735], Loss: 0.0027
Epoch [48/100], Step [151/735], Loss: 0.0142
Epoch [48/100], Step [161/735], Loss: 0.0022
Epoch [48/100], Step [171/735], Loss: 0.0224
Epoch [48/100], Step [181/735], Loss: 0.0386
Epoch [48/100], Step [191/735], Loss: 0.0173
Epoch [48/100], Step [201/735], Loss: 0.0026
Epoch [48/100], Step [211/735], Loss: 0.0010
Epoch [48/100], Step [221/735], Loss: 0.0039
Epoch [48/100], Step [231/735], Loss: 0.0116
Epoch [48/100], Step [241/735], Loss: 0.0053
Epoch [48/100], Step [251/735], Loss: 0.0113
Epoch [48/100], Step [261/735], Loss: 0.0294
Epoch [48/100], Step [271/735], Loss: 0.0305
Epoch [48/100], Step [281/735], Loss: 0.0004
Epoch [48/100], Step [291/735], Loss: 0.0024
Epoch [48/100], Step [301/735], Loss: 0.0265
Epoch [48/100], Step [311/735], Loss: 0.0360
Epoch [48/100], Step [321/735], Loss: 0.0188
Epoch [48/100], Step [331/735], Loss: 0.0119
Epoch [48/100], Step [341/735], Loss: 0.0028
Epoch [48/100], Step [351/735], Loss: 0.0040
Epoch [48/100], Step [361/735], Loss: 0.0010
Epoch [48/100], Step [371/735], Loss: 0.0250
Epoch [48/100], Step [381/735], Loss: 0.0005
Epoch [48/100], Step [391/735], Loss: 0.0149
Epoch [48/100], Step [401/735], Loss: 0.0303
Epoch [48/100], Step [411/735], Loss: 0.0151
Epoch [48/100], Step [421/735], Loss: 0.0001
Epoch [48/100], Step [431/735], Loss: 0.0182
Epoch [48/100], Step [441/735], Loss: 0.0001
Epoch [48/100], Step [451/735], Loss: 0.0023
Epoch [48/100], Step [461/735], Loss: 0.0005
Epoch [48/100], Step [471/735], Loss: 0.0034
Epoch [48/100], Step [481/735], Loss: 0.0048
Epoch [48/100], Step [491/735], Loss: 0.0173
Epoch [48/100], Step [501/735], Loss: 0.0184
Epoch [48/100], Step [511/735], Loss: 0.0218
Epoch [48/100], Step [521/735], Loss: 0.0039
Epoch [48/100], Step [531/735], Loss: 0.0133
Epoch [48/100], Step [541/735], Loss: 0.0010
Epoch [48/100], Step [551/735], Loss: 0.0019
Epoch [48/100], Step [561/735], Loss: 0.0140
Epoch [48/100], Step [571/735], Loss: 0.0233
Epoch [48/100], Step [581/735], Loss: 0.0023
Epoch [48/100], Step [591/735], Loss: 0.0009
Epoch [48/100], Step [601/735], Loss: 0.0098
Epoch [48/100], Step [611/735], Loss: 0.0080
Epoch [48/100], Step [621/735], Loss: 0.0002
Epoch [48/100], Step [631/735], Loss: 0.0141
Epoch [48/100], Step [641/735], Loss: 0.0079
Epoch [48/100], Step [651/735], Loss: 0.0142
Epoch [48/100], Step [661/735], Loss: 0.0197
Epoch [48/100], Step [671/735], Loss: 0.0139
Epoch [48/100], Step [681/735], Loss: 0.0001
Epoch [48/100], Step [691/735], Loss: 0.0017
Epoch [48/100], Step [701/735], Loss: 0.0155
Epoch [48/100], Step [711/735], Loss: 0.0053
Epoch [48/100], Step [721/735], Loss: 0.0223
Epoch [48/100], Step [731/735], Loss: 0.0011
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9120,Val AUC: 0.9560,Val precision: 0.8316, Val recall: 0.8622, Val Loss: 0.0746
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 48 | Time taken: 2294.78s |
| Val CE loss: 0.07464 | Val MSE 0.91202 | Train Loss 0.01139 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 49
Training for epoch 49
Epoch [49/100], Step [1/735], Loss: 0.0027
Epoch [49/100], Step [11/735], Loss: 0.0204
Epoch [49/100], Step [21/735], Loss: 0.0031
Epoch [49/100], Step [31/735], Loss: 0.0037
Epoch [49/100], Step [41/735], Loss: 0.0131
Epoch [49/100], Step [51/735], Loss: 0.0139
Epoch [49/100], Step [61/735], Loss: 0.0181
Epoch [49/100], Step [71/735], Loss: 0.0159
Epoch [49/100], Step [81/735], Loss: 0.0268
Epoch [49/100], Step [91/735], Loss: 0.0028
Epoch [49/100], Step [101/735], Loss: 0.0334
Epoch [49/100], Step [111/735], Loss: 0.0002
Epoch [49/100], Step [121/735], Loss: 0.0001
Epoch [49/100], Step [131/735], Loss: 0.0066
Epoch [49/100], Step [141/735], Loss: 0.0137
Epoch [49/100], Step [151/735], Loss: 0.0019
Epoch [49/100], Step [161/735], Loss: 0.0140
Epoch [49/100], Step [171/735], Loss: 0.0006
Epoch [49/100], Step [181/735], Loss: 0.0192
Epoch [49/100], Step [191/735], Loss: 0.0293
Epoch [49/100], Step [201/735], Loss: 0.0144
Epoch [49/100], Step [211/735], Loss: 0.0161
Epoch [49/100], Step [221/735], Loss: 0.0276
Epoch [49/100], Step [231/735], Loss: 0.0385
Epoch [49/100], Step [241/735], Loss: 0.0001
Epoch [49/100], Step [251/735], Loss: 0.0309
Epoch [49/100], Step [261/735], Loss: 0.0017
Epoch [49/100], Step [271/735], Loss: 0.0104
Epoch [49/100], Step [281/735], Loss: 0.0204
Epoch [49/100], Step [291/735], Loss: 0.0003
Epoch [49/100], Step [301/735], Loss: 0.0139
Epoch [49/100], Step [311/735], Loss: 0.0101
Epoch [49/100], Step [321/735], Loss: 0.0145
Epoch [49/100], Step [331/735], Loss: 0.0249
Epoch [49/100], Step [341/735], Loss: 0.0105
Epoch [49/100], Step [351/735], Loss: 0.0174
Epoch [49/100], Step [361/735], Loss: 0.0095
Epoch [49/100], Step [371/735], Loss: 0.0004
Epoch [49/100], Step [381/735], Loss: 0.0147
Epoch [49/100], Step [391/735], Loss: 0.0002
Epoch [49/100], Step [401/735], Loss: 0.0182
Epoch [49/100], Step [411/735], Loss: 0.0011
Epoch [49/100], Step [421/735], Loss: 0.0018
Epoch [49/100], Step [431/735], Loss: 0.0572
Epoch [49/100], Step [441/735], Loss: 0.0048
Epoch [49/100], Step [451/735], Loss: 0.0139
Epoch [49/100], Step [461/735], Loss: 0.0119
Epoch [49/100], Step [471/735], Loss: 0.0232
Epoch [49/100], Step [481/735], Loss: 0.0142
Epoch [49/100], Step [491/735], Loss: 0.0127
Epoch [49/100], Step [501/735], Loss: 0.0092
Epoch [49/100], Step [511/735], Loss: 0.0112
Epoch [49/100], Step [521/735], Loss: 0.0145
Epoch [49/100], Step [531/735], Loss: 0.0145
Epoch [49/100], Step [541/735], Loss: 0.0097
Epoch [49/100], Step [551/735], Loss: 0.0074
Epoch [49/100], Step [561/735], Loss: 0.0094
Epoch [49/100], Step [571/735], Loss: 0.0004
Epoch [49/100], Step [581/735], Loss: 0.0138
Epoch [49/100], Step [591/735], Loss: 0.0241
Epoch [49/100], Step [601/735], Loss: 0.0140
Epoch [49/100], Step [611/735], Loss: 0.0130
Epoch [49/100], Step [621/735], Loss: 0.0030
Epoch [49/100], Step [631/735], Loss: 0.0003
Epoch [49/100], Step [641/735], Loss: 0.0010
Epoch [49/100], Step [651/735], Loss: 0.0052
Epoch [49/100], Step [661/735], Loss: 0.0020
Epoch [49/100], Step [671/735], Loss: 0.0130
Epoch [49/100], Step [681/735], Loss: 0.0113
Epoch [49/100], Step [691/735], Loss: 0.0226
Epoch [49/100], Step [701/735], Loss: 0.0133
Epoch [49/100], Step [711/735], Loss: 0.0263
Epoch [49/100], Step [721/735], Loss: 0.0021
Epoch [49/100], Step [731/735], Loss: 0.0235
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9125,Val AUC: 0.9522,Val precision: 0.8338, Val recall: 0.8610, Val Loss: 0.0745
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 49 | Time taken: 2258.47s |
| Val CE loss: 0.07447 | Val MSE 0.91254 | Train Loss 0.01127 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 50
Training for epoch 50
Epoch [50/100], Step [1/735], Loss: 0.0295
Epoch [50/100], Step [11/735], Loss: 0.0132
Epoch [50/100], Step [21/735], Loss: 0.0024
Epoch [50/100], Step [31/735], Loss: 0.0001
Epoch [50/100], Step [41/735], Loss: 0.0041
Epoch [50/100], Step [51/735], Loss: 0.0006
Epoch [50/100], Step [61/735], Loss: 0.0180
Epoch [50/100], Step [71/735], Loss: 0.0155
Epoch [50/100], Step [81/735], Loss: 0.0036
Epoch [50/100], Step [91/735], Loss: 0.0140
Epoch [50/100], Step [101/735], Loss: 0.0025
Epoch [50/100], Step [111/735], Loss: 0.0140
Epoch [50/100], Step [121/735], Loss: 0.0187
Epoch [50/100], Step [131/735], Loss: 0.0001
Epoch [50/100], Step [141/735], Loss: 0.0055
Epoch [50/100], Step [151/735], Loss: 0.0127
Epoch [50/100], Step [161/735], Loss: 0.0007
Epoch [50/100], Step [171/735], Loss: 0.0002
Epoch [50/100], Step [181/735], Loss: 0.0106
Epoch [50/100], Step [191/735], Loss: 0.0175
Epoch [50/100], Step [201/735], Loss: 0.0141
Epoch [50/100], Step [211/735], Loss: 0.0044
Epoch [50/100], Step [221/735], Loss: 0.0260
Epoch [50/100], Step [231/735], Loss: 0.0206
Epoch [50/100], Step [241/735], Loss: 0.0022
Epoch [50/100], Step [251/735], Loss: 0.0137
Epoch [50/100], Step [261/735], Loss: 0.0034
Epoch [50/100], Step [271/735], Loss: 0.0015
Epoch [50/100], Step [281/735], Loss: 0.0099
Epoch [50/100], Step [291/735], Loss: 0.0139
Epoch [50/100], Step [301/735], Loss: 0.0033
Epoch [50/100], Step [311/735], Loss: 0.0139
Epoch [50/100], Step [321/735], Loss: 0.0417
Epoch [50/100], Step [331/735], Loss: 0.0005
Epoch [50/100], Step [341/735], Loss: 0.0003
Epoch [50/100], Step [351/735], Loss: 0.0003
Epoch [50/100], Step [361/735], Loss: 0.0556
Epoch [50/100], Step [371/735], Loss: 0.0013
Epoch [50/100], Step [381/735], Loss: 0.0279
Epoch [50/100], Step [391/735], Loss: 0.0146
Epoch [50/100], Step [401/735], Loss: 0.0207
Epoch [50/100], Step [411/735], Loss: 0.0004
Epoch [50/100], Step [421/735], Loss: 0.0061
Epoch [50/100], Step [431/735], Loss: 0.0109
Epoch [50/100], Step [441/735], Loss: 0.0085
Epoch [50/100], Step [451/735], Loss: 0.0004
Epoch [50/100], Step [461/735], Loss: 0.0027
Epoch [50/100], Step [471/735], Loss: 0.0139
Epoch [50/100], Step [481/735], Loss: 0.0187
Epoch [50/100], Step [491/735], Loss: 0.0131
Epoch [50/100], Step [501/735], Loss: 0.0298
Epoch [50/100], Step [511/735], Loss: 0.0013
Epoch [50/100], Step [521/735], Loss: 0.0022
Epoch [50/100], Step [531/735], Loss: 0.0127
Epoch [50/100], Step [541/735], Loss: 0.0191
Epoch [50/100], Step [551/735], Loss: 0.0014
Epoch [50/100], Step [561/735], Loss: 0.0350
Epoch [50/100], Step [571/735], Loss: 0.0010
Epoch [50/100], Step [581/735], Loss: 0.0203
Epoch [50/100], Step [591/735], Loss: 0.0058
Epoch [50/100], Step [601/735], Loss: 0.0076
Epoch [50/100], Step [611/735], Loss: 0.0043
Epoch [50/100], Step [621/735], Loss: 0.0173
Epoch [50/100], Step [631/735], Loss: 0.0199
Epoch [50/100], Step [641/735], Loss: 0.0126
Epoch [50/100], Step [651/735], Loss: 0.0008
Epoch [50/100], Step [661/735], Loss: 0.0261
Epoch [50/100], Step [671/735], Loss: 0.0031
Epoch [50/100], Step [681/735], Loss: 0.0220
Epoch [50/100], Step [691/735], Loss: 0.0143
Epoch [50/100], Step [701/735], Loss: 0.0107
Epoch [50/100], Step [711/735], Loss: 0.0019
Epoch [50/100], Step [721/735], Loss: 0.0232
Epoch [50/100], Step [731/735], Loss: 0.0128
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9039,Val AUC: 0.9538,Val precision: 0.8044, Val recall: 0.8702, Val Loss: 0.0807
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 50 | Time taken: 2252.04s |
| Val CE loss: 0.08075 | Val MSE 0.90388 | Train Loss 0.01117 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 51
Training for epoch 51
Epoch [51/100], Step [1/735], Loss: 0.0149
Epoch [51/100], Step [11/735], Loss: 0.0117
Epoch [51/100], Step [21/735], Loss: 0.0199
Epoch [51/100], Step [31/735], Loss: 0.0056
Epoch [51/100], Step [41/735], Loss: 0.0231
Epoch [51/100], Step [51/735], Loss: 0.0165
Epoch [51/100], Step [61/735], Loss: 0.0286
Epoch [51/100], Step [71/735], Loss: 0.0071
Epoch [51/100], Step [81/735], Loss: 0.0058
Epoch [51/100], Step [91/735], Loss: 0.0008
Epoch [51/100], Step [101/735], Loss: 0.0143
Epoch [51/100], Step [111/735], Loss: 0.0133
Epoch [51/100], Step [121/735], Loss: 0.0231
Epoch [51/100], Step [131/735], Loss: 0.0083
Epoch [51/100], Step [141/735], Loss: 0.0133
Epoch [51/100], Step [151/735], Loss: 0.0007
Epoch [51/100], Step [161/735], Loss: 0.0069
Epoch [51/100], Step [171/735], Loss: 0.0019
Epoch [51/100], Step [181/735], Loss: 0.0034
Epoch [51/100], Step [191/735], Loss: 0.0002
Epoch [51/100], Step [201/735], Loss: 0.0141
Epoch [51/100], Step [211/735], Loss: 0.0004
Epoch [51/100], Step [221/735], Loss: 0.0278
Epoch [51/100], Step [231/735], Loss: 0.0092
Epoch [51/100], Step [241/735], Loss: 0.0032
Epoch [51/100], Step [251/735], Loss: 0.0004
Epoch [51/100], Step [261/735], Loss: 0.0146
Epoch [51/100], Step [271/735], Loss: 0.0034
Epoch [51/100], Step [281/735], Loss: 0.0043
Epoch [51/100], Step [291/735], Loss: 0.0139
Epoch [51/100], Step [301/735], Loss: 0.0004
Epoch [51/100], Step [311/735], Loss: 0.0215
Epoch [51/100], Step [321/735], Loss: 0.0230
Epoch [51/100], Step [331/735], Loss: 0.0005
Epoch [51/100], Step [341/735], Loss: 0.0140
Epoch [51/100], Step [351/735], Loss: 0.0058
Epoch [51/100], Step [361/735], Loss: 0.0016
Epoch [51/100], Step [371/735], Loss: 0.0058
Epoch [51/100], Step [381/735], Loss: 0.0009
Epoch [51/100], Step [391/735], Loss: 0.0280
Epoch [51/100], Step [401/735], Loss: 0.0022
Epoch [51/100], Step [411/735], Loss: 0.0078
Epoch [51/100], Step [421/735], Loss: 0.0037
Epoch [51/100], Step [431/735], Loss: 0.0007
Epoch [51/100], Step [441/735], Loss: 0.0012
Epoch [51/100], Step [451/735], Loss: 0.0086
Epoch [51/100], Step [461/735], Loss: 0.0040
Epoch [51/100], Step [471/735], Loss: 0.0009
Epoch [51/100], Step [481/735], Loss: 0.0162
Epoch [51/100], Step [491/735], Loss: 0.0003
Epoch [51/100], Step [501/735], Loss: 0.0018
Epoch [51/100], Step [511/735], Loss: 0.0192
Epoch [51/100], Step [521/735], Loss: 0.0040
Epoch [51/100], Step [531/735], Loss: 0.0050
Epoch [51/100], Step [541/735], Loss: 0.0019
Epoch [51/100], Step [551/735], Loss: 0.0076
Epoch [51/100], Step [561/735], Loss: 0.0035
Epoch [51/100], Step [571/735], Loss: 0.0207
Epoch [51/100], Step [581/735], Loss: 0.0063
Epoch [51/100], Step [591/735], Loss: 0.0004
Epoch [51/100], Step [601/735], Loss: 0.0122
Epoch [51/100], Step [611/735], Loss: 0.0031
Epoch [51/100], Step [621/735], Loss: 0.0004
Epoch [51/100], Step [631/735], Loss: 0.0104
Epoch [51/100], Step [641/735], Loss: 0.0206
Epoch [51/100], Step [651/735], Loss: 0.0033
Epoch [51/100], Step [661/735], Loss: 0.0080
Epoch [51/100], Step [671/735], Loss: 0.0351
Epoch [51/100], Step [681/735], Loss: 0.0140
Epoch [51/100], Step [691/735], Loss: 0.0337
Epoch [51/100], Step [701/735], Loss: 0.0017
Epoch [51/100], Step [711/735], Loss: 0.0115
Epoch [51/100], Step [721/735], Loss: 0.0081
Epoch [51/100], Step [731/735], Loss: 0.0017
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9112,Val AUC: 0.9553,Val precision: 0.8211, Val recall: 0.8752, Val Loss: 0.0764
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 51 | Time taken: 2239.22s |
| Val CE loss: 0.07642 | Val MSE 0.91115 | Train Loss 0.01137 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 52
Training for epoch 52
Epoch [52/100], Step [1/735], Loss: 0.0156
Epoch [52/100], Step [11/735], Loss: 0.0142
Epoch [52/100], Step [21/735], Loss: 0.0091
Epoch [52/100], Step [31/735], Loss: 0.0081
Epoch [52/100], Step [41/735], Loss: 0.0039
Epoch [52/100], Step [51/735], Loss: 0.0355
Epoch [52/100], Step [61/735], Loss: 0.0020
Epoch [52/100], Step [71/735], Loss: 0.0143
Epoch [52/100], Step [81/735], Loss: 0.0229
Epoch [52/100], Step [91/735], Loss: 0.0134
Epoch [52/100], Step [101/735], Loss: 0.0003
Epoch [52/100], Step [111/735], Loss: 0.0198
Epoch [52/100], Step [121/735], Loss: 0.0149
Epoch [52/100], Step [131/735], Loss: 0.0027
Epoch [52/100], Step [141/735], Loss: 0.0144
Epoch [52/100], Step [151/735], Loss: 0.0002
Epoch [52/100], Step [161/735], Loss: 0.0149
Epoch [52/100], Step [171/735], Loss: 0.0345
Epoch [52/100], Step [181/735], Loss: 0.0011
Epoch [52/100], Step [191/735], Loss: 0.0061
Epoch [52/100], Step [201/735], Loss: 0.0146
Epoch [52/100], Step [211/735], Loss: 0.0001
Epoch [52/100], Step [221/735], Loss: 0.0044
Epoch [52/100], Step [231/735], Loss: 0.0044
Epoch [52/100], Step [241/735], Loss: 0.0126
Epoch [52/100], Step [251/735], Loss: 0.0001
Epoch [52/100], Step [261/735], Loss: 0.0000
Epoch [52/100], Step [271/735], Loss: 0.0024
Epoch [52/100], Step [281/735], Loss: 0.0094
Epoch [52/100], Step [291/735], Loss: 0.0035
Epoch [52/100], Step [301/735], Loss: 0.0052
Epoch [52/100], Step [311/735], Loss: 0.0253
Epoch [52/100], Step [321/735], Loss: 0.0044
Epoch [52/100], Step [331/735], Loss: 0.0021
Epoch [52/100], Step [341/735], Loss: 0.0157
Epoch [52/100], Step [351/735], Loss: 0.0059
Epoch [52/100], Step [361/735], Loss: 0.0021
Epoch [52/100], Step [371/735], Loss: 0.0037
Epoch [52/100], Step [381/735], Loss: 0.0143
Epoch [52/100], Step [391/735], Loss: 0.0248
Epoch [52/100], Step [401/735], Loss: 0.0043
Epoch [52/100], Step [411/735], Loss: 0.0267
Epoch [52/100], Step [421/735], Loss: 0.0049
Epoch [52/100], Step [431/735], Loss: 0.0069
Epoch [52/100], Step [441/735], Loss: 0.0021
Epoch [52/100], Step [451/735], Loss: 0.0127
Epoch [52/100], Step [461/735], Loss: 0.0138
Epoch [52/100], Step [471/735], Loss: 0.0091
Epoch [52/100], Step [481/735], Loss: 0.0198
Epoch [52/100], Step [491/735], Loss: 0.0001
Epoch [52/100], Step [501/735], Loss: 0.0059
Epoch [52/100], Step [511/735], Loss: 0.0007
Epoch [52/100], Step [521/735], Loss: 0.0002
Epoch [52/100], Step [531/735], Loss: 0.0002
Epoch [52/100], Step [541/735], Loss: 0.0144
Epoch [52/100], Step [551/735], Loss: 0.0146
Epoch [52/100], Step [561/735], Loss: 0.0159
Epoch [52/100], Step [571/735], Loss: 0.0001
Epoch [52/100], Step [581/735], Loss: 0.0036
Epoch [52/100], Step [591/735], Loss: 0.0019
Epoch [52/100], Step [601/735], Loss: 0.0144
Epoch [52/100], Step [611/735], Loss: 0.0144
Epoch [52/100], Step [621/735], Loss: 0.0166
Epoch [52/100], Step [631/735], Loss: 0.0267
Epoch [52/100], Step [641/735], Loss: 0.0525
Epoch [52/100], Step [651/735], Loss: 0.0072
Epoch [52/100], Step [661/735], Loss: 0.0170
Epoch [52/100], Step [671/735], Loss: 0.0114
Epoch [52/100], Step [681/735], Loss: 0.0001
Epoch [52/100], Step [691/735], Loss: 0.0002
Epoch [52/100], Step [701/735], Loss: 0.0047
Epoch [52/100], Step [711/735], Loss: 0.0086
Epoch [52/100], Step [721/735], Loss: 0.0400
Epoch [52/100], Step [731/735], Loss: 0.0086
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9144,Val AUC: 0.9520,Val precision: 0.8361, Val recall: 0.8659, Val Loss: 0.0755
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 52 | Time taken: 2240.78s |
| Val CE loss: 0.07547 | Val MSE 0.91444 | Train Loss 0.01067 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 53
Training for epoch 53
Epoch [53/100], Step [1/735], Loss: 0.0181
Epoch [53/100], Step [11/735], Loss: 0.0139
Epoch [53/100], Step [21/735], Loss: 0.0008
Epoch [53/100], Step [31/735], Loss: 0.0096
Epoch [53/100], Step [41/735], Loss: 0.0190
Epoch [53/100], Step [51/735], Loss: 0.0008
Epoch [53/100], Step [61/735], Loss: 0.0103
Epoch [53/100], Step [71/735], Loss: 0.0007
Epoch [53/100], Step [81/735], Loss: 0.0021
Epoch [53/100], Step [91/735], Loss: 0.0064
Epoch [53/100], Step [101/735], Loss: 0.0040
Epoch [53/100], Step [111/735], Loss: 0.0198
Epoch [53/100], Step [121/735], Loss: 0.0245
Epoch [53/100], Step [131/735], Loss: 0.0181
Epoch [53/100], Step [141/735], Loss: 0.0001
Epoch [53/100], Step [151/735], Loss: 0.0003
Epoch [53/100], Step [161/735], Loss: 0.0162
Epoch [53/100], Step [171/735], Loss: 0.0001
Epoch [53/100], Step [181/735], Loss: 0.0003
Epoch [53/100], Step [191/735], Loss: 0.0275
Epoch [53/100], Step [201/735], Loss: 0.0003
Epoch [53/100], Step [211/735], Loss: 0.0269
Epoch [53/100], Step [221/735], Loss: 0.0202
Epoch [53/100], Step [231/735], Loss: 0.0052
Epoch [53/100], Step [241/735], Loss: 0.0268
Epoch [53/100], Step [251/735], Loss: 0.0093
Epoch [53/100], Step [261/735], Loss: 0.0031
Epoch [53/100], Step [271/735], Loss: 0.0160
Epoch [53/100], Step [281/735], Loss: 0.0023
Epoch [53/100], Step [291/735], Loss: 0.0033
Epoch [53/100], Step [301/735], Loss: 0.0140
Epoch [53/100], Step [311/735], Loss: 0.0163
Epoch [53/100], Step [321/735], Loss: 0.0241
Epoch [53/100], Step [331/735], Loss: 0.0000
Epoch [53/100], Step [341/735], Loss: 0.0131
Epoch [53/100], Step [351/735], Loss: 0.0031
Epoch [53/100], Step [361/735], Loss: 0.0005
Epoch [53/100], Step [371/735], Loss: 0.0162
Epoch [53/100], Step [381/735], Loss: 0.0213
Epoch [53/100], Step [391/735], Loss: 0.0276
Epoch [53/100], Step [401/735], Loss: 0.0009
Epoch [53/100], Step [411/735], Loss: 0.0155
Epoch [53/100], Step [421/735], Loss: 0.0068
Epoch [53/100], Step [431/735], Loss: 0.0150
Epoch [53/100], Step [441/735], Loss: 0.0169
Epoch [53/100], Step [451/735], Loss: 0.0006
Epoch [53/100], Step [461/735], Loss: 0.0040
Epoch [53/100], Step [471/735], Loss: 0.0002
Epoch [53/100], Step [481/735], Loss: 0.0241
Epoch [53/100], Step [491/735], Loss: 0.0003
Epoch [53/100], Step [501/735], Loss: 0.0007
Epoch [53/100], Step [511/735], Loss: 0.0038
Epoch [53/100], Step [521/735], Loss: 0.0007
Epoch [53/100], Step [531/735], Loss: 0.0275
Epoch [53/100], Step [541/735], Loss: 0.0003
Epoch [53/100], Step [551/735], Loss: 0.0023
Epoch [53/100], Step [561/735], Loss: 0.0015
Epoch [53/100], Step [571/735], Loss: 0.0002
Epoch [53/100], Step [581/735], Loss: 0.0024
Epoch [53/100], Step [591/735], Loss: 0.0131
Epoch [53/100], Step [601/735], Loss: 0.0137
Epoch [53/100], Step [611/735], Loss: 0.0226
Epoch [53/100], Step [621/735], Loss: 0.0007
Epoch [53/100], Step [631/735], Loss: 0.0142
Epoch [53/100], Step [641/735], Loss: 0.0001
Epoch [53/100], Step [651/735], Loss: 0.0103
Epoch [53/100], Step [661/735], Loss: 0.0007
Epoch [53/100], Step [671/735], Loss: 0.0122
Epoch [53/100], Step [681/735], Loss: 0.0091
Epoch [53/100], Step [691/735], Loss: 0.0145
Epoch [53/100], Step [701/735], Loss: 0.0014
Epoch [53/100], Step [711/735], Loss: 0.0004
Epoch [53/100], Step [721/735], Loss: 0.0165
Epoch [53/100], Step [731/735], Loss: 0.0077
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9167,Val AUC: 0.9527,Val precision: 0.8594, Val recall: 0.8419, Val Loss: 0.0717
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 53 | Time taken: 2251.75s |
| Val CE loss: 0.07168 | Val MSE 0.91670 | Train Loss 0.01120 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 54
Training for epoch 54
Epoch [54/100], Step [1/735], Loss: 0.0137
Epoch [54/100], Step [11/735], Loss: 0.0140
Epoch [54/100], Step [21/735], Loss: 0.0001
Epoch [54/100], Step [31/735], Loss: 0.0010
Epoch [54/100], Step [41/735], Loss: 0.0003
Epoch [54/100], Step [51/735], Loss: 0.0249
Epoch [54/100], Step [61/735], Loss: 0.0001
Epoch [54/100], Step [71/735], Loss: 0.0038
Epoch [54/100], Step [81/735], Loss: 0.0013
Epoch [54/100], Step [91/735], Loss: 0.0018
Epoch [54/100], Step [101/735], Loss: 0.0086
Epoch [54/100], Step [111/735], Loss: 0.0304
Epoch [54/100], Step [121/735], Loss: 0.0265
Epoch [54/100], Step [131/735], Loss: 0.0265
Epoch [54/100], Step [141/735], Loss: 0.0251
Epoch [54/100], Step [151/735], Loss: 0.0005
Epoch [54/100], Step [161/735], Loss: 0.0346
Epoch [54/100], Step [171/735], Loss: 0.0120
Epoch [54/100], Step [181/735], Loss: 0.0139
Epoch [54/100], Step [191/735], Loss: 0.0265
Epoch [54/100], Step [201/735], Loss: 0.0228
Epoch [54/100], Step [211/735], Loss: 0.0172
Epoch [54/100], Step [221/735], Loss: 0.0249
Epoch [54/100], Step [231/735], Loss: 0.0171
Epoch [54/100], Step [241/735], Loss: 0.0184
Epoch [54/100], Step [251/735], Loss: 0.0016
Epoch [54/100], Step [261/735], Loss: 0.0015
Epoch [54/100], Step [271/735], Loss: 0.0181
Epoch [54/100], Step [281/735], Loss: 0.0094
Epoch [54/100], Step [291/735], Loss: 0.0010
Epoch [54/100], Step [301/735], Loss: 0.0176
Epoch [54/100], Step [311/735], Loss: 0.0140
Epoch [54/100], Step [321/735], Loss: 0.0060
Epoch [54/100], Step [331/735], Loss: 0.0138
Epoch [54/100], Step [341/735], Loss: 0.0090
Epoch [54/100], Step [351/735], Loss: 0.0011
Epoch [54/100], Step [361/735], Loss: 0.0001
Epoch [54/100], Step [371/735], Loss: 0.0011
Epoch [54/100], Step [381/735], Loss: 0.0147
Epoch [54/100], Step [391/735], Loss: 0.0003
Epoch [54/100], Step [401/735], Loss: 0.0179
Epoch [54/100], Step [411/735], Loss: 0.0011
Epoch [54/100], Step [421/735], Loss: 0.0005
Epoch [54/100], Step [431/735], Loss: 0.0130
Epoch [54/100], Step [441/735], Loss: 0.0004
Epoch [54/100], Step [451/735], Loss: 0.0056
Epoch [54/100], Step [461/735], Loss: 0.0033
Epoch [54/100], Step [471/735], Loss: 0.0166
Epoch [54/100], Step [481/735], Loss: 0.0001
Epoch [54/100], Step [491/735], Loss: 0.0224
Epoch [54/100], Step [501/735], Loss: 0.0426
Epoch [54/100], Step [511/735], Loss: 0.0064
Epoch [54/100], Step [521/735], Loss: 0.0010
Epoch [54/100], Step [531/735], Loss: 0.0128
Epoch [54/100], Step [541/735], Loss: 0.0054
Epoch [54/100], Step [551/735], Loss: 0.0239
Epoch [54/100], Step [561/735], Loss: 0.0150
Epoch [54/100], Step [571/735], Loss: 0.0012
Epoch [54/100], Step [581/735], Loss: 0.0209
Epoch [54/100], Step [591/735], Loss: 0.0031
Epoch [54/100], Step [601/735], Loss: 0.0022
Epoch [54/100], Step [611/735], Loss: 0.0016
Epoch [54/100], Step [621/735], Loss: 0.0001
Epoch [54/100], Step [631/735], Loss: 0.0004
Epoch [54/100], Step [641/735], Loss: 0.0007
Epoch [54/100], Step [651/735], Loss: 0.0010
Epoch [54/100], Step [661/735], Loss: 0.0159
Epoch [54/100], Step [671/735], Loss: 0.0278
Epoch [54/100], Step [681/735], Loss: 0.0040
Epoch [54/100], Step [691/735], Loss: 0.0021
Epoch [54/100], Step [701/735], Loss: 0.0559
Epoch [54/100], Step [711/735], Loss: 0.0027
Epoch [54/100], Step [721/735], Loss: 0.0115
Epoch [54/100], Step [731/735], Loss: 0.0223
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9160,Val AUC: 0.9526,Val precision: 0.8468, Val recall: 0.8567, Val Loss: 0.0731
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 54 | Time taken: 2267.39s |
| Val CE loss: 0.07308 | Val MSE 0.91600 | Train Loss 0.01056 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 55
Training for epoch 55
Epoch [55/100], Step [1/735], Loss: 0.0025
Epoch [55/100], Step [11/735], Loss: 0.0193
Epoch [55/100], Step [21/735], Loss: 0.0007
Epoch [55/100], Step [31/735], Loss: 0.0047
Epoch [55/100], Step [41/735], Loss: 0.0234
Epoch [55/100], Step [51/735], Loss: 0.0022
Epoch [55/100], Step [61/735], Loss: 0.0116
Epoch [55/100], Step [71/735], Loss: 0.0040
Epoch [55/100], Step [81/735], Loss: 0.0019
Epoch [55/100], Step [91/735], Loss: 0.0110
Epoch [55/100], Step [101/735], Loss: 0.0002
Epoch [55/100], Step [111/735], Loss: 0.0149
Epoch [55/100], Step [121/735], Loss: 0.0187
Epoch [55/100], Step [131/735], Loss: 0.0003
Epoch [55/100], Step [141/735], Loss: 0.0016
Epoch [55/100], Step [151/735], Loss: 0.0132
Epoch [55/100], Step [161/735], Loss: 0.0018
Epoch [55/100], Step [171/735], Loss: 0.0011
Epoch [55/100], Step [181/735], Loss: 0.0144
Epoch [55/100], Step [191/735], Loss: 0.0004
Epoch [55/100], Step [201/735], Loss: 0.0163
Epoch [55/100], Step [211/735], Loss: 0.0063
Epoch [55/100], Step [221/735], Loss: 0.0142
Epoch [55/100], Step [231/735], Loss: 0.0009
Epoch [55/100], Step [241/735], Loss: 0.0002
Epoch [55/100], Step [251/735], Loss: 0.0003
Epoch [55/100], Step [261/735], Loss: 0.0003
Epoch [55/100], Step [271/735], Loss: 0.0066
Epoch [55/100], Step [281/735], Loss: 0.0010
Epoch [55/100], Step [291/735], Loss: 0.0142
Epoch [55/100], Step [301/735], Loss: 0.0045
Epoch [55/100], Step [311/735], Loss: 0.0035
Epoch [55/100], Step [321/735], Loss: 0.0104
Epoch [55/100], Step [331/735], Loss: 0.0001
Epoch [55/100], Step [341/735], Loss: 0.0139
Epoch [55/100], Step [351/735], Loss: 0.0299
Epoch [55/100], Step [361/735], Loss: 0.0002
Epoch [55/100], Step [371/735], Loss: 0.0273
Epoch [55/100], Step [381/735], Loss: 0.0040
Epoch [55/100], Step [391/735], Loss: 0.0077
Epoch [55/100], Step [401/735], Loss: 0.0214
Epoch [55/100], Step [411/735], Loss: 0.0006
Epoch [55/100], Step [421/735], Loss: 0.0121
Epoch [55/100], Step [431/735], Loss: 0.0001
Epoch [55/100], Step [441/735], Loss: 0.0102
Epoch [55/100], Step [451/735], Loss: 0.0139
Epoch [55/100], Step [461/735], Loss: 0.0006
Epoch [55/100], Step [471/735], Loss: 0.0053
Epoch [55/100], Step [481/735], Loss: 0.0009
Epoch [55/100], Step [491/735], Loss: 0.0185
Epoch [55/100], Step [501/735], Loss: 0.0170
Epoch [55/100], Step [511/735], Loss: 0.0201
Epoch [55/100], Step [521/735], Loss: 0.0001
Epoch [55/100], Step [531/735], Loss: 0.0246
Epoch [55/100], Step [541/735], Loss: 0.0031
Epoch [55/100], Step [551/735], Loss: 0.0004
Epoch [55/100], Step [561/735], Loss: 0.0002
Epoch [55/100], Step [571/735], Loss: 0.0293
Epoch [55/100], Step [581/735], Loss: 0.0118
Epoch [55/100], Step [591/735], Loss: 0.0181
Epoch [55/100], Step [601/735], Loss: 0.0214
Epoch [55/100], Step [611/735], Loss: 0.0131
Epoch [55/100], Step [621/735], Loss: 0.0001
Epoch [55/100], Step [631/735], Loss: 0.0121
Epoch [55/100], Step [641/735], Loss: 0.0267
Epoch [55/100], Step [651/735], Loss: 0.0056
Epoch [55/100], Step [661/735], Loss: 0.0159
Epoch [55/100], Step [671/735], Loss: 0.0054
Epoch [55/100], Step [681/735], Loss: 0.0002
Epoch [55/100], Step [691/735], Loss: 0.0022
Epoch [55/100], Step [701/735], Loss: 0.0165
Epoch [55/100], Step [711/735], Loss: 0.0009
Epoch [55/100], Step [721/735], Loss: 0.0001
Epoch [55/100], Step [731/735], Loss: 0.0059
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9163,Val AUC: 0.9567,Val precision: 0.8408, Val recall: 0.8672, Val Loss: 0.0724
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 55 | Time taken: 2248.44s |
| Val CE loss: 0.07242 | Val MSE 0.91635 | Train Loss 0.00947 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 56
Training for epoch 56
Epoch [56/100], Step [1/735], Loss: 0.0145
Epoch [56/100], Step [11/735], Loss: 0.0002
Epoch [56/100], Step [21/735], Loss: 0.0137
Epoch [56/100], Step [31/735], Loss: 0.0022
Epoch [56/100], Step [41/735], Loss: 0.0024
Epoch [56/100], Step [51/735], Loss: 0.0057
Epoch [56/100], Step [61/735], Loss: 0.0017
Epoch [56/100], Step [71/735], Loss: 0.0206
Epoch [56/100], Step [81/735], Loss: 0.0024
Epoch [56/100], Step [91/735], Loss: 0.0002
Epoch [56/100], Step [101/735], Loss: 0.0001
Epoch [56/100], Step [111/735], Loss: 0.0332
Epoch [56/100], Step [121/735], Loss: 0.0001
Epoch [56/100], Step [131/735], Loss: 0.0015
Epoch [56/100], Step [141/735], Loss: 0.0003
Epoch [56/100], Step [151/735], Loss: 0.0007
Epoch [56/100], Step [161/735], Loss: 0.0001
Epoch [56/100], Step [171/735], Loss: 0.0279
Epoch [56/100], Step [181/735], Loss: 0.0173
Epoch [56/100], Step [191/735], Loss: 0.0000
Epoch [56/100], Step [201/735], Loss: 0.0131
Epoch [56/100], Step [211/735], Loss: 0.0037
Epoch [56/100], Step [221/735], Loss: 0.0013
Epoch [56/100], Step [231/735], Loss: 0.0048
Epoch [56/100], Step [241/735], Loss: 0.0033
Epoch [56/100], Step [251/735], Loss: 0.0122
Epoch [56/100], Step [261/735], Loss: 0.0001
Epoch [56/100], Step [271/735], Loss: 0.0404
Epoch [56/100], Step [281/735], Loss: 0.0049
Epoch [56/100], Step [291/735], Loss: 0.0120
Epoch [56/100], Step [301/735], Loss: 0.0112
Epoch [56/100], Step [311/735], Loss: 0.0139
Epoch [56/100], Step [321/735], Loss: 0.0003
Epoch [56/100], Step [331/735], Loss: 0.0002
Epoch [56/100], Step [341/735], Loss: 0.0023
Epoch [56/100], Step [351/735], Loss: 0.0022
Epoch [56/100], Step [361/735], Loss: 0.0190
Epoch [56/100], Step [371/735], Loss: 0.0004
Epoch [56/100], Step [381/735], Loss: 0.0105
Epoch [56/100], Step [391/735], Loss: 0.0000
Epoch [56/100], Step [401/735], Loss: 0.0001
Epoch [56/100], Step [411/735], Loss: 0.0002
Epoch [56/100], Step [421/735], Loss: 0.0007
Epoch [56/100], Step [431/735], Loss: 0.0032
Epoch [56/100], Step [441/735], Loss: 0.0001
Epoch [56/100], Step [451/735], Loss: 0.0004
Epoch [56/100], Step [461/735], Loss: 0.0012
Epoch [56/100], Step [471/735], Loss: 0.0239
Epoch [56/100], Step [481/735], Loss: 0.0142
Epoch [56/100], Step [491/735], Loss: 0.0106
Epoch [56/100], Step [501/735], Loss: 0.0382
Epoch [56/100], Step [511/735], Loss: 0.0131
Epoch [56/100], Step [521/735], Loss: 0.0039
Epoch [56/100], Step [531/735], Loss: 0.0003
Epoch [56/100], Step [541/735], Loss: 0.0143
Epoch [56/100], Step [551/735], Loss: 0.0162
Epoch [56/100], Step [561/735], Loss: 0.0007
Epoch [56/100], Step [571/735], Loss: 0.0338
Epoch [56/100], Step [581/735], Loss: 0.0374
Epoch [56/100], Step [591/735], Loss: 0.0191
Epoch [56/100], Step [601/735], Loss: 0.0085
Epoch [56/100], Step [611/735], Loss: 0.0152
Epoch [56/100], Step [621/735], Loss: 0.0004
Epoch [56/100], Step [631/735], Loss: 0.0005
Epoch [56/100], Step [641/735], Loss: 0.0149
Epoch [56/100], Step [651/735], Loss: 0.0009
Epoch [56/100], Step [661/735], Loss: 0.0014
Epoch [56/100], Step [671/735], Loss: 0.0008
Epoch [56/100], Step [681/735], Loss: 0.0009
Epoch [56/100], Step [691/735], Loss: 0.0002
Epoch [56/100], Step [701/735], Loss: 0.0010
Epoch [56/100], Step [711/735], Loss: 0.0026
Epoch [56/100], Step [721/735], Loss: 0.0056
Epoch [56/100], Step [731/735], Loss: 0.0208
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9144,Val AUC: 0.9528,Val precision: 0.8333, Val recall: 0.8702, Val Loss: 0.0736
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 56 | Time taken: 2234.58s |
| Val CE loss: 0.07355 | Val MSE 0.91444 | Train Loss 0.01016 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 57
Training for epoch 57
Epoch [57/100], Step [1/735], Loss: 0.0002
Epoch [57/100], Step [11/735], Loss: 0.0040
Epoch [57/100], Step [21/735], Loss: 0.0186
Epoch [57/100], Step [31/735], Loss: 0.0001
Epoch [57/100], Step [41/735], Loss: 0.0095
Epoch [57/100], Step [51/735], Loss: 0.0319
Epoch [57/100], Step [61/735], Loss: 0.0012
Epoch [57/100], Step [71/735], Loss: 0.0109
Epoch [57/100], Step [81/735], Loss: 0.0004
Epoch [57/100], Step [91/735], Loss: 0.0182
Epoch [57/100], Step [101/735], Loss: 0.0009
Epoch [57/100], Step [111/735], Loss: 0.0001
Epoch [57/100], Step [121/735], Loss: 0.0137
Epoch [57/100], Step [131/735], Loss: 0.0057
Epoch [57/100], Step [141/735], Loss: 0.0143
Epoch [57/100], Step [151/735], Loss: 0.0063
Epoch [57/100], Step [161/735], Loss: 0.0056
Epoch [57/100], Step [171/735], Loss: 0.0004
Epoch [57/100], Step [181/735], Loss: 0.0010
Epoch [57/100], Step [191/735], Loss: 0.0449
Epoch [57/100], Step [201/735], Loss: 0.0001
Epoch [57/100], Step [211/735], Loss: 0.0149
Epoch [57/100], Step [221/735], Loss: 0.0074
Epoch [57/100], Step [231/735], Loss: 0.0098
Epoch [57/100], Step [241/735], Loss: 0.0262
Epoch [57/100], Step [251/735], Loss: 0.0291
Epoch [57/100], Step [261/735], Loss: 0.0028
Epoch [57/100], Step [271/735], Loss: 0.0021
Epoch [57/100], Step [281/735], Loss: 0.0316
Epoch [57/100], Step [291/735], Loss: 0.0411
Epoch [57/100], Step [301/735], Loss: 0.0191
Epoch [57/100], Step [311/735], Loss: 0.0313
Epoch [57/100], Step [321/735], Loss: 0.0024
Epoch [57/100], Step [331/735], Loss: 0.0068
Epoch [57/100], Step [341/735], Loss: 0.0018
Epoch [57/100], Step [351/735], Loss: 0.0005
Epoch [57/100], Step [361/735], Loss: 0.0229
Epoch [57/100], Step [371/735], Loss: 0.0126
Epoch [57/100], Step [381/735], Loss: 0.0001
Epoch [57/100], Step [391/735], Loss: 0.0122
Epoch [57/100], Step [401/735], Loss: 0.0001
Epoch [57/100], Step [411/735], Loss: 0.0278
Epoch [57/100], Step [421/735], Loss: 0.0059
Epoch [57/100], Step [431/735], Loss: 0.0363
Epoch [57/100], Step [441/735], Loss: 0.0032
Epoch [57/100], Step [451/735], Loss: 0.0001
Epoch [57/100], Step [461/735], Loss: 0.0336
Epoch [57/100], Step [471/735], Loss: 0.0056
Epoch [57/100], Step [481/735], Loss: 0.0008
Epoch [57/100], Step [491/735], Loss: 0.0169
Epoch [57/100], Step [501/735], Loss: 0.0001
Epoch [57/100], Step [511/735], Loss: 0.0254
Epoch [57/100], Step [521/735], Loss: 0.0532
Epoch [57/100], Step [531/735], Loss: 0.0046
Epoch [57/100], Step [541/735], Loss: 0.0017
Epoch [57/100], Step [551/735], Loss: 0.0416
Epoch [57/100], Step [561/735], Loss: 0.0008
Epoch [57/100], Step [571/735], Loss: 0.0050
Epoch [57/100], Step [581/735], Loss: 0.0008
Epoch [57/100], Step [591/735], Loss: 0.0001
Epoch [57/100], Step [601/735], Loss: 0.0003
Epoch [57/100], Step [611/735], Loss: 0.0173
Epoch [57/100], Step [621/735], Loss: 0.0022
Epoch [57/100], Step [631/735], Loss: 0.0034
Epoch [57/100], Step [641/735], Loss: 0.0003
Epoch [57/100], Step [651/735], Loss: 0.0012
Epoch [57/100], Step [661/735], Loss: 0.0012
Epoch [57/100], Step [671/735], Loss: 0.0013
Epoch [57/100], Step [681/735], Loss: 0.0097
Epoch [57/100], Step [691/735], Loss: 0.0002
Epoch [57/100], Step [701/735], Loss: 0.0032
Epoch [57/100], Step [711/735], Loss: 0.0146
Epoch [57/100], Step [721/735], Loss: 0.0001
Epoch [57/100], Step [731/735], Loss: 0.0144
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9127,Val AUC: 0.9545,Val precision: 0.8243, Val recall: 0.8770, Val Loss: 0.0737
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 57 | Time taken: 2239.33s |
| Val CE loss: 0.07368 | Val MSE 0.91271 | Train Loss 0.01043 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 58
Training for epoch 58
Epoch [58/100], Step [1/735], Loss: 0.0138
Epoch [58/100], Step [11/735], Loss: 0.0001
Epoch [58/100], Step [21/735], Loss: 0.0128
Epoch [58/100], Step [31/735], Loss: 0.0005
Epoch [58/100], Step [41/735], Loss: 0.0295
Epoch [58/100], Step [51/735], Loss: 0.0168
Epoch [58/100], Step [61/735], Loss: 0.0003
Epoch [58/100], Step [71/735], Loss: 0.0077
Epoch [58/100], Step [81/735], Loss: 0.0001
Epoch [58/100], Step [91/735], Loss: 0.0152
Epoch [58/100], Step [101/735], Loss: 0.0010
Epoch [58/100], Step [111/735], Loss: 0.0127
Epoch [58/100], Step [121/735], Loss: 0.0138
Epoch [58/100], Step [131/735], Loss: 0.0001
Epoch [58/100], Step [141/735], Loss: 0.0015
Epoch [58/100], Step [151/735], Loss: 0.0155
Epoch [58/100], Step [161/735], Loss: 0.0061
Epoch [58/100], Step [171/735], Loss: 0.0152
Epoch [58/100], Step [181/735], Loss: 0.0139
Epoch [58/100], Step [191/735], Loss: 0.0003
Epoch [58/100], Step [201/735], Loss: 0.0226
Epoch [58/100], Step [211/735], Loss: 0.0075
Epoch [58/100], Step [221/735], Loss: 0.0001
Epoch [58/100], Step [231/735], Loss: 0.0071
Epoch [58/100], Step [241/735], Loss: 0.0006
Epoch [58/100], Step [251/735], Loss: 0.0139
Epoch [58/100], Step [261/735], Loss: 0.0001
Epoch [58/100], Step [271/735], Loss: 0.0079
Epoch [58/100], Step [281/735], Loss: 0.0020
Epoch [58/100], Step [291/735], Loss: 0.0141
Epoch [58/100], Step [301/735], Loss: 0.0161
Epoch [58/100], Step [311/735], Loss: 0.0132
Epoch [58/100], Step [321/735], Loss: 0.0273
Epoch [58/100], Step [331/735], Loss: 0.0000
Epoch [58/100], Step [341/735], Loss: 0.0123
Epoch [58/100], Step [351/735], Loss: 0.0118
Epoch [58/100], Step [361/735], Loss: 0.0140
Epoch [58/100], Step [371/735], Loss: 0.0022
Epoch [58/100], Step [381/735], Loss: 0.0007
Epoch [58/100], Step [391/735], Loss: 0.0099
Epoch [58/100], Step [401/735], Loss: 0.0141
Epoch [58/100], Step [411/735], Loss: 0.0002
Epoch [58/100], Step [421/735], Loss: 0.0008
Epoch [58/100], Step [431/735], Loss: 0.0193
Epoch [58/100], Step [441/735], Loss: 0.0125
Epoch [58/100], Step [451/735], Loss: 0.0138
Epoch [58/100], Step [461/735], Loss: 0.0001
Epoch [58/100], Step [471/735], Loss: 0.0062
Epoch [58/100], Step [481/735], Loss: 0.0006
Epoch [58/100], Step [491/735], Loss: 0.0004
Epoch [58/100], Step [501/735], Loss: 0.0431
Epoch [58/100], Step [511/735], Loss: 0.0002
Epoch [58/100], Step [521/735], Loss: 0.0002
Epoch [58/100], Step [531/735], Loss: 0.0066
Epoch [58/100], Step [541/735], Loss: 0.0001
Epoch [58/100], Step [551/735], Loss: 0.0010
Epoch [58/100], Step [561/735], Loss: 0.0004
Epoch [58/100], Step [571/735], Loss: 0.0051
Epoch [58/100], Step [581/735], Loss: 0.0130
Epoch [58/100], Step [591/735], Loss: 0.0001
Epoch [58/100], Step [601/735], Loss: 0.0127
Epoch [58/100], Step [611/735], Loss: 0.0002
Epoch [58/100], Step [621/735], Loss: 0.0140
Epoch [58/100], Step [631/735], Loss: 0.0032
Epoch [58/100], Step [641/735], Loss: 0.0005
Epoch [58/100], Step [651/735], Loss: 0.0097
Epoch [58/100], Step [661/735], Loss: 0.0274
Epoch [58/100], Step [671/735], Loss: 0.0034
Epoch [58/100], Step [681/735], Loss: 0.0223
Epoch [58/100], Step [691/735], Loss: 0.0237
Epoch [58/100], Step [701/735], Loss: 0.0001
Epoch [58/100], Step [711/735], Loss: 0.0001
Epoch [58/100], Step [721/735], Loss: 0.0260
Epoch [58/100], Step [731/735], Loss: 0.0006
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9169,Val AUC: 0.9574,Val precision: 0.8383, Val recall: 0.8733, Val Loss: 0.0713
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 58 | Time taken: 2234.81s |
| Val CE loss: 0.07132 | Val MSE 0.91687 | Train Loss 0.00976 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 59
Training for epoch 59
Epoch [59/100], Step [1/735], Loss: 0.0002
Epoch [59/100], Step [11/735], Loss: 0.0113
Epoch [59/100], Step [21/735], Loss: 0.0293
Epoch [59/100], Step [31/735], Loss: 0.0001
Epoch [59/100], Step [41/735], Loss: 0.0064
Epoch [59/100], Step [51/735], Loss: 0.0001
Epoch [59/100], Step [61/735], Loss: 0.0204
Epoch [59/100], Step [71/735], Loss: 0.0044
Epoch [59/100], Step [81/735], Loss: 0.0131
Epoch [59/100], Step [91/735], Loss: 0.0114
Epoch [59/100], Step [101/735], Loss: 0.0006
Epoch [59/100], Step [111/735], Loss: 0.0396
Epoch [59/100], Step [121/735], Loss: 0.0018
Epoch [59/100], Step [131/735], Loss: 0.0261
Epoch [59/100], Step [141/735], Loss: 0.0008
Epoch [59/100], Step [151/735], Loss: 0.0250
Epoch [59/100], Step [161/735], Loss: 0.0245
Epoch [59/100], Step [171/735], Loss: 0.0002
Epoch [59/100], Step [181/735], Loss: 0.0031
Epoch [59/100], Step [191/735], Loss: 0.0004
Epoch [59/100], Step [201/735], Loss: 0.0377
Epoch [59/100], Step [211/735], Loss: 0.0256
Epoch [59/100], Step [221/735], Loss: 0.0146
Epoch [59/100], Step [231/735], Loss: 0.0001
Epoch [59/100], Step [241/735], Loss: 0.0252
Epoch [59/100], Step [251/735], Loss: 0.0003
Epoch [59/100], Step [261/735], Loss: 0.0179
Epoch [59/100], Step [271/735], Loss: 0.0005
Epoch [59/100], Step [281/735], Loss: 0.0230
Epoch [59/100], Step [291/735], Loss: 0.0262
Epoch [59/100], Step [301/735], Loss: 0.0377
Epoch [59/100], Step [311/735], Loss: 0.0155
Epoch [59/100], Step [321/735], Loss: 0.0041
Epoch [59/100], Step [331/735], Loss: 0.0000
Epoch [59/100], Step [341/735], Loss: 0.0053
Epoch [59/100], Step [351/735], Loss: 0.0052
Epoch [59/100], Step [361/735], Loss: 0.0114
Epoch [59/100], Step [371/735], Loss: 0.0198
Epoch [59/100], Step [381/735], Loss: 0.0160
Epoch [59/100], Step [391/735], Loss: 0.0027
Epoch [59/100], Step [401/735], Loss: 0.0003
Epoch [59/100], Step [411/735], Loss: 0.0018
Epoch [59/100], Step [421/735], Loss: 0.0241
Epoch [59/100], Step [431/735], Loss: 0.0001
Epoch [59/100], Step [441/735], Loss: 0.0018
Epoch [59/100], Step [451/735], Loss: 0.0047
Epoch [59/100], Step [461/735], Loss: 0.0231
Epoch [59/100], Step [471/735], Loss: 0.0313
Epoch [59/100], Step [481/735], Loss: 0.0349
Epoch [59/100], Step [491/735], Loss: 0.0012
Epoch [59/100], Step [501/735], Loss: 0.0437
Epoch [59/100], Step [511/735], Loss: 0.0278
Epoch [59/100], Step [521/735], Loss: 0.0002
Epoch [59/100], Step [531/735], Loss: 0.0244
Epoch [59/100], Step [541/735], Loss: 0.0151
Epoch [59/100], Step [551/735], Loss: 0.0145
Epoch [59/100], Step [561/735], Loss: 0.0261
Epoch [59/100], Step [571/735], Loss: 0.0001
Epoch [59/100], Step [581/735], Loss: 0.0245
Epoch [59/100], Step [591/735], Loss: 0.0025
Epoch [59/100], Step [601/735], Loss: 0.0003
Epoch [59/100], Step [611/735], Loss: 0.0018
Epoch [59/100], Step [621/735], Loss: 0.0004
Epoch [59/100], Step [631/735], Loss: 0.0267
Epoch [59/100], Step [641/735], Loss: 0.0072
Epoch [59/100], Step [651/735], Loss: 0.0006
Epoch [59/100], Step [661/735], Loss: 0.0413
Epoch [59/100], Step [671/735], Loss: 0.0011
Epoch [59/100], Step [681/735], Loss: 0.0002
Epoch [59/100], Step [691/735], Loss: 0.0018
Epoch [59/100], Step [701/735], Loss: 0.0045
Epoch [59/100], Step [711/735], Loss: 0.0193
Epoch [59/100], Step [721/735], Loss: 0.0038
Epoch [59/100], Step [731/735], Loss: 0.0010
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9143,Val AUC: 0.9542,Val precision: 0.8328, Val recall: 0.8702, Val Loss: 0.0745
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 59 | Time taken: 2235.80s |
| Val CE loss: 0.07445 | Val MSE 0.91427 | Train Loss 0.01031 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 60
Training for epoch 60
Epoch [60/100], Step [1/735], Loss: 0.0000
Epoch [60/100], Step [11/735], Loss: 0.0255
Epoch [60/100], Step [21/735], Loss: 0.0231
Epoch [60/100], Step [31/735], Loss: 0.0176
Epoch [60/100], Step [41/735], Loss: 0.0024
Epoch [60/100], Step [51/735], Loss: 0.0068
Epoch [60/100], Step [61/735], Loss: 0.0272
Epoch [60/100], Step [71/735], Loss: 0.0012
Epoch [60/100], Step [81/735], Loss: 0.0146
Epoch [60/100], Step [91/735], Loss: 0.0001
Epoch [60/100], Step [101/735], Loss: 0.0033
Epoch [60/100], Step [111/735], Loss: 0.0017
Epoch [60/100], Step [121/735], Loss: 0.0179
Epoch [60/100], Step [131/735], Loss: 0.0168
Epoch [60/100], Step [141/735], Loss: 0.0025
Epoch [60/100], Step [151/735], Loss: 0.0021
Epoch [60/100], Step [161/735], Loss: 0.0285
Epoch [60/100], Step [171/735], Loss: 0.0150
Epoch [60/100], Step [181/735], Loss: 0.0003
Epoch [60/100], Step [191/735], Loss: 0.0111
Epoch [60/100], Step [201/735], Loss: 0.0083
Epoch [60/100], Step [211/735], Loss: 0.0161
Epoch [60/100], Step [221/735], Loss: 0.0010
Epoch [60/100], Step [231/735], Loss: 0.0151
Epoch [60/100], Step [241/735], Loss: 0.0011
Epoch [60/100], Step [251/735], Loss: 0.0000
Epoch [60/100], Step [261/735], Loss: 0.0186
Epoch [60/100], Step [271/735], Loss: 0.0011
Epoch [60/100], Step [281/735], Loss: 0.0149
Epoch [60/100], Step [291/735], Loss: 0.0056
Epoch [60/100], Step [301/735], Loss: 0.0003
Epoch [60/100], Step [311/735], Loss: 0.0234
Epoch [60/100], Step [321/735], Loss: 0.0166
Epoch [60/100], Step [331/735], Loss: 0.0006
Epoch [60/100], Step [341/735], Loss: 0.0018
Epoch [60/100], Step [351/735], Loss: 0.0010
Epoch [60/100], Step [361/735], Loss: 0.0140
Epoch [60/100], Step [371/735], Loss: 0.0099
Epoch [60/100], Step [381/735], Loss: 0.0117
Epoch [60/100], Step [391/735], Loss: 0.0004
Epoch [60/100], Step [401/735], Loss: 0.0131
Epoch [60/100], Step [411/735], Loss: 0.0003
Epoch [60/100], Step [421/735], Loss: 0.0022
Epoch [60/100], Step [431/735], Loss: 0.0139
Epoch [60/100], Step [441/735], Loss: 0.0087
Epoch [60/100], Step [451/735], Loss: 0.0133
Epoch [60/100], Step [461/735], Loss: 0.0155
Epoch [60/100], Step [471/735], Loss: 0.0004
Epoch [60/100], Step [481/735], Loss: 0.0145
Epoch [60/100], Step [491/735], Loss: 0.0001
Epoch [60/100], Step [501/735], Loss: 0.0039
Epoch [60/100], Step [511/735], Loss: 0.0007
Epoch [60/100], Step [521/735], Loss: 0.0198
Epoch [60/100], Step [531/735], Loss: 0.0001
Epoch [60/100], Step [541/735], Loss: 0.0188
Epoch [60/100], Step [551/735], Loss: 0.0167
Epoch [60/100], Step [561/735], Loss: 0.0223
Epoch [60/100], Step [571/735], Loss: 0.0070
Epoch [60/100], Step [581/735], Loss: 0.0276
Epoch [60/100], Step [591/735], Loss: 0.0002
Epoch [60/100], Step [601/735], Loss: 0.0003
Epoch [60/100], Step [611/735], Loss: 0.0001
Epoch [60/100], Step [621/735], Loss: 0.0003
Epoch [60/100], Step [631/735], Loss: 0.0001
Epoch [60/100], Step [641/735], Loss: 0.0175
Epoch [60/100], Step [651/735], Loss: 0.0069
Epoch [60/100], Step [661/735], Loss: 0.0059
Epoch [60/100], Step [671/735], Loss: 0.0009
Epoch [60/100], Step [681/735], Loss: 0.0138
Epoch [60/100], Step [691/735], Loss: 0.0035
Epoch [60/100], Step [701/735], Loss: 0.0044
Epoch [60/100], Step [711/735], Loss: 0.0002
Epoch [60/100], Step [721/735], Loss: 0.0007
Epoch [60/100], Step [731/735], Loss: 0.0096
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9188,Val AUC: 0.9546,Val precision: 0.8454, Val recall: 0.8708, Val Loss: 0.0705
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 60 | Time taken: 2249.28s |
| Val CE loss: 0.07048 | Val MSE 0.91877 | Train Loss 0.00910 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 61
Training for epoch 61
Epoch [61/100], Step [1/735], Loss: 0.0095
Epoch [61/100], Step [11/735], Loss: 0.0190
Epoch [61/100], Step [21/735], Loss: 0.0166
Epoch [61/100], Step [31/735], Loss: 0.0042
Epoch [61/100], Step [41/735], Loss: 0.0005
Epoch [61/100], Step [51/735], Loss: 0.0005
Epoch [61/100], Step [61/735], Loss: 0.0083
Epoch [61/100], Step [71/735], Loss: 0.0001
Epoch [61/100], Step [81/735], Loss: 0.0001
Epoch [61/100], Step [91/735], Loss: 0.0097
Epoch [61/100], Step [101/735], Loss: 0.0104
Epoch [61/100], Step [111/735], Loss: 0.0115
Epoch [61/100], Step [121/735], Loss: 0.0172
Epoch [61/100], Step [131/735], Loss: 0.0316
Epoch [61/100], Step [141/735], Loss: 0.0019
Epoch [61/100], Step [151/735], Loss: 0.0001
Epoch [61/100], Step [161/735], Loss: 0.0091
Epoch [61/100], Step [171/735], Loss: 0.0215
Epoch [61/100], Step [181/735], Loss: 0.0006
Epoch [61/100], Step [191/735], Loss: 0.0196
Epoch [61/100], Step [201/735], Loss: 0.0124
Epoch [61/100], Step [211/735], Loss: 0.0003
Epoch [61/100], Step [221/735], Loss: 0.0003
Epoch [61/100], Step [231/735], Loss: 0.0186
Epoch [61/100], Step [241/735], Loss: 0.0162
Epoch [61/100], Step [251/735], Loss: 0.0003
Epoch [61/100], Step [261/735], Loss: 0.0006
Epoch [61/100], Step [271/735], Loss: 0.0108
Epoch [61/100], Step [281/735], Loss: 0.0008
Epoch [61/100], Step [291/735], Loss: 0.0118
Epoch [61/100], Step [301/735], Loss: 0.0152
Epoch [61/100], Step [311/735], Loss: 0.0123
Epoch [61/100], Step [321/735], Loss: 0.0006
Epoch [61/100], Step [331/735], Loss: 0.0006
Epoch [61/100], Step [341/735], Loss: 0.0001
Epoch [61/100], Step [351/735], Loss: 0.0011
Epoch [61/100], Step [361/735], Loss: 0.0003
Epoch [61/100], Step [371/735], Loss: 0.0022
Epoch [61/100], Step [381/735], Loss: 0.0118
Epoch [61/100], Step [391/735], Loss: 0.0029
Epoch [61/100], Step [401/735], Loss: 0.0098
Epoch [61/100], Step [411/735], Loss: 0.0052
Epoch [61/100], Step [421/735], Loss: 0.0003
Epoch [61/100], Step [431/735], Loss: 0.0192
Epoch [61/100], Step [441/735], Loss: 0.0273
Epoch [61/100], Step [451/735], Loss: 0.0002
Epoch [61/100], Step [461/735], Loss: 0.0002
Epoch [61/100], Step [471/735], Loss: 0.0087
Epoch [61/100], Step [481/735], Loss: 0.0261
Epoch [61/100], Step [491/735], Loss: 0.0019
Epoch [61/100], Step [501/735], Loss: 0.0083
Epoch [61/100], Step [511/735], Loss: 0.0014
Epoch [61/100], Step [521/735], Loss: 0.0061
Epoch [61/100], Step [531/735], Loss: 0.0018
Epoch [61/100], Step [541/735], Loss: 0.0019
Epoch [61/100], Step [551/735], Loss: 0.0082
Epoch [61/100], Step [561/735], Loss: 0.0010
Epoch [61/100], Step [571/735], Loss: 0.0131
Epoch [61/100], Step [581/735], Loss: 0.0000
Epoch [61/100], Step [591/735], Loss: 0.0001
Epoch [61/100], Step [601/735], Loss: 0.0006
Epoch [61/100], Step [611/735], Loss: 0.0004
Epoch [61/100], Step [621/735], Loss: 0.0144
Epoch [61/100], Step [631/735], Loss: 0.0001
Epoch [61/100], Step [641/735], Loss: 0.0059
Epoch [61/100], Step [651/735], Loss: 0.0116
Epoch [61/100], Step [661/735], Loss: 0.0262
Epoch [61/100], Step [671/735], Loss: 0.0050
Epoch [61/100], Step [681/735], Loss: 0.0007
Epoch [61/100], Step [691/735], Loss: 0.0137
Epoch [61/100], Step [701/735], Loss: 0.0094
Epoch [61/100], Step [711/735], Loss: 0.0310
Epoch [61/100], Step [721/735], Loss: 0.0114
Epoch [61/100], Step [731/735], Loss: 0.0004
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9144,Val AUC: 0.9537,Val precision: 0.8369, Val recall: 0.8647, Val Loss: 0.0726
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 61 | Time taken: 2230.24s |
| Val CE loss: 0.07256 | Val MSE 0.91444 | Train Loss 0.00975 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 62
Training for epoch 62
Epoch [62/100], Step [1/735], Loss: 0.0010
Epoch [62/100], Step [11/735], Loss: 0.0046
Epoch [62/100], Step [21/735], Loss: 0.0248
Epoch [62/100], Step [31/735], Loss: 0.0012
Epoch [62/100], Step [41/735], Loss: 0.0160
Epoch [62/100], Step [51/735], Loss: 0.0424
Epoch [62/100], Step [61/735], Loss: 0.0463
Epoch [62/100], Step [71/735], Loss: 0.0327
Epoch [62/100], Step [81/735], Loss: 0.0242
Epoch [62/100], Step [91/735], Loss: 0.0280
Epoch [62/100], Step [101/735], Loss: 0.0093
Epoch [62/100], Step [111/735], Loss: 0.0015
Epoch [62/100], Step [121/735], Loss: 0.0001
Epoch [62/100], Step [131/735], Loss: 0.0116
Epoch [62/100], Step [141/735], Loss: 0.0013
Epoch [62/100], Step [151/735], Loss: 0.0072
Epoch [62/100], Step [161/735], Loss: 0.0014
Epoch [62/100], Step [171/735], Loss: 0.0005
Epoch [62/100], Step [181/735], Loss: 0.0018
Epoch [62/100], Step [191/735], Loss: 0.0016
Epoch [62/100], Step [201/735], Loss: 0.0278
Epoch [62/100], Step [211/735], Loss: 0.0004
Epoch [62/100], Step [221/735], Loss: 0.0106
Epoch [62/100], Step [231/735], Loss: 0.0071
Epoch [62/100], Step [241/735], Loss: 0.0010
Epoch [62/100], Step [251/735], Loss: 0.0005
Epoch [62/100], Step [261/735], Loss: 0.0053
Epoch [62/100], Step [271/735], Loss: 0.0097
Epoch [62/100], Step [281/735], Loss: 0.0470
Epoch [62/100], Step [291/735], Loss: 0.0160
Epoch [62/100], Step [301/735], Loss: 0.0011
Epoch [62/100], Step [311/735], Loss: 0.0047
Epoch [62/100], Step [321/735], Loss: 0.0002
Epoch [62/100], Step [331/735], Loss: 0.0206
Epoch [62/100], Step [341/735], Loss: 0.0145
Epoch [62/100], Step [351/735], Loss: 0.0139
Epoch [62/100], Step [361/735], Loss: 0.0016
Epoch [62/100], Step [371/735], Loss: 0.0007
Epoch [62/100], Step [381/735], Loss: 0.0002
Epoch [62/100], Step [391/735], Loss: 0.0139
Epoch [62/100], Step [401/735], Loss: 0.0134
Epoch [62/100], Step [411/735], Loss: 0.0040
Epoch [62/100], Step [421/735], Loss: 0.0005
Epoch [62/100], Step [431/735], Loss: 0.0084
Epoch [62/100], Step [441/735], Loss: 0.0042
Epoch [62/100], Step [451/735], Loss: 0.0050
Epoch [62/100], Step [461/735], Loss: 0.0141
Epoch [62/100], Step [471/735], Loss: 0.0144
Epoch [62/100], Step [481/735], Loss: 0.0116
Epoch [62/100], Step [491/735], Loss: 0.0009
Epoch [62/100], Step [501/735], Loss: 0.0008
Epoch [62/100], Step [511/735], Loss: 0.0001
Epoch [62/100], Step [521/735], Loss: 0.0003
Epoch [62/100], Step [531/735], Loss: 0.0116
Epoch [62/100], Step [541/735], Loss: 0.0158
Epoch [62/100], Step [551/735], Loss: 0.0163
Epoch [62/100], Step [561/735], Loss: 0.0004
Epoch [62/100], Step [571/735], Loss: 0.0053
Epoch [62/100], Step [581/735], Loss: 0.0001
Epoch [62/100], Step [591/735], Loss: 0.0020
Epoch [62/100], Step [601/735], Loss: 0.0145
Epoch [62/100], Step [611/735], Loss: 0.0003
Epoch [62/100], Step [621/735], Loss: 0.0010
Epoch [62/100], Step [631/735], Loss: 0.0275
Epoch [62/100], Step [641/735], Loss: 0.0226
Epoch [62/100], Step [651/735], Loss: 0.0088
Epoch [62/100], Step [661/735], Loss: 0.0001
Epoch [62/100], Step [671/735], Loss: 0.0010
Epoch [62/100], Step [681/735], Loss: 0.0001
Epoch [62/100], Step [691/735], Loss: 0.0137
Epoch [62/100], Step [701/735], Loss: 0.0050
Epoch [62/100], Step [711/735], Loss: 0.0014
Epoch [62/100], Step [721/735], Loss: 0.0018
Epoch [62/100], Step [731/735], Loss: 0.0106
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9139,Val AUC: 0.9520,Val precision: 0.8374, Val recall: 0.8616, Val Loss: 0.0749
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 62 | Time taken: 2227.35s |
| Val CE loss: 0.07493 | Val MSE 0.91392 | Train Loss 0.00908 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 63
Training for epoch 63
Epoch [63/100], Step [1/735], Loss: 0.0001
Epoch [63/100], Step [11/735], Loss: 0.0012
Epoch [63/100], Step [21/735], Loss: 0.0091
Epoch [63/100], Step [31/735], Loss: 0.0001
Epoch [63/100], Step [41/735], Loss: 0.0131
Epoch [63/100], Step [51/735], Loss: 0.0139
Epoch [63/100], Step [61/735], Loss: 0.0094
Epoch [63/100], Step [71/735], Loss: 0.0003
Epoch [63/100], Step [81/735], Loss: 0.0149
Epoch [63/100], Step [91/735], Loss: 0.0224
Epoch [63/100], Step [101/735], Loss: 0.0000
Epoch [63/100], Step [111/735], Loss: 0.0250
Epoch [63/100], Step [121/735], Loss: 0.0043
Epoch [63/100], Step [131/735], Loss: 0.0092
Epoch [63/100], Step [141/735], Loss: 0.0002
Epoch [63/100], Step [151/735], Loss: 0.0245
Epoch [63/100], Step [161/735], Loss: 0.0088
Epoch [63/100], Step [171/735], Loss: 0.0015
Epoch [63/100], Step [181/735], Loss: 0.0155
Epoch [63/100], Step [191/735], Loss: 0.0023
Epoch [63/100], Step [201/735], Loss: 0.0011
Epoch [63/100], Step [211/735], Loss: 0.0001
Epoch [63/100], Step [221/735], Loss: 0.0008
Epoch [63/100], Step [231/735], Loss: 0.0072
Epoch [63/100], Step [241/735], Loss: 0.0091
Epoch [63/100], Step [251/735], Loss: 0.0019
Epoch [63/100], Step [261/735], Loss: 0.0159
Epoch [63/100], Step [271/735], Loss: 0.0018
Epoch [63/100], Step [281/735], Loss: 0.0181
Epoch [63/100], Step [291/735], Loss: 0.0163
Epoch [63/100], Step [301/735], Loss: 0.0140
Epoch [63/100], Step [311/735], Loss: 0.0023
Epoch [63/100], Step [321/735], Loss: 0.0001
Epoch [63/100], Step [331/735], Loss: 0.0072
Epoch [63/100], Step [341/735], Loss: 0.0025
Epoch [63/100], Step [351/735], Loss: 0.0012
Epoch [63/100], Step [361/735], Loss: 0.0094
Epoch [63/100], Step [371/735], Loss: 0.0107
Epoch [63/100], Step [381/735], Loss: 0.0279
Epoch [63/100], Step [391/735], Loss: 0.0070
Epoch [63/100], Step [401/735], Loss: 0.0245
Epoch [63/100], Step [411/735], Loss: 0.0001
Epoch [63/100], Step [421/735], Loss: 0.0003
Epoch [63/100], Step [431/735], Loss: 0.0026
Epoch [63/100], Step [441/735], Loss: 0.0277
Epoch [63/100], Step [451/735], Loss: 0.0002
Epoch [63/100], Step [461/735], Loss: 0.0065
Epoch [63/100], Step [471/735], Loss: 0.0139
Epoch [63/100], Step [481/735], Loss: 0.0157
Epoch [63/100], Step [491/735], Loss: 0.0440
Epoch [63/100], Step [501/735], Loss: 0.0214
Epoch [63/100], Step [511/735], Loss: 0.0029
Epoch [63/100], Step [521/735], Loss: 0.0037
Epoch [63/100], Step [531/735], Loss: 0.0000
Epoch [63/100], Step [541/735], Loss: 0.0426
Epoch [63/100], Step [551/735], Loss: 0.0004
Epoch [63/100], Step [561/735], Loss: 0.0001
Epoch [63/100], Step [571/735], Loss: 0.0000
Epoch [63/100], Step [581/735], Loss: 0.0224
Epoch [63/100], Step [591/735], Loss: 0.0022
Epoch [63/100], Step [601/735], Loss: 0.0073
Epoch [63/100], Step [611/735], Loss: 0.0001
Epoch [63/100], Step [621/735], Loss: 0.0249
Epoch [63/100], Step [631/735], Loss: 0.0001
Epoch [63/100], Step [641/735], Loss: 0.0007
Epoch [63/100], Step [651/735], Loss: 0.0209
Epoch [63/100], Step [661/735], Loss: 0.0009
Epoch [63/100], Step [671/735], Loss: 0.0278
Epoch [63/100], Step [681/735], Loss: 0.0076
Epoch [63/100], Step [691/735], Loss: 0.0004
Epoch [63/100], Step [701/735], Loss: 0.0030
Epoch [63/100], Step [711/735], Loss: 0.0056
Epoch [63/100], Step [721/735], Loss: 0.0000
Epoch [63/100], Step [731/735], Loss: 0.0155
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9172,Val AUC: 0.9568,Val precision: 0.8384, Val recall: 0.8745, Val Loss: 0.0722
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 63 | Time taken: 2260.42s |
| Val CE loss: 0.07220 | Val MSE 0.91722 | Train Loss 0.00923 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 64
Training for epoch 64
Epoch [64/100], Step [1/735], Loss: 0.0006
Epoch [64/100], Step [11/735], Loss: 0.0000
Epoch [64/100], Step [21/735], Loss: 0.0077
Epoch [64/100], Step [31/735], Loss: 0.0020
Epoch [64/100], Step [41/735], Loss: 0.0007
Epoch [64/100], Step [51/735], Loss: 0.0004
Epoch [64/100], Step [61/735], Loss: 0.0067
Epoch [64/100], Step [71/735], Loss: 0.0286
Epoch [64/100], Step [81/735], Loss: 0.0008
Epoch [64/100], Step [91/735], Loss: 0.0021
Epoch [64/100], Step [101/735], Loss: 0.0001
Epoch [64/100], Step [111/735], Loss: 0.0113
Epoch [64/100], Step [121/735], Loss: 0.0264
Epoch [64/100], Step [131/735], Loss: 0.0088
Epoch [64/100], Step [141/735], Loss: 0.0003
Epoch [64/100], Step [151/735], Loss: 0.0005
Epoch [64/100], Step [161/735], Loss: 0.0073
Epoch [64/100], Step [171/735], Loss: 0.0126
Epoch [64/100], Step [181/735], Loss: 0.0092
Epoch [64/100], Step [191/735], Loss: 0.0059
Epoch [64/100], Step [201/735], Loss: 0.0264
Epoch [64/100], Step [211/735], Loss: 0.0277
Epoch [64/100], Step [221/735], Loss: 0.0142
Epoch [64/100], Step [231/735], Loss: 0.0010
Epoch [64/100], Step [241/735], Loss: 0.0028
Epoch [64/100], Step [251/735], Loss: 0.0005
Epoch [64/100], Step [261/735], Loss: 0.0007
Epoch [64/100], Step [271/735], Loss: 0.0256
Epoch [64/100], Step [281/735], Loss: 0.0003
Epoch [64/100], Step [291/735], Loss: 0.0130
Epoch [64/100], Step [301/735], Loss: 0.0122
Epoch [64/100], Step [311/735], Loss: 0.0169
Epoch [64/100], Step [321/735], Loss: 0.0139
Epoch [64/100], Step [331/735], Loss: 0.0015
Epoch [64/100], Step [341/735], Loss: 0.0170
Epoch [64/100], Step [351/735], Loss: 0.0139
Epoch [64/100], Step [361/735], Loss: 0.0193
Epoch [64/100], Step [371/735], Loss: 0.0136
Epoch [64/100], Step [381/735], Loss: 0.0273
Epoch [64/100], Step [391/735], Loss: 0.0009
Epoch [64/100], Step [401/735], Loss: 0.0156
Epoch [64/100], Step [411/735], Loss: 0.0132
Epoch [64/100], Step [421/735], Loss: 0.0001
Epoch [64/100], Step [431/735], Loss: 0.0038
Epoch [64/100], Step [441/735], Loss: 0.0141
Epoch [64/100], Step [451/735], Loss: 0.0007
Epoch [64/100], Step [461/735], Loss: 0.0007
Epoch [64/100], Step [471/735], Loss: 0.0000
Epoch [64/100], Step [481/735], Loss: 0.0000
Epoch [64/100], Step [491/735], Loss: 0.0135
Epoch [64/100], Step [501/735], Loss: 0.0245
Epoch [64/100], Step [511/735], Loss: 0.0236
Epoch [64/100], Step [521/735], Loss: 0.0200
Epoch [64/100], Step [531/735], Loss: 0.0015
Epoch [64/100], Step [541/735], Loss: 0.0017
Epoch [64/100], Step [551/735], Loss: 0.0043
Epoch [64/100], Step [561/735], Loss: 0.0050
Epoch [64/100], Step [571/735], Loss: 0.0001
Epoch [64/100], Step [581/735], Loss: 0.0017
Epoch [64/100], Step [591/735], Loss: 0.0003
Epoch [64/100], Step [601/735], Loss: 0.0006
Epoch [64/100], Step [611/735], Loss: 0.0013
Epoch [64/100], Step [621/735], Loss: 0.0006
Epoch [64/100], Step [631/735], Loss: 0.0135
Epoch [64/100], Step [641/735], Loss: 0.0382
Epoch [64/100], Step [651/735], Loss: 0.0139
Epoch [64/100], Step [661/735], Loss: 0.0122
Epoch [64/100], Step [671/735], Loss: 0.0001
Epoch [64/100], Step [681/735], Loss: 0.0085
Epoch [64/100], Step [691/735], Loss: 0.0002
Epoch [64/100], Step [701/735], Loss: 0.0013
Epoch [64/100], Step [711/735], Loss: 0.0017
Epoch [64/100], Step [721/735], Loss: 0.0001
Epoch [64/100], Step [731/735], Loss: 0.0231
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9153,Val AUC: 0.9543,Val precision: 0.8354, Val recall: 0.8708, Val Loss: 0.0732
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 64 | Time taken: 2244.51s |
| Val CE loss: 0.07325 | Val MSE 0.91531 | Train Loss 0.00923 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 65
Training for epoch 65
Epoch [65/100], Step [1/735], Loss: 0.0026
Epoch [65/100], Step [11/735], Loss: 0.0143
Epoch [65/100], Step [21/735], Loss: 0.0016
Epoch [65/100], Step [31/735], Loss: 0.0149
Epoch [65/100], Step [41/735], Loss: 0.0015
Epoch [65/100], Step [51/735], Loss: 0.0014
Epoch [65/100], Step [61/735], Loss: 0.0002
Epoch [65/100], Step [71/735], Loss: 0.0002
Epoch [65/100], Step [81/735], Loss: 0.0002
Epoch [65/100], Step [91/735], Loss: 0.0132
Epoch [65/100], Step [101/735], Loss: 0.0275
Epoch [65/100], Step [111/735], Loss: 0.0003
Epoch [65/100], Step [121/735], Loss: 0.0007
Epoch [65/100], Step [131/735], Loss: 0.0006
Epoch [65/100], Step [141/735], Loss: 0.0004
Epoch [65/100], Step [151/735], Loss: 0.0250
Epoch [65/100], Step [161/735], Loss: 0.0162
Epoch [65/100], Step [171/735], Loss: 0.0002
Epoch [65/100], Step [181/735], Loss: 0.0155
Epoch [65/100], Step [191/735], Loss: 0.0006
Epoch [65/100], Step [201/735], Loss: 0.0333
Epoch [65/100], Step [211/735], Loss: 0.0001
Epoch [65/100], Step [221/735], Loss: 0.0002
Epoch [65/100], Step [231/735], Loss: 0.0043
Epoch [65/100], Step [241/735], Loss: 0.0088
Epoch [65/100], Step [251/735], Loss: 0.0002
Epoch [65/100], Step [261/735], Loss: 0.0003
Epoch [65/100], Step [271/735], Loss: 0.0003
Epoch [65/100], Step [281/735], Loss: 0.0000
Epoch [65/100], Step [291/735], Loss: 0.0201
Epoch [65/100], Step [301/735], Loss: 0.0003
Epoch [65/100], Step [311/735], Loss: 0.0026
Epoch [65/100], Step [321/735], Loss: 0.0003
Epoch [65/100], Step [331/735], Loss: 0.0412
Epoch [65/100], Step [341/735], Loss: 0.0090
Epoch [65/100], Step [351/735], Loss: 0.0066
Epoch [65/100], Step [361/735], Loss: 0.0027
Epoch [65/100], Step [371/735], Loss: 0.0013
Epoch [65/100], Step [381/735], Loss: 0.0069
Epoch [65/100], Step [391/735], Loss: 0.0092
Epoch [65/100], Step [401/735], Loss: 0.0207
Epoch [65/100], Step [411/735], Loss: 0.0001
Epoch [65/100], Step [421/735], Loss: 0.0281
Epoch [65/100], Step [431/735], Loss: 0.0139
Epoch [65/100], Step [441/735], Loss: 0.0212
Epoch [65/100], Step [451/735], Loss: 0.0277
Epoch [65/100], Step [461/735], Loss: 0.0143
Epoch [65/100], Step [471/735], Loss: 0.0154
Epoch [65/100], Step [481/735], Loss: 0.0125
Epoch [65/100], Step [491/735], Loss: 0.0004
Epoch [65/100], Step [501/735], Loss: 0.0001
Epoch [65/100], Step [511/735], Loss: 0.0259
Epoch [65/100], Step [521/735], Loss: 0.0003
Epoch [65/100], Step [531/735], Loss: 0.0254
Epoch [65/100], Step [541/735], Loss: 0.0188
Epoch [65/100], Step [551/735], Loss: 0.0000
Epoch [65/100], Step [561/735], Loss: 0.0000
Epoch [65/100], Step [571/735], Loss: 0.0107
Epoch [65/100], Step [581/735], Loss: 0.0056
Epoch [65/100], Step [591/735], Loss: 0.0000
Epoch [65/100], Step [601/735], Loss: 0.0046
Epoch [65/100], Step [611/735], Loss: 0.0155
Epoch [65/100], Step [621/735], Loss: 0.0220
Epoch [65/100], Step [631/735], Loss: 0.0008
Epoch [65/100], Step [641/735], Loss: 0.0142
Epoch [65/100], Step [651/735], Loss: 0.0603
Epoch [65/100], Step [661/735], Loss: 0.0001
Epoch [65/100], Step [671/735], Loss: 0.0057
Epoch [65/100], Step [681/735], Loss: 0.0296
Epoch [65/100], Step [691/735], Loss: 0.0144
Epoch [65/100], Step [701/735], Loss: 0.0163
Epoch [65/100], Step [711/735], Loss: 0.0075
Epoch [65/100], Step [721/735], Loss: 0.0005
Epoch [65/100], Step [731/735], Loss: 0.0153
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9163,Val AUC: 0.9559,Val precision: 0.8449, Val recall: 0.8610, Val Loss: 0.0721
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 65 | Time taken: 2220.31s |
| Val CE loss: 0.07213 | Val MSE 0.91635 | Train Loss 0.00910 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 66
Training for epoch 66
Epoch [66/100], Step [1/735], Loss: 0.0129
Epoch [66/100], Step [11/735], Loss: 0.0250
Epoch [66/100], Step [21/735], Loss: 0.0004
Epoch [66/100], Step [31/735], Loss: 0.0004
Epoch [66/100], Step [41/735], Loss: 0.0019
Epoch [66/100], Step [51/735], Loss: 0.0002
Epoch [66/100], Step [61/735], Loss: 0.0153
Epoch [66/100], Step [71/735], Loss: 0.0005
Epoch [66/100], Step [81/735], Loss: 0.0188
Epoch [66/100], Step [91/735], Loss: 0.0138
Epoch [66/100], Step [101/735], Loss: 0.0002
Epoch [66/100], Step [111/735], Loss: 0.0144
Epoch [66/100], Step [121/735], Loss: 0.0004
Epoch [66/100], Step [131/735], Loss: 0.0090
Epoch [66/100], Step [141/735], Loss: 0.0111
Epoch [66/100], Step [151/735], Loss: 0.0207
Epoch [66/100], Step [161/735], Loss: 0.0003
Epoch [66/100], Step [171/735], Loss: 0.0142
Epoch [66/100], Step [181/735], Loss: 0.0293
Epoch [66/100], Step [191/735], Loss: 0.0132
Epoch [66/100], Step [201/735], Loss: 0.0161
Epoch [66/100], Step [211/735], Loss: 0.0258
Epoch [66/100], Step [221/735], Loss: 0.0132
Epoch [66/100], Step [231/735], Loss: 0.0011
Epoch [66/100], Step [241/735], Loss: 0.0003
Epoch [66/100], Step [251/735], Loss: 0.0037
Epoch [66/100], Step [261/735], Loss: 0.0218
Epoch [66/100], Step [271/735], Loss: 0.0002
Epoch [66/100], Step [281/735], Loss: 0.0004
Epoch [66/100], Step [291/735], Loss: 0.0137
Epoch [66/100], Step [301/735], Loss: 0.0202
Epoch [66/100], Step [311/735], Loss: 0.0087
Epoch [66/100], Step [321/735], Loss: 0.0014
Epoch [66/100], Step [331/735], Loss: 0.0247
Epoch [66/100], Step [341/735], Loss: 0.0015
Epoch [66/100], Step [351/735], Loss: 0.0029
Epoch [66/100], Step [361/735], Loss: 0.0042
Epoch [66/100], Step [371/735], Loss: 0.0009
Epoch [66/100], Step [381/735], Loss: 0.0269
Epoch [66/100], Step [391/735], Loss: 0.0126
Epoch [66/100], Step [401/735], Loss: 0.0138
Epoch [66/100], Step [411/735], Loss: 0.0425
Epoch [66/100], Step [421/735], Loss: 0.0423
Epoch [66/100], Step [431/735], Loss: 0.0132
Epoch [66/100], Step [441/735], Loss: 0.0085
Epoch [66/100], Step [451/735], Loss: 0.0105
Epoch [66/100], Step [461/735], Loss: 0.0112
Epoch [66/100], Step [471/735], Loss: 0.0183
Epoch [66/100], Step [481/735], Loss: 0.0051
Epoch [66/100], Step [491/735], Loss: 0.0097
Epoch [66/100], Step [501/735], Loss: 0.0040
Epoch [66/100], Step [511/735], Loss: 0.0066
Epoch [66/100], Step [521/735], Loss: 0.0180
Epoch [66/100], Step [531/735], Loss: 0.0005
Epoch [66/100], Step [541/735], Loss: 0.0189
Epoch [66/100], Step [551/735], Loss: 0.0001
Epoch [66/100], Step [561/735], Loss: 0.0143
Epoch [66/100], Step [571/735], Loss: 0.0037
Epoch [66/100], Step [581/735], Loss: 0.0004
Epoch [66/100], Step [591/735], Loss: 0.0001
Epoch [66/100], Step [601/735], Loss: 0.0171
Epoch [66/100], Step [611/735], Loss: 0.0148
Epoch [66/100], Step [621/735], Loss: 0.0133
Epoch [66/100], Step [631/735], Loss: 0.0140
Epoch [66/100], Step [641/735], Loss: 0.0403
Epoch [66/100], Step [651/735], Loss: 0.0118
Epoch [66/100], Step [661/735], Loss: 0.0003
Epoch [66/100], Step [671/735], Loss: 0.0001
Epoch [66/100], Step [681/735], Loss: 0.0077
Epoch [66/100], Step [691/735], Loss: 0.0250
Epoch [66/100], Step [701/735], Loss: 0.0000
Epoch [66/100], Step [711/735], Loss: 0.0011
Epoch [66/100], Step [721/735], Loss: 0.0203
Epoch [66/100], Step [731/735], Loss: 0.0218
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9165,Val AUC: 0.9577,Val precision: 0.8421, Val recall: 0.8659, Val Loss: 0.0710
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 66 | Time taken: 2219.48s |
| Val CE loss: 0.07102 | Val MSE 0.91652 | Train Loss 0.00925 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 67
Training for epoch 67
Epoch [67/100], Step [1/735], Loss: 0.0123
Epoch [67/100], Step [11/735], Loss: 0.0266
Epoch [67/100], Step [21/735], Loss: 0.0024
Epoch [67/100], Step [31/735], Loss: 0.0155
Epoch [67/100], Step [41/735], Loss: 0.0144
Epoch [67/100], Step [51/735], Loss: 0.0023
Epoch [67/100], Step [61/735], Loss: 0.0004
Epoch [67/100], Step [71/735], Loss: 0.0061
Epoch [67/100], Step [81/735], Loss: 0.0118
Epoch [67/100], Step [91/735], Loss: 0.0138
Epoch [67/100], Step [101/735], Loss: 0.0052
Epoch [67/100], Step [111/735], Loss: 0.0091
Epoch [67/100], Step [121/735], Loss: 0.0018
Epoch [67/100], Step [131/735], Loss: 0.0235
Epoch [67/100], Step [141/735], Loss: 0.0331
Epoch [67/100], Step [151/735], Loss: 0.0008
Epoch [67/100], Step [161/735], Loss: 0.0065
Epoch [67/100], Step [171/735], Loss: 0.0169
Epoch [67/100], Step [181/735], Loss: 0.0007
Epoch [67/100], Step [191/735], Loss: 0.0000
Epoch [67/100], Step [201/735], Loss: 0.0036
Epoch [67/100], Step [211/735], Loss: 0.0001
Epoch [67/100], Step [221/735], Loss: 0.0006
Epoch [67/100], Step [231/735], Loss: 0.0001
Epoch [67/100], Step [241/735], Loss: 0.0034
Epoch [67/100], Step [251/735], Loss: 0.0123
Epoch [67/100], Step [261/735], Loss: 0.0011
Epoch [67/100], Step [271/735], Loss: 0.0149
Epoch [67/100], Step [281/735], Loss: 0.0040
Epoch [67/100], Step [291/735], Loss: 0.0053
Epoch [67/100], Step [301/735], Loss: 0.0005
Epoch [67/100], Step [311/735], Loss: 0.0138
Epoch [67/100], Step [321/735], Loss: 0.0002
Epoch [67/100], Step [331/735], Loss: 0.0001
Epoch [67/100], Step [341/735], Loss: 0.0076
Epoch [67/100], Step [351/735], Loss: 0.0344
Epoch [67/100], Step [361/735], Loss: 0.0118
Epoch [67/100], Step [371/735], Loss: 0.0008
Epoch [67/100], Step [381/735], Loss: 0.0288
Epoch [67/100], Step [391/735], Loss: 0.0039
Epoch [67/100], Step [401/735], Loss: 0.0024
Epoch [67/100], Step [411/735], Loss: 0.0152
Epoch [67/100], Step [421/735], Loss: 0.0001
Epoch [67/100], Step [431/735], Loss: 0.0001
Epoch [67/100], Step [441/735], Loss: 0.0025
Epoch [67/100], Step [451/735], Loss: 0.0031
Epoch [67/100], Step [461/735], Loss: 0.0002
Epoch [67/100], Step [471/735], Loss: 0.0008
Epoch [67/100], Step [481/735], Loss: 0.0037
Epoch [67/100], Step [491/735], Loss: 0.0323
Epoch [67/100], Step [501/735], Loss: 0.0022
Epoch [67/100], Step [511/735], Loss: 0.0002
Epoch [67/100], Step [521/735], Loss: 0.0045
Epoch [67/100], Step [531/735], Loss: 0.0001
Epoch [67/100], Step [541/735], Loss: 0.0259
Epoch [67/100], Step [551/735], Loss: 0.0001
Epoch [67/100], Step [561/735], Loss: 0.0092
Epoch [67/100], Step [571/735], Loss: 0.0176
Epoch [67/100], Step [581/735], Loss: 0.0339
Epoch [67/100], Step [591/735], Loss: 0.0286
Epoch [67/100], Step [601/735], Loss: 0.0001
Epoch [67/100], Step [611/735], Loss: 0.0003
Epoch [67/100], Step [621/735], Loss: 0.0139
Epoch [67/100], Step [631/735], Loss: 0.0014
Epoch [67/100], Step [641/735], Loss: 0.0002
Epoch [67/100], Step [651/735], Loss: 0.0105
Epoch [67/100], Step [661/735], Loss: 0.0147
Epoch [67/100], Step [671/735], Loss: 0.0002
Epoch [67/100], Step [681/735], Loss: 0.0001
Epoch [67/100], Step [691/735], Loss: 0.0004
Epoch [67/100], Step [701/735], Loss: 0.0021
Epoch [67/100], Step [711/735], Loss: 0.0045
Epoch [67/100], Step [721/735], Loss: 0.0047
Epoch [67/100], Step [731/735], Loss: 0.0143
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9212,Val AUC: 0.9581,Val precision: 0.8521, Val recall: 0.8715, Val Loss: 0.0682
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 67 | Time taken: 2271.52s |
| Val CE loss: 0.06821 | Val MSE 0.92120 | Train Loss 0.00902 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 68
Training for epoch 68
Epoch [68/100], Step [1/735], Loss: 0.0141
Epoch [68/100], Step [11/735], Loss: 0.0000
Epoch [68/100], Step [21/735], Loss: 0.0005
Epoch [68/100], Step [31/735], Loss: 0.0006
Epoch [68/100], Step [41/735], Loss: 0.0146
Epoch [68/100], Step [51/735], Loss: 0.0139
Epoch [68/100], Step [61/735], Loss: 0.0171
Epoch [68/100], Step [71/735], Loss: 0.0003
Epoch [68/100], Step [81/735], Loss: 0.0129
Epoch [68/100], Step [91/735], Loss: 0.0271
Epoch [68/100], Step [101/735], Loss: 0.0007
Epoch [68/100], Step [111/735], Loss: 0.0102
Epoch [68/100], Step [121/735], Loss: 0.0159
Epoch [68/100], Step [131/735], Loss: 0.0030
Epoch [68/100], Step [141/735], Loss: 0.0215
Epoch [68/100], Step [151/735], Loss: 0.0004
Epoch [68/100], Step [161/735], Loss: 0.0132
Epoch [68/100], Step [171/735], Loss: 0.0275
Epoch [68/100], Step [181/735], Loss: 0.0023
Epoch [68/100], Step [191/735], Loss: 0.0133
Epoch [68/100], Step [201/735], Loss: 0.0153
Epoch [68/100], Step [211/735], Loss: 0.0137
Epoch [68/100], Step [221/735], Loss: 0.0066
Epoch [68/100], Step [231/735], Loss: 0.0138
Epoch [68/100], Step [241/735], Loss: 0.0149
Epoch [68/100], Step [251/735], Loss: 0.0007
Epoch [68/100], Step [261/735], Loss: 0.0000
Epoch [68/100], Step [271/735], Loss: 0.0088
Epoch [68/100], Step [281/735], Loss: 0.0013
Epoch [68/100], Step [291/735], Loss: 0.0045
Epoch [68/100], Step [301/735], Loss: 0.0020
Epoch [68/100], Step [311/735], Loss: 0.0057
Epoch [68/100], Step [321/735], Loss: 0.0065
Epoch [68/100], Step [331/735], Loss: 0.0215
Epoch [68/100], Step [341/735], Loss: 0.0001
Epoch [68/100], Step [351/735], Loss: 0.0284
Epoch [68/100], Step [361/735], Loss: 0.0012
Epoch [68/100], Step [371/735], Loss: 0.0051
Epoch [68/100], Step [381/735], Loss: 0.0002
Epoch [68/100], Step [391/735], Loss: 0.0235
Epoch [68/100], Step [401/735], Loss: 0.0003
Epoch [68/100], Step [411/735], Loss: 0.0328
Epoch [68/100], Step [421/735], Loss: 0.0017
Epoch [68/100], Step [431/735], Loss: 0.0001
Epoch [68/100], Step [441/735], Loss: 0.0048
Epoch [68/100], Step [451/735], Loss: 0.0148
Epoch [68/100], Step [461/735], Loss: 0.0009
Epoch [68/100], Step [471/735], Loss: 0.0007
Epoch [68/100], Step [481/735], Loss: 0.0066
Epoch [68/100], Step [491/735], Loss: 0.0023
Epoch [68/100], Step [501/735], Loss: 0.0116
Epoch [68/100], Step [511/735], Loss: 0.0001
Epoch [68/100], Step [521/735], Loss: 0.0007
Epoch [68/100], Step [531/735], Loss: 0.0003
Epoch [68/100], Step [541/735], Loss: 0.0144
Epoch [68/100], Step [551/735], Loss: 0.0210
Epoch [68/100], Step [561/735], Loss: 0.0059
Epoch [68/100], Step [571/735], Loss: 0.0197
Epoch [68/100], Step [581/735], Loss: 0.0162
Epoch [68/100], Step [591/735], Loss: 0.0241
Epoch [68/100], Step [601/735], Loss: 0.0001
Epoch [68/100], Step [611/735], Loss: 0.0270
Epoch [68/100], Step [621/735], Loss: 0.0012
Epoch [68/100], Step [631/735], Loss: 0.0151
Epoch [68/100], Step [641/735], Loss: 0.0050
Epoch [68/100], Step [651/735], Loss: 0.0005
Epoch [68/100], Step [661/735], Loss: 0.0140
Epoch [68/100], Step [671/735], Loss: 0.0003
Epoch [68/100], Step [681/735], Loss: 0.0166
Epoch [68/100], Step [691/735], Loss: 0.0139
Epoch [68/100], Step [701/735], Loss: 0.0272
Epoch [68/100], Step [711/735], Loss: 0.0004
Epoch [68/100], Step [721/735], Loss: 0.0101
Epoch [68/100], Step [731/735], Loss: 0.0002
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9118,Val AUC: 0.9529,Val precision: 0.8318, Val recall: 0.8610, Val Loss: 0.0787
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 68 | Time taken: 2230.00s |
| Val CE loss: 0.07866 | Val MSE 0.91185 | Train Loss 0.00867 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 69
Training for epoch 69
Epoch [69/100], Step [1/735], Loss: 0.0499
Epoch [69/100], Step [11/735], Loss: 0.0000
Epoch [69/100], Step [21/735], Loss: 0.0086
Epoch [69/100], Step [31/735], Loss: 0.0038
Epoch [69/100], Step [41/735], Loss: 0.0043
Epoch [69/100], Step [51/735], Loss: 0.0066
Epoch [69/100], Step [61/735], Loss: 0.0145
Epoch [69/100], Step [71/735], Loss: 0.0001
Epoch [69/100], Step [81/735], Loss: 0.0202
Epoch [69/100], Step [91/735], Loss: 0.0019
Epoch [69/100], Step [101/735], Loss: 0.0001
Epoch [69/100], Step [111/735], Loss: 0.0014
Epoch [69/100], Step [121/735], Loss: 0.0276
Epoch [69/100], Step [131/735], Loss: 0.0002
Epoch [69/100], Step [141/735], Loss: 0.0186
Epoch [69/100], Step [151/735], Loss: 0.0002
Epoch [69/100], Step [161/735], Loss: 0.0189
Epoch [69/100], Step [171/735], Loss: 0.0203
Epoch [69/100], Step [181/735], Loss: 0.0001
Epoch [69/100], Step [191/735], Loss: 0.0136
Epoch [69/100], Step [201/735], Loss: 0.0144
Epoch [69/100], Step [211/735], Loss: 0.0093
Epoch [69/100], Step [221/735], Loss: 0.0003
Epoch [69/100], Step [231/735], Loss: 0.0002
Epoch [69/100], Step [241/735], Loss: 0.0008
Epoch [69/100], Step [251/735], Loss: 0.0001
Epoch [69/100], Step [261/735], Loss: 0.0052
Epoch [69/100], Step [271/735], Loss: 0.0005
Epoch [69/100], Step [281/735], Loss: 0.0232
Epoch [69/100], Step [291/735], Loss: 0.0002
Epoch [69/100], Step [301/735], Loss: 0.0007
Epoch [69/100], Step [311/735], Loss: 0.0150
Epoch [69/100], Step [321/735], Loss: 0.0001
Epoch [69/100], Step [331/735], Loss: 0.0113
Epoch [69/100], Step [341/735], Loss: 0.0143
Epoch [69/100], Step [351/735], Loss: 0.0001
Epoch [69/100], Step [361/735], Loss: 0.0131
Epoch [69/100], Step [371/735], Loss: 0.0169
Epoch [69/100], Step [381/735], Loss: 0.0059
Epoch [69/100], Step [391/735], Loss: 0.0011
Epoch [69/100], Step [401/735], Loss: 0.0039
Epoch [69/100], Step [411/735], Loss: 0.0007
Epoch [69/100], Step [421/735], Loss: 0.0003
Epoch [69/100], Step [431/735], Loss: 0.0005
Epoch [69/100], Step [441/735], Loss: 0.0024
Epoch [69/100], Step [451/735], Loss: 0.0002
Epoch [69/100], Step [461/735], Loss: 0.0030
Epoch [69/100], Step [471/735], Loss: 0.0000
Epoch [69/100], Step [481/735], Loss: 0.0001
Epoch [69/100], Step [491/735], Loss: 0.0003
Epoch [69/100], Step [501/735], Loss: 0.0141
Epoch [69/100], Step [511/735], Loss: 0.0011
Epoch [69/100], Step [521/735], Loss: 0.0115
Epoch [69/100], Step [531/735], Loss: 0.0133
Epoch [69/100], Step [541/735], Loss: 0.0004
Epoch [69/100], Step [551/735], Loss: 0.0139
Epoch [69/100], Step [561/735], Loss: 0.0009
Epoch [69/100], Step [571/735], Loss: 0.0246
Epoch [69/100], Step [581/735], Loss: 0.0013
Epoch [69/100], Step [591/735], Loss: 0.0008
Epoch [69/100], Step [601/735], Loss: 0.0111
Epoch [69/100], Step [611/735], Loss: 0.0012
Epoch [69/100], Step [621/735], Loss: 0.0086
Epoch [69/100], Step [631/735], Loss: 0.0069
Epoch [69/100], Step [641/735], Loss: 0.0002
Epoch [69/100], Step [651/735], Loss: 0.0001
Epoch [69/100], Step [661/735], Loss: 0.0119
Epoch [69/100], Step [671/735], Loss: 0.0124
Epoch [69/100], Step [681/735], Loss: 0.0002
Epoch [69/100], Step [691/735], Loss: 0.0046
Epoch [69/100], Step [701/735], Loss: 0.0020
Epoch [69/100], Step [711/735], Loss: 0.0001
Epoch [69/100], Step [721/735], Loss: 0.0001
Epoch [69/100], Step [731/735], Loss: 0.0204
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9240,Val AUC: 0.9598,Val precision: 0.8643, Val recall: 0.8659, Val Loss: 0.0665
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 69 | Time taken: 2218.02s |
| Val CE loss: 0.06651 | Val MSE 0.92397 | Train Loss 0.00861 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 70
Training for epoch 70
Epoch [70/100], Step [1/735], Loss: 0.0002
Epoch [70/100], Step [11/735], Loss: 0.0005
Epoch [70/100], Step [21/735], Loss: 0.0141
Epoch [70/100], Step [31/735], Loss: 0.0137
Epoch [70/100], Step [41/735], Loss: 0.0059
Epoch [70/100], Step [51/735], Loss: 0.0068
Epoch [70/100], Step [61/735], Loss: 0.0006
Epoch [70/100], Step [71/735], Loss: 0.0014
Epoch [70/100], Step [81/735], Loss: 0.0007
Epoch [70/100], Step [91/735], Loss: 0.0010
Epoch [70/100], Step [101/735], Loss: 0.0008
Epoch [70/100], Step [111/735], Loss: 0.0005
Epoch [70/100], Step [121/735], Loss: 0.0161
Epoch [70/100], Step [131/735], Loss: 0.0029
Epoch [70/100], Step [141/735], Loss: 0.0059
Epoch [70/100], Step [151/735], Loss: 0.0007
Epoch [70/100], Step [161/735], Loss: 0.0015
Epoch [70/100], Step [171/735], Loss: 0.0002
Epoch [70/100], Step [181/735], Loss: 0.0077
Epoch [70/100], Step [191/735], Loss: 0.0005
Epoch [70/100], Step [201/735], Loss: 0.0204
Epoch [70/100], Step [211/735], Loss: 0.0139
Epoch [70/100], Step [221/735], Loss: 0.0182
Epoch [70/100], Step [231/735], Loss: 0.0004
Epoch [70/100], Step [241/735], Loss: 0.0001
Epoch [70/100], Step [251/735], Loss: 0.0008
Epoch [70/100], Step [261/735], Loss: 0.0148
Epoch [70/100], Step [271/735], Loss: 0.0020
Epoch [70/100], Step [281/735], Loss: 0.0060
Epoch [70/100], Step [291/735], Loss: 0.0204
Epoch [70/100], Step [301/735], Loss: 0.0046
Epoch [70/100], Step [311/735], Loss: 0.0007
Epoch [70/100], Step [321/735], Loss: 0.0001
Epoch [70/100], Step [331/735], Loss: 0.0193
Epoch [70/100], Step [341/735], Loss: 0.0080
Epoch [70/100], Step [351/735], Loss: 0.0003
Epoch [70/100], Step [361/735], Loss: 0.0022
Epoch [70/100], Step [371/735], Loss: 0.0015
Epoch [70/100], Step [381/735], Loss: 0.0028
Epoch [70/100], Step [391/735], Loss: 0.0160
Epoch [70/100], Step [401/735], Loss: 0.0220
Epoch [70/100], Step [411/735], Loss: 0.0090
Epoch [70/100], Step [421/735], Loss: 0.0140
Epoch [70/100], Step [431/735], Loss: 0.0003
Epoch [70/100], Step [441/735], Loss: 0.0123
Epoch [70/100], Step [451/735], Loss: 0.0139
Epoch [70/100], Step [461/735], Loss: 0.0079
Epoch [70/100], Step [471/735], Loss: 0.0085
Epoch [70/100], Step [481/735], Loss: 0.0124
Epoch [70/100], Step [491/735], Loss: 0.0017
Epoch [70/100], Step [501/735], Loss: 0.0138
Epoch [70/100], Step [511/735], Loss: 0.0010
Epoch [70/100], Step [521/735], Loss: 0.0189
Epoch [70/100], Step [531/735], Loss: 0.0406
Epoch [70/100], Step [541/735], Loss: 0.0139
Epoch [70/100], Step [551/735], Loss: 0.0114
Epoch [70/100], Step [561/735], Loss: 0.0143
Epoch [70/100], Step [571/735], Loss: 0.0277
Epoch [70/100], Step [581/735], Loss: 0.0014
Epoch [70/100], Step [591/735], Loss: 0.0021
Epoch [70/100], Step [601/735], Loss: 0.0003
Epoch [70/100], Step [611/735], Loss: 0.0001
Epoch [70/100], Step [621/735], Loss: 0.0006
Epoch [70/100], Step [631/735], Loss: 0.0365
Epoch [70/100], Step [641/735], Loss: 0.0075
Epoch [70/100], Step [651/735], Loss: 0.0031
Epoch [70/100], Step [661/735], Loss: 0.0003
Epoch [70/100], Step [671/735], Loss: 0.0002
Epoch [70/100], Step [681/735], Loss: 0.0145
Epoch [70/100], Step [691/735], Loss: 0.0145
Epoch [70/100], Step [701/735], Loss: 0.0004
Epoch [70/100], Step [711/735], Loss: 0.0001
Epoch [70/100], Step [721/735], Loss: 0.0001
Epoch [70/100], Step [731/735], Loss: 0.0123
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9165,Val AUC: 0.9542,Val precision: 0.8349, Val recall: 0.8770, Val Loss: 0.0740
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 70 | Time taken: 2215.67s |
| Val CE loss: 0.07399 | Val MSE 0.91652 | Train Loss 0.00905 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 71
Training for epoch 71
Epoch [71/100], Step [1/735], Loss: 0.0268
Epoch [71/100], Step [11/735], Loss: 0.0000
Epoch [71/100], Step [21/735], Loss: 0.0149
Epoch [71/100], Step [31/735], Loss: 0.0001
Epoch [71/100], Step [41/735], Loss: 0.0266
Epoch [71/100], Step [51/735], Loss: 0.0069
Epoch [71/100], Step [61/735], Loss: 0.0322
Epoch [71/100], Step [71/735], Loss: 0.0149
Epoch [71/100], Step [81/735], Loss: 0.0204
Epoch [71/100], Step [91/735], Loss: 0.0001
Epoch [71/100], Step [101/735], Loss: 0.0003
Epoch [71/100], Step [111/735], Loss: 0.0007
Epoch [71/100], Step [121/735], Loss: 0.0033
Epoch [71/100], Step [131/735], Loss: 0.0182
Epoch [71/100], Step [141/735], Loss: 0.0002
Epoch [71/100], Step [151/735], Loss: 0.0160
Epoch [71/100], Step [161/735], Loss: 0.0145
Epoch [71/100], Step [171/735], Loss: 0.0010
Epoch [71/100], Step [181/735], Loss: 0.0036
Epoch [71/100], Step [191/735], Loss: 0.0272
Epoch [71/100], Step [201/735], Loss: 0.0002
Epoch [71/100], Step [211/735], Loss: 0.0075
Epoch [71/100], Step [221/735], Loss: 0.0277
Epoch [71/100], Step [231/735], Loss: 0.0154
Epoch [71/100], Step [241/735], Loss: 0.0005
Epoch [71/100], Step [251/735], Loss: 0.0142
Epoch [71/100], Step [261/735], Loss: 0.0002
Epoch [71/100], Step [271/735], Loss: 0.0172
Epoch [71/100], Step [281/735], Loss: 0.0001
Epoch [71/100], Step [291/735], Loss: 0.0278
Epoch [71/100], Step [301/735], Loss: 0.0138
Epoch [71/100], Step [311/735], Loss: 0.0448
Epoch [71/100], Step [321/735], Loss: 0.0003
Epoch [71/100], Step [331/735], Loss: 0.0002
Epoch [71/100], Step [341/735], Loss: 0.0040
Epoch [71/100], Step [351/735], Loss: 0.0002
Epoch [71/100], Step [361/735], Loss: 0.0032
Epoch [71/100], Step [371/735], Loss: 0.0001
Epoch [71/100], Step [381/735], Loss: 0.0004
Epoch [71/100], Step [391/735], Loss: 0.0113
Epoch [71/100], Step [401/735], Loss: 0.0006
Epoch [71/100], Step [411/735], Loss: 0.0000
Epoch [71/100], Step [421/735], Loss: 0.0264
Epoch [71/100], Step [431/735], Loss: 0.0007
Epoch [71/100], Step [441/735], Loss: 0.0002
Epoch [71/100], Step [451/735], Loss: 0.0001
Epoch [71/100], Step [461/735], Loss: 0.0129
Epoch [71/100], Step [471/735], Loss: 0.0023
Epoch [71/100], Step [481/735], Loss: 0.0020
Epoch [71/100], Step [491/735], Loss: 0.0010
Epoch [71/100], Step [501/735], Loss: 0.0016
Epoch [71/100], Step [511/735], Loss: 0.0003
Epoch [71/100], Step [521/735], Loss: 0.0096
Epoch [71/100], Step [531/735], Loss: 0.0029
Epoch [71/100], Step [541/735], Loss: 0.0229
Epoch [71/100], Step [551/735], Loss: 0.0159
Epoch [71/100], Step [561/735], Loss: 0.0007
Epoch [71/100], Step [571/735], Loss: 0.0138
Epoch [71/100], Step [581/735], Loss: 0.0137
Epoch [71/100], Step [591/735], Loss: 0.0122
Epoch [71/100], Step [601/735], Loss: 0.0138
Epoch [71/100], Step [611/735], Loss: 0.0279
Epoch [71/100], Step [621/735], Loss: 0.0002
Epoch [71/100], Step [631/735], Loss: 0.0142
Epoch [71/100], Step [641/735], Loss: 0.0146
Epoch [71/100], Step [651/735], Loss: 0.0200
Epoch [71/100], Step [661/735], Loss: 0.0002
Epoch [71/100], Step [671/735], Loss: 0.0029
Epoch [71/100], Step [681/735], Loss: 0.0143
Epoch [71/100], Step [691/735], Loss: 0.0116
Epoch [71/100], Step [701/735], Loss: 0.0137
Epoch [71/100], Step [711/735], Loss: 0.0002
Epoch [71/100], Step [721/735], Loss: 0.0085
Epoch [71/100], Step [731/735], Loss: 0.0002
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9222,Val AUC: 0.9577,Val precision: 0.8530, Val recall: 0.8745, Val Loss: 0.0688
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 71 | Time taken: 2253.75s |
| Val CE loss: 0.06876 | Val MSE 0.92224 | Train Loss 0.00895 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 72
Training for epoch 72
Epoch [72/100], Step [1/735], Loss: 0.0006
Epoch [72/100], Step [11/735], Loss: 0.0011
Epoch [72/100], Step [21/735], Loss: 0.0172
Epoch [72/100], Step [31/735], Loss: 0.0279
Epoch [72/100], Step [41/735], Loss: 0.0207
Epoch [72/100], Step [51/735], Loss: 0.0096
Epoch [72/100], Step [61/735], Loss: 0.0250
Epoch [72/100], Step [71/735], Loss: 0.0183
Epoch [72/100], Step [81/735], Loss: 0.0121
Epoch [72/100], Step [91/735], Loss: 0.0114
Epoch [72/100], Step [101/735], Loss: 0.0234
Epoch [72/100], Step [111/735], Loss: 0.0064
Epoch [72/100], Step [121/735], Loss: 0.0031
Epoch [72/100], Step [131/735], Loss: 0.0002
Epoch [72/100], Step [141/735], Loss: 0.0062
Epoch [72/100], Step [151/735], Loss: 0.0180
Epoch [72/100], Step [161/735], Loss: 0.0003
Epoch [72/100], Step [171/735], Loss: 0.0035
Epoch [72/100], Step [181/735], Loss: 0.0141
Epoch [72/100], Step [191/735], Loss: 0.0000
Epoch [72/100], Step [201/735], Loss: 0.0002
Epoch [72/100], Step [211/735], Loss: 0.0028
Epoch [72/100], Step [221/735], Loss: 0.0021
Epoch [72/100], Step [231/735], Loss: 0.0104
Epoch [72/100], Step [241/735], Loss: 0.0009
Epoch [72/100], Step [251/735], Loss: 0.0234
Epoch [72/100], Step [261/735], Loss: 0.0086
Epoch [72/100], Step [271/735], Loss: 0.0139
Epoch [72/100], Step [281/735], Loss: 0.0004
Epoch [72/100], Step [291/735], Loss: 0.0037
Epoch [72/100], Step [301/735], Loss: 0.0270
Epoch [72/100], Step [311/735], Loss: 0.0066
Epoch [72/100], Step [321/735], Loss: 0.0029
Epoch [72/100], Step [331/735], Loss: 0.0187
Epoch [72/100], Step [341/735], Loss: 0.0182
Epoch [72/100], Step [351/735], Loss: 0.0000
Epoch [72/100], Step [361/735], Loss: 0.0004
Epoch [72/100], Step [371/735], Loss: 0.0006
Epoch [72/100], Step [381/735], Loss: 0.0135
Epoch [72/100], Step [391/735], Loss: 0.0015
Epoch [72/100], Step [401/735], Loss: 0.0002
Epoch [72/100], Step [411/735], Loss: 0.0088
Epoch [72/100], Step [421/735], Loss: 0.0082
Epoch [72/100], Step [431/735], Loss: 0.0021
Epoch [72/100], Step [441/735], Loss: 0.0002
Epoch [72/100], Step [451/735], Loss: 0.0002
Epoch [72/100], Step [461/735], Loss: 0.0138
Epoch [72/100], Step [471/735], Loss: 0.0003
Epoch [72/100], Step [481/735], Loss: 0.0140
Epoch [72/100], Step [491/735], Loss: 0.0003
Epoch [72/100], Step [501/735], Loss: 0.0078
Epoch [72/100], Step [511/735], Loss: 0.0265
Epoch [72/100], Step [521/735], Loss: 0.0003
Epoch [72/100], Step [531/735], Loss: 0.0001
Epoch [72/100], Step [541/735], Loss: 0.0131
Epoch [72/100], Step [551/735], Loss: 0.0013
Epoch [72/100], Step [561/735], Loss: 0.0265
Epoch [72/100], Step [571/735], Loss: 0.0139
Epoch [72/100], Step [581/735], Loss: 0.0121
Epoch [72/100], Step [591/735], Loss: 0.0140
Epoch [72/100], Step [601/735], Loss: 0.0367
Epoch [72/100], Step [611/735], Loss: 0.0001
Epoch [72/100], Step [621/735], Loss: 0.0212
Epoch [72/100], Step [631/735], Loss: 0.0111
Epoch [72/100], Step [641/735], Loss: 0.0107
Epoch [72/100], Step [651/735], Loss: 0.0006
Epoch [72/100], Step [661/735], Loss: 0.0132
Epoch [72/100], Step [671/735], Loss: 0.0152
Epoch [72/100], Step [681/735], Loss: 0.0165
Epoch [72/100], Step [691/735], Loss: 0.0001
Epoch [72/100], Step [701/735], Loss: 0.0003
Epoch [72/100], Step [711/735], Loss: 0.0105
Epoch [72/100], Step [721/735], Loss: 0.0090
Epoch [72/100], Step [731/735], Loss: 0.0237
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9158,Val AUC: 0.9570,Val precision: 0.8322, Val recall: 0.8782, Val Loss: 0.0722
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 72 | Time taken: 2244.14s |
| Val CE loss: 0.07218 | Val MSE 0.91583 | Train Loss 0.00824 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 73
Training for epoch 73
Epoch [73/100], Step [1/735], Loss: 0.0178
Epoch [73/100], Step [11/735], Loss: 0.0127
Epoch [73/100], Step [21/735], Loss: 0.0003
Epoch [73/100], Step [31/735], Loss: 0.0010
Epoch [73/100], Step [41/735], Loss: 0.0143
Epoch [73/100], Step [51/735], Loss: 0.0069
Epoch [73/100], Step [61/735], Loss: 0.0003
Epoch [73/100], Step [71/735], Loss: 0.0038
Epoch [73/100], Step [81/735], Loss: 0.0003
Epoch [73/100], Step [91/735], Loss: 0.0140
Epoch [73/100], Step [101/735], Loss: 0.0143
Epoch [73/100], Step [111/735], Loss: 0.0117
Epoch [73/100], Step [121/735], Loss: 0.0142
Epoch [73/100], Step [131/735], Loss: 0.0020
Epoch [73/100], Step [141/735], Loss: 0.0000
Epoch [73/100], Step [151/735], Loss: 0.0002
Epoch [73/100], Step [161/735], Loss: 0.0327
Epoch [73/100], Step [171/735], Loss: 0.0001
Epoch [73/100], Step [181/735], Loss: 0.0024
Epoch [73/100], Step [191/735], Loss: 0.0278
Epoch [73/100], Step [201/735], Loss: 0.0011
Epoch [73/100], Step [211/735], Loss: 0.0139
Epoch [73/100], Step [221/735], Loss: 0.0140
Epoch [73/100], Step [231/735], Loss: 0.0003
Epoch [73/100], Step [241/735], Loss: 0.0161
Epoch [73/100], Step [251/735], Loss: 0.0166
Epoch [73/100], Step [261/735], Loss: 0.0143
Epoch [73/100], Step [271/735], Loss: 0.0216
Epoch [73/100], Step [281/735], Loss: 0.0249
Epoch [73/100], Step [291/735], Loss: 0.0140
Epoch [73/100], Step [301/735], Loss: 0.0015
Epoch [73/100], Step [311/735], Loss: 0.0150
Epoch [73/100], Step [321/735], Loss: 0.0002
Epoch [73/100], Step [331/735], Loss: 0.0140
Epoch [73/100], Step [341/735], Loss: 0.0001
Epoch [73/100], Step [351/735], Loss: 0.0001
Epoch [73/100], Step [361/735], Loss: 0.0001
Epoch [73/100], Step [371/735], Loss: 0.0003
Epoch [73/100], Step [381/735], Loss: 0.0074
Epoch [73/100], Step [391/735], Loss: 0.0009
Epoch [73/100], Step [401/735], Loss: 0.0298
Epoch [73/100], Step [411/735], Loss: 0.0337
Epoch [73/100], Step [421/735], Loss: 0.0008
Epoch [73/100], Step [431/735], Loss: 0.0010
Epoch [73/100], Step [441/735], Loss: 0.0086
Epoch [73/100], Step [451/735], Loss: 0.0128
Epoch [73/100], Step [461/735], Loss: 0.0116
Epoch [73/100], Step [471/735], Loss: 0.0130
Epoch [73/100], Step [481/735], Loss: 0.0146
Epoch [73/100], Step [491/735], Loss: 0.0001
Epoch [73/100], Step [501/735], Loss: 0.0381
Epoch [73/100], Step [511/735], Loss: 0.0139
Epoch [73/100], Step [521/735], Loss: 0.0002
Epoch [73/100], Step [531/735], Loss: 0.0260
Epoch [73/100], Step [541/735], Loss: 0.0001
Epoch [73/100], Step [551/735], Loss: 0.0169
Epoch [73/100], Step [561/735], Loss: 0.0126
Epoch [73/100], Step [571/735], Loss: 0.0183
Epoch [73/100], Step [581/735], Loss: 0.0528
Epoch [73/100], Step [591/735], Loss: 0.0176
Epoch [73/100], Step [601/735], Loss: 0.0001
Epoch [73/100], Step [611/735], Loss: 0.0085
Epoch [73/100], Step [621/735], Loss: 0.0002
Epoch [73/100], Step [631/735], Loss: 0.0097
Epoch [73/100], Step [641/735], Loss: 0.0044
Epoch [73/100], Step [651/735], Loss: 0.0273
Epoch [73/100], Step [661/735], Loss: 0.0002
Epoch [73/100], Step [671/735], Loss: 0.0001
Epoch [73/100], Step [681/735], Loss: 0.0230
Epoch [73/100], Step [691/735], Loss: 0.0002
Epoch [73/100], Step [701/735], Loss: 0.0002
Epoch [73/100], Step [711/735], Loss: 0.0144
Epoch [73/100], Step [721/735], Loss: 0.0288
Epoch [73/100], Step [731/735], Loss: 0.0038
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9222,Val AUC: 0.9560,Val precision: 0.8556, Val recall: 0.8708, Val Loss: 0.0677
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 73 | Time taken: 2217.38s |
| Val CE loss: 0.06765 | Val MSE 0.92224 | Train Loss 0.00840 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 74
Training for epoch 74
Epoch [74/100], Step [1/735], Loss: 0.0099
Epoch [74/100], Step [11/735], Loss: 0.0001
Epoch [74/100], Step [21/735], Loss: 0.0006
Epoch [74/100], Step [31/735], Loss: 0.0093
Epoch [74/100], Step [41/735], Loss: 0.0125
Epoch [74/100], Step [51/735], Loss: 0.0006
Epoch [74/100], Step [61/735], Loss: 0.0005
Epoch [74/100], Step [71/735], Loss: 0.0002
Epoch [74/100], Step [81/735], Loss: 0.0002
Epoch [74/100], Step [91/735], Loss: 0.0001
Epoch [74/100], Step [101/735], Loss: 0.0002
Epoch [74/100], Step [111/735], Loss: 0.0124
Epoch [74/100], Step [121/735], Loss: 0.0010
Epoch [74/100], Step [131/735], Loss: 0.0001
Epoch [74/100], Step [141/735], Loss: 0.0003
Epoch [74/100], Step [151/735], Loss: 0.0011
Epoch [74/100], Step [161/735], Loss: 0.0022
Epoch [74/100], Step [171/735], Loss: 0.0143
Epoch [74/100], Step [181/735], Loss: 0.0077
Epoch [74/100], Step [191/735], Loss: 0.0341
Epoch [74/100], Step [201/735], Loss: 0.0169
Epoch [74/100], Step [211/735], Loss: 0.0004
Epoch [74/100], Step [221/735], Loss: 0.0026
Epoch [74/100], Step [231/735], Loss: 0.0004
Epoch [74/100], Step [241/735], Loss: 0.0012
Epoch [74/100], Step [251/735], Loss: 0.0001
Epoch [74/100], Step [261/735], Loss: 0.0001
Epoch [74/100], Step [271/735], Loss: 0.0143
Epoch [74/100], Step [281/735], Loss: 0.0002
Epoch [74/100], Step [291/735], Loss: 0.0099
Epoch [74/100], Step [301/735], Loss: 0.0032
Epoch [74/100], Step [311/735], Loss: 0.0044
Epoch [74/100], Step [321/735], Loss: 0.0002
Epoch [74/100], Step [331/735], Loss: 0.0009
Epoch [74/100], Step [341/735], Loss: 0.0146
Epoch [74/100], Step [351/735], Loss: 0.0230
Epoch [74/100], Step [361/735], Loss: 0.0010
Epoch [74/100], Step [371/735], Loss: 0.0005
Epoch [74/100], Step [381/735], Loss: 0.0014
Epoch [74/100], Step [391/735], Loss: 0.0002
Epoch [74/100], Step [401/735], Loss: 0.0081
Epoch [74/100], Step [411/735], Loss: 0.0021
Epoch [74/100], Step [421/735], Loss: 0.0001
Epoch [74/100], Step [431/735], Loss: 0.0004
Epoch [74/100], Step [441/735], Loss: 0.0102
Epoch [74/100], Step [451/735], Loss: 0.0000
Epoch [74/100], Step [461/735], Loss: 0.0179
Epoch [74/100], Step [471/735], Loss: 0.0250
Epoch [74/100], Step [481/735], Loss: 0.0004
Epoch [74/100], Step [491/735], Loss: 0.0137
Epoch [74/100], Step [501/735], Loss: 0.0141
Epoch [74/100], Step [511/735], Loss: 0.0001
Epoch [74/100], Step [521/735], Loss: 0.0026
Epoch [74/100], Step [531/735], Loss: 0.0010
Epoch [74/100], Step [541/735], Loss: 0.0185
Epoch [74/100], Step [551/735], Loss: 0.0071
Epoch [74/100], Step [561/735], Loss: 0.0244
Epoch [74/100], Step [571/735], Loss: 0.0001
Epoch [74/100], Step [581/735], Loss: 0.0163
Epoch [74/100], Step [591/735], Loss: 0.0001
Epoch [74/100], Step [601/735], Loss: 0.0112
Epoch [74/100], Step [611/735], Loss: 0.0003
Epoch [74/100], Step [621/735], Loss: 0.0108
Epoch [74/100], Step [631/735], Loss: 0.0013
Epoch [74/100], Step [641/735], Loss: 0.0011
Epoch [74/100], Step [651/735], Loss: 0.0001
Epoch [74/100], Step [661/735], Loss: 0.0030
Epoch [74/100], Step [671/735], Loss: 0.0319
Epoch [74/100], Step [681/735], Loss: 0.0032
Epoch [74/100], Step [691/735], Loss: 0.0199
Epoch [74/100], Step [701/735], Loss: 0.0139
Epoch [74/100], Step [711/735], Loss: 0.0006
Epoch [74/100], Step [721/735], Loss: 0.0001
Epoch [74/100], Step [731/735], Loss: 0.0011
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9210,Val AUC: 0.9581,Val precision: 0.8541, Val recall: 0.8678, Val Loss: 0.0692
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 74 | Time taken: 2253.77s |
| Val CE loss: 0.06924 | Val MSE 0.92103 | Train Loss 0.00787 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 75
Training for epoch 75
Epoch [75/100], Step [1/735], Loss: 0.0008
Epoch [75/100], Step [11/735], Loss: 0.0181
Epoch [75/100], Step [21/735], Loss: 0.0005
Epoch [75/100], Step [31/735], Loss: 0.0276
Epoch [75/100], Step [41/735], Loss: 0.0001
Epoch [75/100], Step [51/735], Loss: 0.0145
Epoch [75/100], Step [61/735], Loss: 0.0009
Epoch [75/100], Step [71/735], Loss: 0.0010
Epoch [75/100], Step [81/735], Loss: 0.0077
Epoch [75/100], Step [91/735], Loss: 0.0003
Epoch [75/100], Step [101/735], Loss: 0.0030
Epoch [75/100], Step [111/735], Loss: 0.0001
Epoch [75/100], Step [121/735], Loss: 0.0009
Epoch [75/100], Step [131/735], Loss: 0.0026
Epoch [75/100], Step [141/735], Loss: 0.0077
Epoch [75/100], Step [151/735], Loss: 0.0012
Epoch [75/100], Step [161/735], Loss: 0.0052
Epoch [75/100], Step [171/735], Loss: 0.0038
Epoch [75/100], Step [181/735], Loss: 0.0125
Epoch [75/100], Step [191/735], Loss: 0.0002
Epoch [75/100], Step [201/735], Loss: 0.0143
Epoch [75/100], Step [211/735], Loss: 0.0140
Epoch [75/100], Step [221/735], Loss: 0.0242
Epoch [75/100], Step [231/735], Loss: 0.0005
Epoch [75/100], Step [241/735], Loss: 0.0139
Epoch [75/100], Step [251/735], Loss: 0.0019
Epoch [75/100], Step [261/735], Loss: 0.0130
Epoch [75/100], Step [271/735], Loss: 0.0201
Epoch [75/100], Step [281/735], Loss: 0.0000
Epoch [75/100], Step [291/735], Loss: 0.0008
Epoch [75/100], Step [301/735], Loss: 0.0002
Epoch [75/100], Step [311/735], Loss: 0.0000
Epoch [75/100], Step [321/735], Loss: 0.0005
Epoch [75/100], Step [331/735], Loss: 0.0034
Epoch [75/100], Step [341/735], Loss: 0.0001
Epoch [75/100], Step [351/735], Loss: 0.0142
Epoch [75/100], Step [361/735], Loss: 0.0255
Epoch [75/100], Step [371/735], Loss: 0.0003
Epoch [75/100], Step [381/735], Loss: 0.0274
Epoch [75/100], Step [391/735], Loss: 0.0204
Epoch [75/100], Step [401/735], Loss: 0.0011
Epoch [75/100], Step [411/735], Loss: 0.0004
Epoch [75/100], Step [421/735], Loss: 0.0009
Epoch [75/100], Step [431/735], Loss: 0.0143
Epoch [75/100], Step [441/735], Loss: 0.0014
Epoch [75/100], Step [451/735], Loss: 0.0127
Epoch [75/100], Step [461/735], Loss: 0.0003
Epoch [75/100], Step [471/735], Loss: 0.0014
Epoch [75/100], Step [481/735], Loss: 0.0001
Epoch [75/100], Step [491/735], Loss: 0.0001
Epoch [75/100], Step [501/735], Loss: 0.0012
Epoch [75/100], Step [511/735], Loss: 0.0003
Epoch [75/100], Step [521/735], Loss: 0.0395
Epoch [75/100], Step [531/735], Loss: 0.0000
Epoch [75/100], Step [541/735], Loss: 0.0000
Epoch [75/100], Step [551/735], Loss: 0.0162
Epoch [75/100], Step [561/735], Loss: 0.0048
Epoch [75/100], Step [571/735], Loss: 0.0006
Epoch [75/100], Step [581/735], Loss: 0.0000
Epoch [75/100], Step [591/735], Loss: 0.0087
Epoch [75/100], Step [601/735], Loss: 0.0204
Epoch [75/100], Step [611/735], Loss: 0.0295
Epoch [75/100], Step [621/735], Loss: 0.0001
Epoch [75/100], Step [631/735], Loss: 0.0143
Epoch [75/100], Step [641/735], Loss: 0.0143
Epoch [75/100], Step [651/735], Loss: 0.0140
Epoch [75/100], Step [661/735], Loss: 0.0173
Epoch [75/100], Step [671/735], Loss: 0.0075
Epoch [75/100], Step [681/735], Loss: 0.0001
Epoch [75/100], Step [691/735], Loss: 0.0008
Epoch [75/100], Step [701/735], Loss: 0.0011
Epoch [75/100], Step [711/735], Loss: 0.0137
Epoch [75/100], Step [721/735], Loss: 0.0016
Epoch [75/100], Step [731/735], Loss: 0.0024
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9210,Val AUC: 0.9575,Val precision: 0.8511, Val recall: 0.8721, Val Loss: 0.0683
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 75 | Time taken: 2255.25s |
| Val CE loss: 0.06827 | Val MSE 0.92103 | Train Loss 0.00754 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 76
Training for epoch 76
Epoch [76/100], Step [1/735], Loss: 0.0070
Epoch [76/100], Step [11/735], Loss: 0.0002
Epoch [76/100], Step [21/735], Loss: 0.0003
Epoch [76/100], Step [31/735], Loss: 0.0119
Epoch [76/100], Step [41/735], Loss: 0.0005
Epoch [76/100], Step [51/735], Loss: 0.0050
Epoch [76/100], Step [61/735], Loss: 0.0006
Epoch [76/100], Step [71/735], Loss: 0.0003
Epoch [76/100], Step [81/735], Loss: 0.0208
Epoch [76/100], Step [91/735], Loss: 0.0082
Epoch [76/100], Step [101/735], Loss: 0.0001
Epoch [76/100], Step [111/735], Loss: 0.0004
Epoch [76/100], Step [121/735], Loss: 0.0012
Epoch [76/100], Step [131/735], Loss: 0.0307
Epoch [76/100], Step [141/735], Loss: 0.0059
Epoch [76/100], Step [151/735], Loss: 0.0127
Epoch [76/100], Step [161/735], Loss: 0.0001
Epoch [76/100], Step [171/735], Loss: 0.0018
Epoch [76/100], Step [181/735], Loss: 0.0037
Epoch [76/100], Step [191/735], Loss: 0.0001
Epoch [76/100], Step [201/735], Loss: 0.0142
Epoch [76/100], Step [211/735], Loss: 0.0001
Epoch [76/100], Step [221/735], Loss: 0.0002
Epoch [76/100], Step [231/735], Loss: 0.0073
Epoch [76/100], Step [241/735], Loss: 0.0006
Epoch [76/100], Step [251/735], Loss: 0.0273
Epoch [76/100], Step [261/735], Loss: 0.0166
Epoch [76/100], Step [271/735], Loss: 0.0077
Epoch [76/100], Step [281/735], Loss: 0.0283
Epoch [76/100], Step [291/735], Loss: 0.0001
Epoch [76/100], Step [301/735], Loss: 0.0048
Epoch [76/100], Step [311/735], Loss: 0.0274
Epoch [76/100], Step [321/735], Loss: 0.0003
Epoch [76/100], Step [331/735], Loss: 0.0018
Epoch [76/100], Step [341/735], Loss: 0.0163
Epoch [76/100], Step [351/735], Loss: 0.0277
Epoch [76/100], Step [361/735], Loss: 0.0002
Epoch [76/100], Step [371/735], Loss: 0.0042
Epoch [76/100], Step [381/735], Loss: 0.0080
Epoch [76/100], Step [391/735], Loss: 0.0087
Epoch [76/100], Step [401/735], Loss: 0.0010
Epoch [76/100], Step [411/735], Loss: 0.0124
Epoch [76/100], Step [421/735], Loss: 0.0001
Epoch [76/100], Step [431/735], Loss: 0.0386
Epoch [76/100], Step [441/735], Loss: 0.0005
Epoch [76/100], Step [451/735], Loss: 0.0124
Epoch [76/100], Step [461/735], Loss: 0.0002
Epoch [76/100], Step [471/735], Loss: 0.0001
Epoch [76/100], Step [481/735], Loss: 0.0139
Epoch [76/100], Step [491/735], Loss: 0.0001
Epoch [76/100], Step [501/735], Loss: 0.0001
Epoch [76/100], Step [511/735], Loss: 0.0009
Epoch [76/100], Step [521/735], Loss: 0.0006
Epoch [76/100], Step [531/735], Loss: 0.0034
Epoch [76/100], Step [541/735], Loss: 0.0107
Epoch [76/100], Step [551/735], Loss: 0.0005
Epoch [76/100], Step [561/735], Loss: 0.0281
Epoch [76/100], Step [571/735], Loss: 0.0083
Epoch [76/100], Step [581/735], Loss: 0.0010
Epoch [76/100], Step [591/735], Loss: 0.0059
Epoch [76/100], Step [601/735], Loss: 0.0199
Epoch [76/100], Step [611/735], Loss: 0.0239
Epoch [76/100], Step [621/735], Loss: 0.0186
Epoch [76/100], Step [631/735], Loss: 0.0052
Epoch [76/100], Step [641/735], Loss: 0.0275
Epoch [76/100], Step [651/735], Loss: 0.0006
Epoch [76/100], Step [661/735], Loss: 0.0132
Epoch [76/100], Step [671/735], Loss: 0.0245
Epoch [76/100], Step [681/735], Loss: 0.0001
Epoch [76/100], Step [691/735], Loss: 0.0138
Epoch [76/100], Step [701/735], Loss: 0.0135
Epoch [76/100], Step [711/735], Loss: 0.0001
Epoch [76/100], Step [721/735], Loss: 0.0144
Epoch [76/100], Step [731/735], Loss: 0.0002
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9202,Val AUC: 0.9561,Val precision: 0.8541, Val recall: 0.8641, Val Loss: 0.0703
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 76 | Time taken: 2244.92s |
| Val CE loss: 0.07031 | Val MSE 0.92016 | Train Loss 0.00794 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 77
Training for epoch 77
Epoch [77/100], Step [1/735], Loss: 0.0141
Epoch [77/100], Step [11/735], Loss: 0.0000
Epoch [77/100], Step [21/735], Loss: 0.0113
Epoch [77/100], Step [31/735], Loss: 0.0001
Epoch [77/100], Step [41/735], Loss: 0.0001
Epoch [77/100], Step [51/735], Loss: 0.0001
Epoch [77/100], Step [61/735], Loss: 0.0288
Epoch [77/100], Step [71/735], Loss: 0.0088
Epoch [77/100], Step [81/735], Loss: 0.0021
Epoch [77/100], Step [91/735], Loss: 0.0066
Epoch [77/100], Step [101/735], Loss: 0.0001
Epoch [77/100], Step [111/735], Loss: 0.0142
Epoch [77/100], Step [121/735], Loss: 0.0234
Epoch [77/100], Step [131/735], Loss: 0.0103
Epoch [77/100], Step [141/735], Loss: 0.0077
Epoch [77/100], Step [151/735], Loss: 0.0004
Epoch [77/100], Step [161/735], Loss: 0.0136
Epoch [77/100], Step [171/735], Loss: 0.0001
Epoch [77/100], Step [181/735], Loss: 0.0263
Epoch [77/100], Step [191/735], Loss: 0.0004
Epoch [77/100], Step [201/735], Loss: 0.0002
Epoch [77/100], Step [211/735], Loss: 0.0056
Epoch [77/100], Step [221/735], Loss: 0.0484
Epoch [77/100], Step [231/735], Loss: 0.0091
Epoch [77/100], Step [241/735], Loss: 0.0007
Epoch [77/100], Step [251/735], Loss: 0.0149
Epoch [77/100], Step [261/735], Loss: 0.0107
Epoch [77/100], Step [271/735], Loss: 0.0008
Epoch [77/100], Step [281/735], Loss: 0.0006
Epoch [77/100], Step [291/735], Loss: 0.0244
Epoch [77/100], Step [301/735], Loss: 0.0001
Epoch [77/100], Step [311/735], Loss: 0.0232
Epoch [77/100], Step [321/735], Loss: 0.0002
Epoch [77/100], Step [331/735], Loss: 0.0017
Epoch [77/100], Step [341/735], Loss: 0.0034
Epoch [77/100], Step [351/735], Loss: 0.0002
Epoch [77/100], Step [361/735], Loss: 0.0001
Epoch [77/100], Step [371/735], Loss: 0.0001
Epoch [77/100], Step [381/735], Loss: 0.0249
Epoch [77/100], Step [391/735], Loss: 0.0066
Epoch [77/100], Step [401/735], Loss: 0.0141
Epoch [77/100], Step [411/735], Loss: 0.0003
Epoch [77/100], Step [421/735], Loss: 0.0039
Epoch [77/100], Step [431/735], Loss: 0.0069
Epoch [77/100], Step [441/735], Loss: 0.0127
Epoch [77/100], Step [451/735], Loss: 0.0022
Epoch [77/100], Step [461/735], Loss: 0.0150
Epoch [77/100], Step [471/735], Loss: 0.0035
Epoch [77/100], Step [481/735], Loss: 0.0000
Epoch [77/100], Step [491/735], Loss: 0.0001
Epoch [77/100], Step [501/735], Loss: 0.0110
Epoch [77/100], Step [511/735], Loss: 0.0147
Epoch [77/100], Step [521/735], Loss: 0.0012
Epoch [77/100], Step [531/735], Loss: 0.0006
Epoch [77/100], Step [541/735], Loss: 0.0037
Epoch [77/100], Step [551/735], Loss: 0.0014
Epoch [77/100], Step [561/735], Loss: 0.0037
Epoch [77/100], Step [571/735], Loss: 0.0010
Epoch [77/100], Step [581/735], Loss: 0.0001
Epoch [77/100], Step [591/735], Loss: 0.0277
Epoch [77/100], Step [601/735], Loss: 0.0140
Epoch [77/100], Step [611/735], Loss: 0.0114
Epoch [77/100], Step [621/735], Loss: 0.0134
Epoch [77/100], Step [631/735], Loss: 0.0083
Epoch [77/100], Step [641/735], Loss: 0.0097
Epoch [77/100], Step [651/735], Loss: 0.0078
Epoch [77/100], Step [661/735], Loss: 0.0001
Epoch [77/100], Step [671/735], Loss: 0.0177
Epoch [77/100], Step [681/735], Loss: 0.0156
Epoch [77/100], Step [691/735], Loss: 0.0054
Epoch [77/100], Step [701/735], Loss: 0.0005
Epoch [77/100], Step [711/735], Loss: 0.0037
Epoch [77/100], Step [721/735], Loss: 0.0136
Epoch [77/100], Step [731/735], Loss: 0.0001
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9212,Val AUC: 0.9570,Val precision: 0.8568, Val recall: 0.8647, Val Loss: 0.0688
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 77 | Time taken: 2257.92s |
| Val CE loss: 0.06876 | Val MSE 0.92120 | Train Loss 0.00829 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 78
Training for epoch 78
Epoch [78/100], Step [1/735], Loss: 0.0158
Epoch [78/100], Step [11/735], Loss: 0.0234
Epoch [78/100], Step [21/735], Loss: 0.0332
Epoch [78/100], Step [31/735], Loss: 0.0154
Epoch [78/100], Step [41/735], Loss: 0.0112
Epoch [78/100], Step [51/735], Loss: 0.0000
Epoch [78/100], Step [61/735], Loss: 0.0123
Epoch [78/100], Step [71/735], Loss: 0.0145
Epoch [78/100], Step [81/735], Loss: 0.0012
Epoch [78/100], Step [91/735], Loss: 0.0102
Epoch [78/100], Step [101/735], Loss: 0.0139
Epoch [78/100], Step [111/735], Loss: 0.0240
Epoch [78/100], Step [121/735], Loss: 0.0043
Epoch [78/100], Step [131/735], Loss: 0.0141
Epoch [78/100], Step [141/735], Loss: 0.0278
Epoch [78/100], Step [151/735], Loss: 0.0070
Epoch [78/100], Step [161/735], Loss: 0.0033
Epoch [78/100], Step [171/735], Loss: 0.0209
Epoch [78/100], Step [181/735], Loss: 0.0045
Epoch [78/100], Step [191/735], Loss: 0.0011
Epoch [78/100], Step [201/735], Loss: 0.0144
Epoch [78/100], Step [211/735], Loss: 0.0206
Epoch [78/100], Step [221/735], Loss: 0.0029
Epoch [78/100], Step [231/735], Loss: 0.0027
Epoch [78/100], Step [241/735], Loss: 0.0056
Epoch [78/100], Step [251/735], Loss: 0.0005
Epoch [78/100], Step [261/735], Loss: 0.0009
Epoch [78/100], Step [271/735], Loss: 0.0002
Epoch [78/100], Step [281/735], Loss: 0.0001
Epoch [78/100], Step [291/735], Loss: 0.0428
Epoch [78/100], Step [301/735], Loss: 0.0078
Epoch [78/100], Step [311/735], Loss: 0.0002
Epoch [78/100], Step [321/735], Loss: 0.0092
Epoch [78/100], Step [331/735], Loss: 0.0176
Epoch [78/100], Step [341/735], Loss: 0.0003
Epoch [78/100], Step [351/735], Loss: 0.0155
Epoch [78/100], Step [361/735], Loss: 0.0077
Epoch [78/100], Step [371/735], Loss: 0.0000
Epoch [78/100], Step [381/735], Loss: 0.0178
Epoch [78/100], Step [391/735], Loss: 0.0157
Epoch [78/100], Step [401/735], Loss: 0.0009
Epoch [78/100], Step [411/735], Loss: 0.0136
Epoch [78/100], Step [421/735], Loss: 0.0142
Epoch [78/100], Step [431/735], Loss: 0.0132
Epoch [78/100], Step [441/735], Loss: 0.0010
Epoch [78/100], Step [451/735], Loss: 0.0036
Epoch [78/100], Step [461/735], Loss: 0.0071
Epoch [78/100], Step [471/735], Loss: 0.0230
Epoch [78/100], Step [481/735], Loss: 0.0126
Epoch [78/100], Step [491/735], Loss: 0.0143
Epoch [78/100], Step [501/735], Loss: 0.0036
Epoch [78/100], Step [511/735], Loss: 0.0139
Epoch [78/100], Step [521/735], Loss: 0.0068
Epoch [78/100], Step [531/735], Loss: 0.0126
Epoch [78/100], Step [541/735], Loss: 0.0129
Epoch [78/100], Step [551/735], Loss: 0.0001
Epoch [78/100], Step [561/735], Loss: 0.0006
Epoch [78/100], Step [571/735], Loss: 0.0102
Epoch [78/100], Step [581/735], Loss: 0.0223
Epoch [78/100], Step [591/735], Loss: 0.0143
Epoch [78/100], Step [601/735], Loss: 0.0038
Epoch [78/100], Step [611/735], Loss: 0.0050
Epoch [78/100], Step [621/735], Loss: 0.0460
Epoch [78/100], Step [631/735], Loss: 0.0004
Epoch [78/100], Step [641/735], Loss: 0.0131
Epoch [78/100], Step [651/735], Loss: 0.0139
Epoch [78/100], Step [661/735], Loss: 0.0167
Epoch [78/100], Step [671/735], Loss: 0.0286
Epoch [78/100], Step [681/735], Loss: 0.0001
Epoch [78/100], Step [691/735], Loss: 0.0003
Epoch [78/100], Step [701/735], Loss: 0.0139
Epoch [78/100], Step [711/735], Loss: 0.0142
Epoch [78/100], Step [721/735], Loss: 0.0002
Epoch [78/100], Step [731/735], Loss: 0.0129
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9210,Val AUC: 0.9538,Val precision: 0.8511, Val recall: 0.8721, Val Loss: 0.0700
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 78 | Time taken: 2254.29s |
| Val CE loss: 0.06996 | Val MSE 0.92103 | Train Loss 0.00857 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 79
Training for epoch 79
Epoch [79/100], Step [1/735], Loss: 0.0207
Epoch [79/100], Step [11/735], Loss: 0.0040
Epoch [79/100], Step [21/735], Loss: 0.0023
Epoch [79/100], Step [31/735], Loss: 0.0012
Epoch [79/100], Step [41/735], Loss: 0.0051
Epoch [79/100], Step [51/735], Loss: 0.0237
Epoch [79/100], Step [61/735], Loss: 0.0033
Epoch [79/100], Step [71/735], Loss: 0.0019
Epoch [79/100], Step [81/735], Loss: 0.0041
Epoch [79/100], Step [91/735], Loss: 0.0138
Epoch [79/100], Step [101/735], Loss: 0.0003
Epoch [79/100], Step [111/735], Loss: 0.0001
Epoch [79/100], Step [121/735], Loss: 0.0069
Epoch [79/100], Step [131/735], Loss: 0.0109
Epoch [79/100], Step [141/735], Loss: 0.0001
Epoch [79/100], Step [151/735], Loss: 0.0226
Epoch [79/100], Step [161/735], Loss: 0.0136
Epoch [79/100], Step [171/735], Loss: 0.0064
Epoch [79/100], Step [181/735], Loss: 0.0004
Epoch [79/100], Step [191/735], Loss: 0.0006
Epoch [79/100], Step [201/735], Loss: 0.0085
Epoch [79/100], Step [211/735], Loss: 0.0009
Epoch [79/100], Step [221/735], Loss: 0.0001
Epoch [79/100], Step [231/735], Loss: 0.0001
Epoch [79/100], Step [241/735], Loss: 0.0000
Epoch [79/100], Step [251/735], Loss: 0.0066
Epoch [79/100], Step [261/735], Loss: 0.0002
Epoch [79/100], Step [271/735], Loss: 0.0060
Epoch [79/100], Step [281/735], Loss: 0.0075
Epoch [79/100], Step [291/735], Loss: 0.0027
Epoch [79/100], Step [301/735], Loss: 0.0004
Epoch [79/100], Step [311/735], Loss: 0.0003
Epoch [79/100], Step [321/735], Loss: 0.0001
Epoch [79/100], Step [331/735], Loss: 0.0270
Epoch [79/100], Step [341/735], Loss: 0.0138
Epoch [79/100], Step [351/735], Loss: 0.0085
Epoch [79/100], Step [361/735], Loss: 0.0079
Epoch [79/100], Step [371/735], Loss: 0.0139
Epoch [79/100], Step [381/735], Loss: 0.0002
Epoch [79/100], Step [391/735], Loss: 0.0008
Epoch [79/100], Step [401/735], Loss: 0.0017
Epoch [79/100], Step [411/735], Loss: 0.0134
Epoch [79/100], Step [421/735], Loss: 0.0087
Epoch [79/100], Step [431/735], Loss: 0.0016
Epoch [79/100], Step [441/735], Loss: 0.0000
Epoch [79/100], Step [451/735], Loss: 0.0017
Epoch [79/100], Step [461/735], Loss: 0.0130
Epoch [79/100], Step [471/735], Loss: 0.0058
Epoch [79/100], Step [481/735], Loss: 0.0134
Epoch [79/100], Step [491/735], Loss: 0.0080
Epoch [79/100], Step [501/735], Loss: 0.0003
Epoch [79/100], Step [511/735], Loss: 0.0001
Epoch [79/100], Step [521/735], Loss: 0.0001
Epoch [79/100], Step [531/735], Loss: 0.0006
Epoch [79/100], Step [541/735], Loss: 0.0139
Epoch [79/100], Step [551/735], Loss: 0.0130
Epoch [79/100], Step [561/735], Loss: 0.0114
Epoch [79/100], Step [571/735], Loss: 0.0139
Epoch [79/100], Step [581/735], Loss: 0.0049
Epoch [79/100], Step [591/735], Loss: 0.0035
Epoch [79/100], Step [601/735], Loss: 0.0019
Epoch [79/100], Step [611/735], Loss: 0.0031
Epoch [79/100], Step [621/735], Loss: 0.0275
Epoch [79/100], Step [631/735], Loss: 0.0279
Epoch [79/100], Step [641/735], Loss: 0.0207
Epoch [79/100], Step [651/735], Loss: 0.0016
Epoch [79/100], Step [661/735], Loss: 0.0119
Epoch [79/100], Step [671/735], Loss: 0.0211
Epoch [79/100], Step [681/735], Loss: 0.0008
Epoch [79/100], Step [691/735], Loss: 0.0001
Epoch [79/100], Step [701/735], Loss: 0.0004
Epoch [79/100], Step [711/735], Loss: 0.0001
Epoch [79/100], Step [721/735], Loss: 0.0003
Epoch [79/100], Step [731/735], Loss: 0.0026
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9174,Val AUC: 0.9588,Val precision: 0.8397, Val recall: 0.8733, Val Loss: 0.0714
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 79 | Time taken: 2246.47s |
| Val CE loss: 0.07137 | Val MSE 0.91739 | Train Loss 0.00763 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 80
Training for epoch 80
Epoch [80/100], Step [1/735], Loss: 0.0077
Epoch [80/100], Step [11/735], Loss: 0.0139
Epoch [80/100], Step [21/735], Loss: 0.0057
Epoch [80/100], Step [31/735], Loss: 0.0118
Epoch [80/100], Step [41/735], Loss: 0.0139
Epoch [80/100], Step [51/735], Loss: 0.0151
Epoch [80/100], Step [61/735], Loss: 0.0044
Epoch [80/100], Step [71/735], Loss: 0.0001
Epoch [80/100], Step [81/735], Loss: 0.0134
Epoch [80/100], Step [91/735], Loss: 0.0139
Epoch [80/100], Step [101/735], Loss: 0.0007
Epoch [80/100], Step [111/735], Loss: 0.0012
Epoch [80/100], Step [121/735], Loss: 0.0002
Epoch [80/100], Step [131/735], Loss: 0.0148
Epoch [80/100], Step [141/735], Loss: 0.0139
Epoch [80/100], Step [151/735], Loss: 0.0017
Epoch [80/100], Step [161/735], Loss: 0.0134
Epoch [80/100], Step [171/735], Loss: 0.0142
Epoch [80/100], Step [181/735], Loss: 0.0140
Epoch [80/100], Step [191/735], Loss: 0.0280
Epoch [80/100], Step [201/735], Loss: 0.0129
Epoch [80/100], Step [211/735], Loss: 0.0164
Epoch [80/100], Step [221/735], Loss: 0.0001
Epoch [80/100], Step [231/735], Loss: 0.0192
Epoch [80/100], Step [241/735], Loss: 0.0001
Epoch [80/100], Step [251/735], Loss: 0.0048
Epoch [80/100], Step [261/735], Loss: 0.0212
Epoch [80/100], Step [271/735], Loss: 0.0001
Epoch [80/100], Step [281/735], Loss: 0.0031
Epoch [80/100], Step [291/735], Loss: 0.0007
Epoch [80/100], Step [301/735], Loss: 0.0004
Epoch [80/100], Step [311/735], Loss: 0.0129
Epoch [80/100], Step [321/735], Loss: 0.0003
Epoch [80/100], Step [331/735], Loss: 0.0003
Epoch [80/100], Step [341/735], Loss: 0.0001
Epoch [80/100], Step [351/735], Loss: 0.0011
Epoch [80/100], Step [361/735], Loss: 0.0003
Epoch [80/100], Step [371/735], Loss: 0.0001
Epoch [80/100], Step [381/735], Loss: 0.0002
Epoch [80/100], Step [391/735], Loss: 0.0001
Epoch [80/100], Step [401/735], Loss: 0.0140
Epoch [80/100], Step [411/735], Loss: 0.0000
Epoch [80/100], Step [421/735], Loss: 0.0139
Epoch [80/100], Step [431/735], Loss: 0.0059
Epoch [80/100], Step [441/735], Loss: 0.0000
Epoch [80/100], Step [451/735], Loss: 0.0003
Epoch [80/100], Step [461/735], Loss: 0.0003
Epoch [80/100], Step [471/735], Loss: 0.0127
Epoch [80/100], Step [481/735], Loss: 0.0043
Epoch [80/100], Step [491/735], Loss: 0.0040
Epoch [80/100], Step [501/735], Loss: 0.0003
Epoch [80/100], Step [511/735], Loss: 0.0001
Epoch [80/100], Step [521/735], Loss: 0.0135
Epoch [80/100], Step [531/735], Loss: 0.0040
Epoch [80/100], Step [541/735], Loss: 0.0007
Epoch [80/100], Step [551/735], Loss: 0.0141
Epoch [80/100], Step [561/735], Loss: 0.0230
Epoch [80/100], Step [571/735], Loss: 0.0143
Epoch [80/100], Step [581/735], Loss: 0.0405
Epoch [80/100], Step [591/735], Loss: 0.0006
Epoch [80/100], Step [601/735], Loss: 0.0001
Epoch [80/100], Step [611/735], Loss: 0.0002
Epoch [80/100], Step [621/735], Loss: 0.0133
Epoch [80/100], Step [631/735], Loss: 0.0002
Epoch [80/100], Step [641/735], Loss: 0.0277
Epoch [80/100], Step [651/735], Loss: 0.0005
Epoch [80/100], Step [661/735], Loss: 0.0143
Epoch [80/100], Step [671/735], Loss: 0.0132
Epoch [80/100], Step [681/735], Loss: 0.0002
Epoch [80/100], Step [691/735], Loss: 0.0001
Epoch [80/100], Step [701/735], Loss: 0.0391
Epoch [80/100], Step [711/735], Loss: 0.0003
Epoch [80/100], Step [721/735], Loss: 0.0005
Epoch [80/100], Step [731/735], Loss: 0.0204
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9184,Val AUC: 0.9589,Val precision: 0.8336, Val recall: 0.8875, Val Loss: 0.0716
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 80 | Time taken: 2230.95s |
| Val CE loss: 0.07158 | Val MSE 0.91843 | Train Loss 0.00727 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 81
Training for epoch 81
Epoch [81/100], Step [1/735], Loss: 0.0000
Epoch [81/100], Step [11/735], Loss: 0.0057
Epoch [81/100], Step [21/735], Loss: 0.0005
Epoch [81/100], Step [31/735], Loss: 0.0286
Epoch [81/100], Step [41/735], Loss: 0.0373
Epoch [81/100], Step [51/735], Loss: 0.0011
Epoch [81/100], Step [61/735], Loss: 0.0146
Epoch [81/100], Step [71/735], Loss: 0.0009
Epoch [81/100], Step [81/735], Loss: 0.0114
Epoch [81/100], Step [91/735], Loss: 0.0000
Epoch [81/100], Step [101/735], Loss: 0.0007
Epoch [81/100], Step [111/735], Loss: 0.0002
Epoch [81/100], Step [121/735], Loss: 0.0080
Epoch [81/100], Step [131/735], Loss: 0.0250
Epoch [81/100], Step [141/735], Loss: 0.0139
Epoch [81/100], Step [151/735], Loss: 0.0022
Epoch [81/100], Step [161/735], Loss: 0.0150
Epoch [81/100], Step [171/735], Loss: 0.0316
Epoch [81/100], Step [181/735], Loss: 0.0002
Epoch [81/100], Step [191/735], Loss: 0.0208
Epoch [81/100], Step [201/735], Loss: 0.0002
Epoch [81/100], Step [211/735], Loss: 0.0122
Epoch [81/100], Step [221/735], Loss: 0.0001
Epoch [81/100], Step [231/735], Loss: 0.0002
Epoch [81/100], Step [241/735], Loss: 0.0024
Epoch [81/100], Step [251/735], Loss: 0.0126
Epoch [81/100], Step [261/735], Loss: 0.0001
Epoch [81/100], Step [271/735], Loss: 0.0045
Epoch [81/100], Step [281/735], Loss: 0.0026
Epoch [81/100], Step [291/735], Loss: 0.0042
Epoch [81/100], Step [301/735], Loss: 0.0146
Epoch [81/100], Step [311/735], Loss: 0.0252
Epoch [81/100], Step [321/735], Loss: 0.0112
Epoch [81/100], Step [331/735], Loss: 0.0002
Epoch [81/100], Step [341/735], Loss: 0.0001
Epoch [81/100], Step [351/735], Loss: 0.0003
Epoch [81/100], Step [361/735], Loss: 0.0259
Epoch [81/100], Step [371/735], Loss: 0.0001
Epoch [81/100], Step [381/735], Loss: 0.0139
Epoch [81/100], Step [391/735], Loss: 0.0001
Epoch [81/100], Step [401/735], Loss: 0.0023
Epoch [81/100], Step [411/735], Loss: 0.0004
Epoch [81/100], Step [421/735], Loss: 0.0001
Epoch [81/100], Step [431/735], Loss: 0.0091
Epoch [81/100], Step [441/735], Loss: 0.0159
Epoch [81/100], Step [451/735], Loss: 0.0030
Epoch [81/100], Step [461/735], Loss: 0.0105
Epoch [81/100], Step [471/735], Loss: 0.0001
Epoch [81/100], Step [481/735], Loss: 0.0147
Epoch [81/100], Step [491/735], Loss: 0.0002
Epoch [81/100], Step [501/735], Loss: 0.0069
Epoch [81/100], Step [511/735], Loss: 0.0000
Epoch [81/100], Step [521/735], Loss: 0.0042
Epoch [81/100], Step [531/735], Loss: 0.0005
Epoch [81/100], Step [541/735], Loss: 0.0185
Epoch [81/100], Step [551/735], Loss: 0.0039
Epoch [81/100], Step [561/735], Loss: 0.0085
Epoch [81/100], Step [571/735], Loss: 0.0304
Epoch [81/100], Step [581/735], Loss: 0.0086
Epoch [81/100], Step [591/735], Loss: 0.0001
Epoch [81/100], Step [601/735], Loss: 0.0002
Epoch [81/100], Step [611/735], Loss: 0.0141
Epoch [81/100], Step [621/735], Loss: 0.0003
Epoch [81/100], Step [631/735], Loss: 0.0187
Epoch [81/100], Step [641/735], Loss: 0.0127
Epoch [81/100], Step [651/735], Loss: 0.0137
Epoch [81/100], Step [661/735], Loss: 0.0086
Epoch [81/100], Step [671/735], Loss: 0.0017
Epoch [81/100], Step [681/735], Loss: 0.0048
Epoch [81/100], Step [691/735], Loss: 0.0001
Epoch [81/100], Step [701/735], Loss: 0.0129
Epoch [81/100], Step [711/735], Loss: 0.0001
Epoch [81/100], Step [721/735], Loss: 0.0003
Epoch [81/100], Step [731/735], Loss: 0.0139
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9195,Val AUC: 0.9561,Val precision: 0.8482, Val recall: 0.8696, Val Loss: 0.0691
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 81 | Time taken: 2237.44s |
| Val CE loss: 0.06907 | Val MSE 0.91947 | Train Loss 0.00834 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 82
Training for epoch 82
Epoch [82/100], Step [1/735], Loss: 0.0191
Epoch [82/100], Step [11/735], Loss: 0.0000
Epoch [82/100], Step [21/735], Loss: 0.0005
Epoch [82/100], Step [31/735], Loss: 0.0057
Epoch [82/100], Step [41/735], Loss: 0.0002
Epoch [82/100], Step [51/735], Loss: 0.0140
Epoch [82/100], Step [61/735], Loss: 0.0034
Epoch [82/100], Step [71/735], Loss: 0.0000
Epoch [82/100], Step [81/735], Loss: 0.0139
Epoch [82/100], Step [91/735], Loss: 0.0151
Epoch [82/100], Step [101/735], Loss: 0.0006
Epoch [82/100], Step [111/735], Loss: 0.0535
Epoch [82/100], Step [121/735], Loss: 0.0010
Epoch [82/100], Step [131/735], Loss: 0.0005
Epoch [82/100], Step [141/735], Loss: 0.0003
Epoch [82/100], Step [151/735], Loss: 0.0038
Epoch [82/100], Step [161/735], Loss: 0.0003
Epoch [82/100], Step [171/735], Loss: 0.0000
Epoch [82/100], Step [181/735], Loss: 0.0138
Epoch [82/100], Step [191/735], Loss: 0.0142
Epoch [82/100], Step [201/735], Loss: 0.0001
Epoch [82/100], Step [211/735], Loss: 0.0171
Epoch [82/100], Step [221/735], Loss: 0.0083
Epoch [82/100], Step [231/735], Loss: 0.0105
Epoch [82/100], Step [241/735], Loss: 0.0002
Epoch [82/100], Step [251/735], Loss: 0.0016
Epoch [82/100], Step [261/735], Loss: 0.0044
Epoch [82/100], Step [271/735], Loss: 0.0156
Epoch [82/100], Step [281/735], Loss: 0.0005
Epoch [82/100], Step [291/735], Loss: 0.0314
Epoch [82/100], Step [301/735], Loss: 0.0232
Epoch [82/100], Step [311/735], Loss: 0.0023
Epoch [82/100], Step [321/735], Loss: 0.0181
Epoch [82/100], Step [331/735], Loss: 0.0015
Epoch [82/100], Step [341/735], Loss: 0.0048
Epoch [82/100], Step [351/735], Loss: 0.0077
Epoch [82/100], Step [361/735], Loss: 0.0005
Epoch [82/100], Step [371/735], Loss: 0.0137
Epoch [82/100], Step [381/735], Loss: 0.0009
Epoch [82/100], Step [391/735], Loss: 0.0003
Epoch [82/100], Step [401/735], Loss: 0.0113
Epoch [82/100], Step [411/735], Loss: 0.0004
Epoch [82/100], Step [421/735], Loss: 0.0002
Epoch [82/100], Step [431/735], Loss: 0.0051
Epoch [82/100], Step [441/735], Loss: 0.0287
Epoch [82/100], Step [451/735], Loss: 0.0109
Epoch [82/100], Step [461/735], Loss: 0.0143
Epoch [82/100], Step [471/735], Loss: 0.0003
Epoch [82/100], Step [481/735], Loss: 0.0140
Epoch [82/100], Step [491/735], Loss: 0.0001
Epoch [82/100], Step [501/735], Loss: 0.0307
Epoch [82/100], Step [511/735], Loss: 0.0213
Epoch [82/100], Step [521/735], Loss: 0.0006
Epoch [82/100], Step [531/735], Loss: 0.0001
Epoch [82/100], Step [541/735], Loss: 0.0016
Epoch [82/100], Step [551/735], Loss: 0.0157
Epoch [82/100], Step [561/735], Loss: 0.0144
Epoch [82/100], Step [571/735], Loss: 0.0003
Epoch [82/100], Step [581/735], Loss: 0.0139
Epoch [82/100], Step [591/735], Loss: 0.0127
Epoch [82/100], Step [601/735], Loss: 0.0038
Epoch [82/100], Step [611/735], Loss: 0.0148
Epoch [82/100], Step [621/735], Loss: 0.0003
Epoch [82/100], Step [631/735], Loss: 0.0010
Epoch [82/100], Step [641/735], Loss: 0.0005
Epoch [82/100], Step [651/735], Loss: 0.0172
Epoch [82/100], Step [661/735], Loss: 0.0004
Epoch [82/100], Step [671/735], Loss: 0.0031
Epoch [82/100], Step [681/735], Loss: 0.0001
Epoch [82/100], Step [691/735], Loss: 0.0125
Epoch [82/100], Step [701/735], Loss: 0.0099
Epoch [82/100], Step [711/735], Loss: 0.0005
Epoch [82/100], Step [721/735], Loss: 0.0016
Epoch [82/100], Step [731/735], Loss: 0.0243
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9162,Val AUC: 0.9548,Val precision: 0.8503, Val recall: 0.8524, Val Loss: 0.0710
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 82 | Time taken: 2263.22s |
| Val CE loss: 0.07100 | Val MSE 0.91618 | Train Loss 0.00813 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 83
Training for epoch 83
Epoch [83/100], Step [1/735], Loss: 0.0254
Epoch [83/100], Step [11/735], Loss: 0.0016
Epoch [83/100], Step [21/735], Loss: 0.0001
Epoch [83/100], Step [31/735], Loss: 0.0013
Epoch [83/100], Step [41/735], Loss: 0.0018
Epoch [83/100], Step [51/735], Loss: 0.0040
Epoch [83/100], Step [61/735], Loss: 0.0212
Epoch [83/100], Step [71/735], Loss: 0.0003
Epoch [83/100], Step [81/735], Loss: 0.0001
Epoch [83/100], Step [91/735], Loss: 0.0024
Epoch [83/100], Step [101/735], Loss: 0.0023
Epoch [83/100], Step [111/735], Loss: 0.0001
Epoch [83/100], Step [121/735], Loss: 0.0002
Epoch [83/100], Step [131/735], Loss: 0.0007
Epoch [83/100], Step [141/735], Loss: 0.0129
Epoch [83/100], Step [151/735], Loss: 0.0258
Epoch [83/100], Step [161/735], Loss: 0.0125
Epoch [83/100], Step [171/735], Loss: 0.0059
Epoch [83/100], Step [181/735], Loss: 0.0194
Epoch [83/100], Step [191/735], Loss: 0.0026
Epoch [83/100], Step [201/735], Loss: 0.0000
Epoch [83/100], Step [211/735], Loss: 0.0135
Epoch [83/100], Step [221/735], Loss: 0.0179
Epoch [83/100], Step [231/735], Loss: 0.0001
Epoch [83/100], Step [241/735], Loss: 0.0000
Epoch [83/100], Step [251/735], Loss: 0.0138
Epoch [83/100], Step [261/735], Loss: 0.0383
Epoch [83/100], Step [271/735], Loss: 0.0003
Epoch [83/100], Step [281/735], Loss: 0.0049
Epoch [83/100], Step [291/735], Loss: 0.0005
Epoch [83/100], Step [301/735], Loss: 0.0207
Epoch [83/100], Step [311/735], Loss: 0.0148
Epoch [83/100], Step [321/735], Loss: 0.0001
Epoch [83/100], Step [331/735], Loss: 0.0034
Epoch [83/100], Step [341/735], Loss: 0.0018
Epoch [83/100], Step [351/735], Loss: 0.0002
Epoch [83/100], Step [361/735], Loss: 0.0001
Epoch [83/100], Step [371/735], Loss: 0.0147
Epoch [83/100], Step [381/735], Loss: 0.0001
Epoch [83/100], Step [391/735], Loss: 0.0145
Epoch [83/100], Step [401/735], Loss: 0.0003
Epoch [83/100], Step [411/735], Loss: 0.0119
Epoch [83/100], Step [421/735], Loss: 0.0116
Epoch [83/100], Step [431/735], Loss: 0.0003
Epoch [83/100], Step [441/735], Loss: 0.0092
Epoch [83/100], Step [451/735], Loss: 0.0207
Epoch [83/100], Step [461/735], Loss: 0.0016
Epoch [83/100], Step [471/735], Loss: 0.0006
Epoch [83/100], Step [481/735], Loss: 0.0278
Epoch [83/100], Step [491/735], Loss: 0.0007
Epoch [83/100], Step [501/735], Loss: 0.0003
Epoch [83/100], Step [511/735], Loss: 0.0062
Epoch [83/100], Step [521/735], Loss: 0.0139
Epoch [83/100], Step [531/735], Loss: 0.0161
Epoch [83/100], Step [541/735], Loss: 0.0124
Epoch [83/100], Step [551/735], Loss: 0.0112
Epoch [83/100], Step [561/735], Loss: 0.0001
Epoch [83/100], Step [571/735], Loss: 0.0227
Epoch [83/100], Step [581/735], Loss: 0.0001
Epoch [83/100], Step [591/735], Loss: 0.0121
Epoch [83/100], Step [601/735], Loss: 0.0134
Epoch [83/100], Step [611/735], Loss: 0.0001
Epoch [83/100], Step [621/735], Loss: 0.0001
Epoch [83/100], Step [631/735], Loss: 0.0004
Epoch [83/100], Step [641/735], Loss: 0.0205
Epoch [83/100], Step [651/735], Loss: 0.0001
Epoch [83/100], Step [661/735], Loss: 0.0282
Epoch [83/100], Step [671/735], Loss: 0.0125
Epoch [83/100], Step [681/735], Loss: 0.0156
Epoch [83/100], Step [691/735], Loss: 0.0034
Epoch [83/100], Step [701/735], Loss: 0.0002
Epoch [83/100], Step [711/735], Loss: 0.0138
Epoch [83/100], Step [721/735], Loss: 0.0177
Epoch [83/100], Step [731/735], Loss: 0.0006
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9215,Val AUC: 0.9547,Val precision: 0.8540, Val recall: 0.8702, Val Loss: 0.0688
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 83 | Time taken: 2230.35s |
| Val CE loss: 0.06884 | Val MSE 0.92154 | Train Loss 0.00736 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 84
Training for epoch 84
Epoch [84/100], Step [1/735], Loss: 0.0000
Epoch [84/100], Step [11/735], Loss: 0.0022
Epoch [84/100], Step [21/735], Loss: 0.0025
Epoch [84/100], Step [31/735], Loss: 0.0006
Epoch [84/100], Step [41/735], Loss: 0.0008
Epoch [84/100], Step [51/735], Loss: 0.0008
Epoch [84/100], Step [61/735], Loss: 0.0010
Epoch [84/100], Step [71/735], Loss: 0.0111
Epoch [84/100], Step [81/735], Loss: 0.0097
Epoch [84/100], Step [91/735], Loss: 0.0138
Epoch [84/100], Step [101/735], Loss: 0.0022
Epoch [84/100], Step [111/735], Loss: 0.0223
Epoch [84/100], Step [121/735], Loss: 0.0017
Epoch [84/100], Step [131/735], Loss: 0.0004
Epoch [84/100], Step [141/735], Loss: 0.0154
Epoch [84/100], Step [151/735], Loss: 0.0033
Epoch [84/100], Step [161/735], Loss: 0.0002
Epoch [84/100], Step [171/735], Loss: 0.0001
Epoch [84/100], Step [181/735], Loss: 0.0202
Epoch [84/100], Step [191/735], Loss: 0.0212
Epoch [84/100], Step [201/735], Loss: 0.0030
Epoch [84/100], Step [211/735], Loss: 0.0002
Epoch [84/100], Step [221/735], Loss: 0.0028
Epoch [84/100], Step [231/735], Loss: 0.0274
Epoch [84/100], Step [241/735], Loss: 0.0001
Epoch [84/100], Step [251/735], Loss: 0.0034
Epoch [84/100], Step [261/735], Loss: 0.0003
Epoch [84/100], Step [271/735], Loss: 0.0198
Epoch [84/100], Step [281/735], Loss: 0.0002
Epoch [84/100], Step [291/735], Loss: 0.0005
Epoch [84/100], Step [301/735], Loss: 0.0131
Epoch [84/100], Step [311/735], Loss: 0.0018
Epoch [84/100], Step [321/735], Loss: 0.0002
Epoch [84/100], Step [331/735], Loss: 0.0019
Epoch [84/100], Step [341/735], Loss: 0.0109
Epoch [84/100], Step [351/735], Loss: 0.0005
Epoch [84/100], Step [361/735], Loss: 0.0036
Epoch [84/100], Step [371/735], Loss: 0.0117
Epoch [84/100], Step [381/735], Loss: 0.0002
Epoch [84/100], Step [391/735], Loss: 0.0191
Epoch [84/100], Step [401/735], Loss: 0.0018
Epoch [84/100], Step [411/735], Loss: 0.0004
Epoch [84/100], Step [421/735], Loss: 0.0032
Epoch [84/100], Step [431/735], Loss: 0.0011
Epoch [84/100], Step [441/735], Loss: 0.0238
Epoch [84/100], Step [451/735], Loss: 0.0001
Epoch [84/100], Step [461/735], Loss: 0.0063
Epoch [84/100], Step [471/735], Loss: 0.0147
Epoch [84/100], Step [481/735], Loss: 0.0050
Epoch [84/100], Step [491/735], Loss: 0.0046
Epoch [84/100], Step [501/735], Loss: 0.0142
Epoch [84/100], Step [511/735], Loss: 0.0261
Epoch [84/100], Step [521/735], Loss: 0.0167
Epoch [84/100], Step [531/735], Loss: 0.0001
Epoch [84/100], Step [541/735], Loss: 0.0004
Epoch [84/100], Step [551/735], Loss: 0.0076
Epoch [84/100], Step [561/735], Loss: 0.0012
Epoch [84/100], Step [571/735], Loss: 0.0022
Epoch [84/100], Step [581/735], Loss: 0.0168
Epoch [84/100], Step [591/735], Loss: 0.0085
Epoch [84/100], Step [601/735], Loss: 0.0011
Epoch [84/100], Step [611/735], Loss: 0.0003
Epoch [84/100], Step [621/735], Loss: 0.0003
Epoch [84/100], Step [631/735], Loss: 0.0251
Epoch [84/100], Step [641/735], Loss: 0.0012
Epoch [84/100], Step [651/735], Loss: 0.0140
Epoch [84/100], Step [661/735], Loss: 0.0114
Epoch [84/100], Step [671/735], Loss: 0.0255
Epoch [84/100], Step [681/735], Loss: 0.0126
Epoch [84/100], Step [691/735], Loss: 0.0003
Epoch [84/100], Step [701/735], Loss: 0.0001
Epoch [84/100], Step [711/735], Loss: 0.0142
Epoch [84/100], Step [721/735], Loss: 0.0002
Epoch [84/100], Step [731/735], Loss: 0.0157
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9196,Val AUC: 0.9573,Val precision: 0.8390, Val recall: 0.8844, Val Loss: 0.0708
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 84 | Time taken: 2269.83s |
| Val CE loss: 0.07082 | Val MSE 0.91964 | Train Loss 0.00822 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 85
Training for epoch 85
Epoch [85/100], Step [1/735], Loss: 0.0097
Epoch [85/100], Step [11/735], Loss: 0.0018
Epoch [85/100], Step [21/735], Loss: 0.0140
Epoch [85/100], Step [31/735], Loss: 0.0001
Epoch [85/100], Step [41/735], Loss: 0.0024
Epoch [85/100], Step [51/735], Loss: 0.0161
Epoch [85/100], Step [61/735], Loss: 0.0021
Epoch [85/100], Step [71/735], Loss: 0.0005
Epoch [85/100], Step [81/735], Loss: 0.0032
Epoch [85/100], Step [91/735], Loss: 0.0015
Epoch [85/100], Step [101/735], Loss: 0.0008
Epoch [85/100], Step [111/735], Loss: 0.0017
Epoch [85/100], Step [121/735], Loss: 0.0007
Epoch [85/100], Step [131/735], Loss: 0.0001
Epoch [85/100], Step [141/735], Loss: 0.0197
Epoch [85/100], Step [151/735], Loss: 0.0126
Epoch [85/100], Step [161/735], Loss: 0.0085
Epoch [85/100], Step [171/735], Loss: 0.0146
Epoch [85/100], Step [181/735], Loss: 0.0046
Epoch [85/100], Step [191/735], Loss: 0.0079
Epoch [85/100], Step [201/735], Loss: 0.0127
Epoch [85/100], Step [211/735], Loss: 0.0126
Epoch [85/100], Step [221/735], Loss: 0.0108
Epoch [85/100], Step [231/735], Loss: 0.0000
Epoch [85/100], Step [241/735], Loss: 0.0000
Epoch [85/100], Step [251/735], Loss: 0.0080
Epoch [85/100], Step [261/735], Loss: 0.0072
Epoch [85/100], Step [271/735], Loss: 0.0000
Epoch [85/100], Step [281/735], Loss: 0.0145
Epoch [85/100], Step [291/735], Loss: 0.0005
Epoch [85/100], Step [301/735], Loss: 0.0005
Epoch [85/100], Step [311/735], Loss: 0.0148
Epoch [85/100], Step [321/735], Loss: 0.0115
Epoch [85/100], Step [331/735], Loss: 0.0135
Epoch [85/100], Step [341/735], Loss: 0.0004
Epoch [85/100], Step [351/735], Loss: 0.0134
Epoch [85/100], Step [361/735], Loss: 0.0001
Epoch [85/100], Step [371/735], Loss: 0.0129
Epoch [85/100], Step [381/735], Loss: 0.0143
Epoch [85/100], Step [391/735], Loss: 0.0268
Epoch [85/100], Step [401/735], Loss: 0.0087
Epoch [85/100], Step [411/735], Loss: 0.0170
Epoch [85/100], Step [421/735], Loss: 0.0001
Epoch [85/100], Step [431/735], Loss: 0.0139
Epoch [85/100], Step [441/735], Loss: 0.0027
Epoch [85/100], Step [451/735], Loss: 0.0001
Epoch [85/100], Step [461/735], Loss: 0.0058
Epoch [85/100], Step [471/735], Loss: 0.0196
Epoch [85/100], Step [481/735], Loss: 0.0066
Epoch [85/100], Step [491/735], Loss: 0.0130
Epoch [85/100], Step [501/735], Loss: 0.0002
Epoch [85/100], Step [511/735], Loss: 0.0141
Epoch [85/100], Step [521/735], Loss: 0.0138
Epoch [85/100], Step [531/735], Loss: 0.0139
Epoch [85/100], Step [541/735], Loss: 0.0139
Epoch [85/100], Step [551/735], Loss: 0.0000
Epoch [85/100], Step [561/735], Loss: 0.0283
Epoch [85/100], Step [571/735], Loss: 0.0257
Epoch [85/100], Step [581/735], Loss: 0.0002
Epoch [85/100], Step [591/735], Loss: 0.0011
Epoch [85/100], Step [601/735], Loss: 0.0000
Epoch [85/100], Step [611/735], Loss: 0.0001
Epoch [85/100], Step [621/735], Loss: 0.0072
Epoch [85/100], Step [631/735], Loss: 0.0141
Epoch [85/100], Step [641/735], Loss: 0.0001
Epoch [85/100], Step [651/735], Loss: 0.0001
Epoch [85/100], Step [661/735], Loss: 0.0005
Epoch [85/100], Step [671/735], Loss: 0.0001
Epoch [85/100], Step [681/735], Loss: 0.0027
Epoch [85/100], Step [691/735], Loss: 0.0156
Epoch [85/100], Step [701/735], Loss: 0.0139
Epoch [85/100], Step [711/735], Loss: 0.0001
Epoch [85/100], Step [721/735], Loss: 0.0137
Epoch [85/100], Step [731/735], Loss: 0.0096
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9212,Val AUC: 0.9525,Val precision: 0.8643, Val recall: 0.8542, Val Loss: 0.0685
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 85 | Time taken: 2244.77s |
| Val CE loss: 0.06850 | Val MSE 0.92120 | Train Loss 0.00734 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 86
Training for epoch 86
Epoch [86/100], Step [1/735], Loss: 0.0014
Epoch [86/100], Step [11/735], Loss: 0.0332
Epoch [86/100], Step [21/735], Loss: 0.0137
Epoch [86/100], Step [31/735], Loss: 0.0139
Epoch [86/100], Step [41/735], Loss: 0.0009
Epoch [86/100], Step [51/735], Loss: 0.0001
Epoch [86/100], Step [61/735], Loss: 0.0001
Epoch [86/100], Step [71/735], Loss: 0.0008
Epoch [86/100], Step [81/735], Loss: 0.0138
Epoch [86/100], Step [91/735], Loss: 0.0012
Epoch [86/100], Step [101/735], Loss: 0.0002
Epoch [86/100], Step [111/735], Loss: 0.0413
Epoch [86/100], Step [121/735], Loss: 0.0254
Epoch [86/100], Step [131/735], Loss: 0.0007
Epoch [86/100], Step [141/735], Loss: 0.0063
Epoch [86/100], Step [151/735], Loss: 0.0011
Epoch [86/100], Step [161/735], Loss: 0.0159
Epoch [86/100], Step [171/735], Loss: 0.0273
Epoch [86/100], Step [181/735], Loss: 0.0005
Epoch [86/100], Step [191/735], Loss: 0.0000
Epoch [86/100], Step [201/735], Loss: 0.0083
Epoch [86/100], Step [211/735], Loss: 0.0002
Epoch [86/100], Step [221/735], Loss: 0.0042
Epoch [86/100], Step [231/735], Loss: 0.0096
Epoch [86/100], Step [241/735], Loss: 0.0055
Epoch [86/100], Step [251/735], Loss: 0.0013
Epoch [86/100], Step [261/735], Loss: 0.0000
Epoch [86/100], Step [271/735], Loss: 0.0036
Epoch [86/100], Step [281/735], Loss: 0.0018
Epoch [86/100], Step [291/735], Loss: 0.0052
Epoch [86/100], Step [301/735], Loss: 0.0139
Epoch [86/100], Step [311/735], Loss: 0.0133
Epoch [86/100], Step [321/735], Loss: 0.0003
Epoch [86/100], Step [331/735], Loss: 0.0164
Epoch [86/100], Step [341/735], Loss: 0.0149
Epoch [86/100], Step [351/735], Loss: 0.0001
Epoch [86/100], Step [361/735], Loss: 0.0274
Epoch [86/100], Step [371/735], Loss: 0.0008
Epoch [86/100], Step [381/735], Loss: 0.0024
Epoch [86/100], Step [391/735], Loss: 0.0002
Epoch [86/100], Step [401/735], Loss: 0.0204
Epoch [86/100], Step [411/735], Loss: 0.0142
Epoch [86/100], Step [421/735], Loss: 0.0145
Epoch [86/100], Step [431/735], Loss: 0.0119
Epoch [86/100], Step [441/735], Loss: 0.0003
Epoch [86/100], Step [451/735], Loss: 0.0045
Epoch [86/100], Step [461/735], Loss: 0.0002
Epoch [86/100], Step [471/735], Loss: 0.0001
Epoch [86/100], Step [481/735], Loss: 0.0104
Epoch [86/100], Step [491/735], Loss: 0.0001
Epoch [86/100], Step [501/735], Loss: 0.0095
Epoch [86/100], Step [511/735], Loss: 0.0057
Epoch [86/100], Step [521/735], Loss: 0.0136
Epoch [86/100], Step [531/735], Loss: 0.0165
Epoch [86/100], Step [541/735], Loss: 0.0024
Epoch [86/100], Step [551/735], Loss: 0.0499
Epoch [86/100], Step [561/735], Loss: 0.0079
Epoch [86/100], Step [571/735], Loss: 0.0106
Epoch [86/100], Step [581/735], Loss: 0.0236
Epoch [86/100], Step [591/735], Loss: 0.0239
Epoch [86/100], Step [601/735], Loss: 0.0131
Epoch [86/100], Step [611/735], Loss: 0.0001
Epoch [86/100], Step [621/735], Loss: 0.0189
Epoch [86/100], Step [631/735], Loss: 0.0001
Epoch [86/100], Step [641/735], Loss: 0.0013
Epoch [86/100], Step [651/735], Loss: 0.0156
Epoch [86/100], Step [661/735], Loss: 0.0060
Epoch [86/100], Step [671/735], Loss: 0.0214
Epoch [86/100], Step [681/735], Loss: 0.0028
Epoch [86/100], Step [691/735], Loss: 0.0000
Epoch [86/100], Step [701/735], Loss: 0.0139
Epoch [86/100], Step [711/735], Loss: 0.0148
Epoch [86/100], Step [721/735], Loss: 0.0090
Epoch [86/100], Step [731/735], Loss: 0.0043
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9138,Val AUC: 0.9552,Val precision: 0.8298, Val recall: 0.8727, Val Loss: 0.0734
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 86 | Time taken: 2264.65s |
| Val CE loss: 0.07344 | Val MSE 0.91375 | Train Loss 0.00726 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 87
Training for epoch 87
Epoch [87/100], Step [1/735], Loss: 0.0337
Epoch [87/100], Step [11/735], Loss: 0.0036
Epoch [87/100], Step [21/735], Loss: 0.0180
Epoch [87/100], Step [31/735], Loss: 0.0017
Epoch [87/100], Step [41/735], Loss: 0.0014
Epoch [87/100], Step [51/735], Loss: 0.0001
Epoch [87/100], Step [61/735], Loss: 0.0227
Epoch [87/100], Step [71/735], Loss: 0.0139
Epoch [87/100], Step [81/735], Loss: 0.0125
Epoch [87/100], Step [91/735], Loss: 0.0043
Epoch [87/100], Step [101/735], Loss: 0.0282
Epoch [87/100], Step [111/735], Loss: 0.0151
Epoch [87/100], Step [121/735], Loss: 0.0141
Epoch [87/100], Step [131/735], Loss: 0.0079
Epoch [87/100], Step [141/735], Loss: 0.0010
Epoch [87/100], Step [151/735], Loss: 0.0198
Epoch [87/100], Step [161/735], Loss: 0.0002
Epoch [87/100], Step [171/735], Loss: 0.0022
Epoch [87/100], Step [181/735], Loss: 0.0104
Epoch [87/100], Step [191/735], Loss: 0.0003
Epoch [87/100], Step [201/735], Loss: 0.0075
Epoch [87/100], Step [211/735], Loss: 0.0001
Epoch [87/100], Step [221/735], Loss: 0.0001
Epoch [87/100], Step [231/735], Loss: 0.0140
Epoch [87/100], Step [241/735], Loss: 0.0004
Epoch [87/100], Step [251/735], Loss: 0.0031
Epoch [87/100], Step [261/735], Loss: 0.0001
Epoch [87/100], Step [271/735], Loss: 0.0014
Epoch [87/100], Step [281/735], Loss: 0.0141
Epoch [87/100], Step [291/735], Loss: 0.0001
Epoch [87/100], Step [301/735], Loss: 0.0006
Epoch [87/100], Step [311/735], Loss: 0.0155
Epoch [87/100], Step [321/735], Loss: 0.0002
Epoch [87/100], Step [331/735], Loss: 0.0143
Epoch [87/100], Step [341/735], Loss: 0.0003
Epoch [87/100], Step [351/735], Loss: 0.0138
Epoch [87/100], Step [361/735], Loss: 0.0051
Epoch [87/100], Step [371/735], Loss: 0.0157
Epoch [87/100], Step [381/735], Loss: 0.0030
Epoch [87/100], Step [391/735], Loss: 0.0001
Epoch [87/100], Step [401/735], Loss: 0.0040
Epoch [87/100], Step [411/735], Loss: 0.0137
Epoch [87/100], Step [421/735], Loss: 0.0068
Epoch [87/100], Step [431/735], Loss: 0.0082
Epoch [87/100], Step [441/735], Loss: 0.0001
Epoch [87/100], Step [451/735], Loss: 0.0008
Epoch [87/100], Step [461/735], Loss: 0.0008
Epoch [87/100], Step [471/735], Loss: 0.0128
Epoch [87/100], Step [481/735], Loss: 0.0230
Epoch [87/100], Step [491/735], Loss: 0.0123
Epoch [87/100], Step [501/735], Loss: 0.0061
Epoch [87/100], Step [511/735], Loss: 0.0000
Epoch [87/100], Step [521/735], Loss: 0.0053
Epoch [87/100], Step [531/735], Loss: 0.0282
Epoch [87/100], Step [541/735], Loss: 0.0139
Epoch [87/100], Step [551/735], Loss: 0.0137
Epoch [87/100], Step [561/735], Loss: 0.0250
Epoch [87/100], Step [571/735], Loss: 0.0183
Epoch [87/100], Step [581/735], Loss: 0.0258
Epoch [87/100], Step [591/735], Loss: 0.0008
Epoch [87/100], Step [601/735], Loss: 0.0008
Epoch [87/100], Step [611/735], Loss: 0.0001
Epoch [87/100], Step [621/735], Loss: 0.0041
Epoch [87/100], Step [631/735], Loss: 0.0223
Epoch [87/100], Step [641/735], Loss: 0.0001
Epoch [87/100], Step [651/735], Loss: 0.0108
Epoch [87/100], Step [661/735], Loss: 0.0008
Epoch [87/100], Step [671/735], Loss: 0.0109
Epoch [87/100], Step [681/735], Loss: 0.0209
Epoch [87/100], Step [691/735], Loss: 0.0005
Epoch [87/100], Step [701/735], Loss: 0.0190
Epoch [87/100], Step [711/735], Loss: 0.0031
Epoch [87/100], Step [721/735], Loss: 0.0027
Epoch [87/100], Step [731/735], Loss: 0.0003
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9106,Val AUC: 0.9568,Val precision: 0.8175, Val recall: 0.8788, Val Loss: 0.0773
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 87 | Time taken: 2271.57s |
| Val CE loss: 0.07734 | Val MSE 0.91063 | Train Loss 0.00883 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 88
Training for epoch 88
Epoch [88/100], Step [1/735], Loss: 0.0005
Epoch [88/100], Step [11/735], Loss: 0.0075
Epoch [88/100], Step [21/735], Loss: 0.0001
Epoch [88/100], Step [31/735], Loss: 0.0172
Epoch [88/100], Step [41/735], Loss: 0.0140
Epoch [88/100], Step [51/735], Loss: 0.0275
Epoch [88/100], Step [61/735], Loss: 0.0001
Epoch [88/100], Step [71/735], Loss: 0.0014
Epoch [88/100], Step [81/735], Loss: 0.0140
Epoch [88/100], Step [91/735], Loss: 0.0036
Epoch [88/100], Step [101/735], Loss: 0.0006
Epoch [88/100], Step [111/735], Loss: 0.0001
Epoch [88/100], Step [121/735], Loss: 0.0007
Epoch [88/100], Step [131/735], Loss: 0.0003
Epoch [88/100], Step [141/735], Loss: 0.0304
Epoch [88/100], Step [151/735], Loss: 0.0053
Epoch [88/100], Step [161/735], Loss: 0.0190
Epoch [88/100], Step [171/735], Loss: 0.0001
Epoch [88/100], Step [181/735], Loss: 0.0048
Epoch [88/100], Step [191/735], Loss: 0.0000
Epoch [88/100], Step [201/735], Loss: 0.0122
Epoch [88/100], Step [211/735], Loss: 0.0004
Epoch [88/100], Step [221/735], Loss: 0.0080
Epoch [88/100], Step [231/735], Loss: 0.0012
Epoch [88/100], Step [241/735], Loss: 0.0259
Epoch [88/100], Step [251/735], Loss: 0.0092
Epoch [88/100], Step [261/735], Loss: 0.0005
Epoch [88/100], Step [271/735], Loss: 0.0140
Epoch [88/100], Step [281/735], Loss: 0.0000
Epoch [88/100], Step [291/735], Loss: 0.0010
Epoch [88/100], Step [301/735], Loss: 0.0002
Epoch [88/100], Step [311/735], Loss: 0.0003
Epoch [88/100], Step [321/735], Loss: 0.0001
Epoch [88/100], Step [331/735], Loss: 0.0107
Epoch [88/100], Step [341/735], Loss: 0.0182
Epoch [88/100], Step [351/735], Loss: 0.0261
Epoch [88/100], Step [361/735], Loss: 0.0137
Epoch [88/100], Step [371/735], Loss: 0.0000
Epoch [88/100], Step [381/735], Loss: 0.0011
Epoch [88/100], Step [391/735], Loss: 0.0051
Epoch [88/100], Step [401/735], Loss: 0.0001
Epoch [88/100], Step [411/735], Loss: 0.0046
Epoch [88/100], Step [421/735], Loss: 0.0131
Epoch [88/100], Step [431/735], Loss: 0.0003
Epoch [88/100], Step [441/735], Loss: 0.0138
Epoch [88/100], Step [451/735], Loss: 0.0001
Epoch [88/100], Step [461/735], Loss: 0.0077
Epoch [88/100], Step [471/735], Loss: 0.0138
Epoch [88/100], Step [481/735], Loss: 0.0125
Epoch [88/100], Step [491/735], Loss: 0.0132
Epoch [88/100], Step [501/735], Loss: 0.0001
Epoch [88/100], Step [511/735], Loss: 0.0008
Epoch [88/100], Step [521/735], Loss: 0.0002
Epoch [88/100], Step [531/735], Loss: 0.0163
Epoch [88/100], Step [541/735], Loss: 0.0070
Epoch [88/100], Step [551/735], Loss: 0.0000
Epoch [88/100], Step [561/735], Loss: 0.0000
Epoch [88/100], Step [571/735], Loss: 0.0157
Epoch [88/100], Step [581/735], Loss: 0.0081
Epoch [88/100], Step [591/735], Loss: 0.0010
Epoch [88/100], Step [601/735], Loss: 0.0042
Epoch [88/100], Step [611/735], Loss: 0.0001
Epoch [88/100], Step [621/735], Loss: 0.0139
Epoch [88/100], Step [631/735], Loss: 0.0109
Epoch [88/100], Step [641/735], Loss: 0.0012
Epoch [88/100], Step [651/735], Loss: 0.0149
Epoch [88/100], Step [661/735], Loss: 0.0031
Epoch [88/100], Step [671/735], Loss: 0.0353
Epoch [88/100], Step [681/735], Loss: 0.0117
Epoch [88/100], Step [691/735], Loss: 0.0002
Epoch [88/100], Step [701/735], Loss: 0.0140
Epoch [88/100], Step [711/735], Loss: 0.0068
Epoch [88/100], Step [721/735], Loss: 0.0004
Epoch [88/100], Step [731/735], Loss: 0.0166
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9222,Val AUC: 0.9572,Val precision: 0.8565, Val recall: 0.8696, Val Loss: 0.0689
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 88 | Time taken: 2264.17s |
| Val CE loss: 0.06887 | Val MSE 0.92224 | Train Loss 0.00682 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 89
Training for epoch 89
Epoch [89/100], Step [1/735], Loss: 0.0013
Epoch [89/100], Step [11/735], Loss: 0.0159
Epoch [89/100], Step [21/735], Loss: 0.0000
Epoch [89/100], Step [31/735], Loss: 0.0002
Epoch [89/100], Step [41/735], Loss: 0.0001
Epoch [89/100], Step [51/735], Loss: 0.0002
Epoch [89/100], Step [61/735], Loss: 0.0000
Epoch [89/100], Step [71/735], Loss: 0.0001
Epoch [89/100], Step [81/735], Loss: 0.0008
Epoch [89/100], Step [91/735], Loss: 0.0015
Epoch [89/100], Step [101/735], Loss: 0.0002
Epoch [89/100], Step [111/735], Loss: 0.0226
Epoch [89/100], Step [121/735], Loss: 0.0000
Epoch [89/100], Step [131/735], Loss: 0.0108
Epoch [89/100], Step [141/735], Loss: 0.0269
Epoch [89/100], Step [151/735], Loss: 0.0003
Epoch [89/100], Step [161/735], Loss: 0.0000
Epoch [89/100], Step [171/735], Loss: 0.0155
Epoch [89/100], Step [181/735], Loss: 0.0029
Epoch [89/100], Step [191/735], Loss: 0.0051
Epoch [89/100], Step [201/735], Loss: 0.0003
Epoch [89/100], Step [211/735], Loss: 0.0045
Epoch [89/100], Step [221/735], Loss: 0.0000
Epoch [89/100], Step [231/735], Loss: 0.0140
Epoch [89/100], Step [241/735], Loss: 0.0117
Epoch [89/100], Step [251/735], Loss: 0.0159
Epoch [89/100], Step [261/735], Loss: 0.0192
Epoch [89/100], Step [271/735], Loss: 0.0023
Epoch [89/100], Step [281/735], Loss: 0.0095
Epoch [89/100], Step [291/735], Loss: 0.0138
Epoch [89/100], Step [301/735], Loss: 0.0139
Epoch [89/100], Step [311/735], Loss: 0.0139
Epoch [89/100], Step [321/735], Loss: 0.0178
Epoch [89/100], Step [331/735], Loss: 0.0021
Epoch [89/100], Step [341/735], Loss: 0.0001
Epoch [89/100], Step [351/735], Loss: 0.0011
Epoch [89/100], Step [361/735], Loss: 0.0147
Epoch [89/100], Step [371/735], Loss: 0.0056
Epoch [89/100], Step [381/735], Loss: 0.0140
Epoch [89/100], Step [391/735], Loss: 0.0146
Epoch [89/100], Step [401/735], Loss: 0.0001
Epoch [89/100], Step [411/735], Loss: 0.0112
Epoch [89/100], Step [421/735], Loss: 0.0000
Epoch [89/100], Step [431/735], Loss: 0.0344
Epoch [89/100], Step [441/735], Loss: 0.0001
Epoch [89/100], Step [451/735], Loss: 0.0003
Epoch [89/100], Step [461/735], Loss: 0.0001
Epoch [89/100], Step [471/735], Loss: 0.0088
Epoch [89/100], Step [481/735], Loss: 0.0144
Epoch [89/100], Step [491/735], Loss: 0.0276
Epoch [89/100], Step [501/735], Loss: 0.0029
Epoch [89/100], Step [511/735], Loss: 0.0324
Epoch [89/100], Step [521/735], Loss: 0.0001
Epoch [89/100], Step [531/735], Loss: 0.0037
Epoch [89/100], Step [541/735], Loss: 0.0000
Epoch [89/100], Step [551/735], Loss: 0.0053
Epoch [89/100], Step [561/735], Loss: 0.0001
Epoch [89/100], Step [571/735], Loss: 0.0119
Epoch [89/100], Step [581/735], Loss: 0.0006
Epoch [89/100], Step [591/735], Loss: 0.0004
Epoch [89/100], Step [601/735], Loss: 0.0137
Epoch [89/100], Step [611/735], Loss: 0.0000
Epoch [89/100], Step [621/735], Loss: 0.0091
Epoch [89/100], Step [631/735], Loss: 0.0005
Epoch [89/100], Step [641/735], Loss: 0.0000
Epoch [89/100], Step [651/735], Loss: 0.0054
Epoch [89/100], Step [661/735], Loss: 0.0131
Epoch [89/100], Step [671/735], Loss: 0.0254
Epoch [89/100], Step [681/735], Loss: 0.0001
Epoch [89/100], Step [691/735], Loss: 0.0125
Epoch [89/100], Step [701/735], Loss: 0.0002
Epoch [89/100], Step [711/735], Loss: 0.0004
Epoch [89/100], Step [721/735], Loss: 0.0056
Epoch [89/100], Step [731/735], Loss: 0.0026
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9217,Val AUC: 0.9592,Val precision: 0.8523, Val recall: 0.8733, Val Loss: 0.0683
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 89 | Time taken: 2236.59s |
| Val CE loss: 0.06832 | Val MSE 0.92172 | Train Loss 0.00674 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 90
Training for epoch 90
Epoch [90/100], Step [1/735], Loss: 0.0001
Epoch [90/100], Step [11/735], Loss: 0.0000
Epoch [90/100], Step [21/735], Loss: 0.0415
Epoch [90/100], Step [31/735], Loss: 0.0018
Epoch [90/100], Step [41/735], Loss: 0.0001
Epoch [90/100], Step [51/735], Loss: 0.0014
Epoch [90/100], Step [61/735], Loss: 0.0011
Epoch [90/100], Step [71/735], Loss: 0.0001
Epoch [90/100], Step [81/735], Loss: 0.0003
Epoch [90/100], Step [91/735], Loss: 0.0021
Epoch [90/100], Step [101/735], Loss: 0.0002
Epoch [90/100], Step [111/735], Loss: 0.0002
Epoch [90/100], Step [121/735], Loss: 0.0378
Epoch [90/100], Step [131/735], Loss: 0.0006
Epoch [90/100], Step [141/735], Loss: 0.0202
Epoch [90/100], Step [151/735], Loss: 0.0134
Epoch [90/100], Step [161/735], Loss: 0.0005
Epoch [90/100], Step [171/735], Loss: 0.0219
Epoch [90/100], Step [181/735], Loss: 0.0121
Epoch [90/100], Step [191/735], Loss: 0.0025
Epoch [90/100], Step [201/735], Loss: 0.0000
Epoch [90/100], Step [211/735], Loss: 0.0139
Epoch [90/100], Step [221/735], Loss: 0.0001
Epoch [90/100], Step [231/735], Loss: 0.0276
Epoch [90/100], Step [241/735], Loss: 0.0074
Epoch [90/100], Step [251/735], Loss: 0.0004
Epoch [90/100], Step [261/735], Loss: 0.0154
Epoch [90/100], Step [271/735], Loss: 0.0081
Epoch [90/100], Step [281/735], Loss: 0.0003
Epoch [90/100], Step [291/735], Loss: 0.0174
Epoch [90/100], Step [301/735], Loss: 0.0270
Epoch [90/100], Step [311/735], Loss: 0.0001
Epoch [90/100], Step [321/735], Loss: 0.0109
Epoch [90/100], Step [331/735], Loss: 0.0079
Epoch [90/100], Step [341/735], Loss: 0.0111
Epoch [90/100], Step [351/735], Loss: 0.0001
Epoch [90/100], Step [361/735], Loss: 0.0001
Epoch [90/100], Step [371/735], Loss: 0.0120
Epoch [90/100], Step [381/735], Loss: 0.0000
Epoch [90/100], Step [391/735], Loss: 0.0118
Epoch [90/100], Step [401/735], Loss: 0.0049
Epoch [90/100], Step [411/735], Loss: 0.0133
Epoch [90/100], Step [421/735], Loss: 0.0066
Epoch [90/100], Step [431/735], Loss: 0.0141
Epoch [90/100], Step [441/735], Loss: 0.0167
Epoch [90/100], Step [451/735], Loss: 0.0141
Epoch [90/100], Step [461/735], Loss: 0.0014
Epoch [90/100], Step [471/735], Loss: 0.0404
Epoch [90/100], Step [481/735], Loss: 0.0031
Epoch [90/100], Step [491/735], Loss: 0.0169
Epoch [90/100], Step [501/735], Loss: 0.0017
Epoch [90/100], Step [511/735], Loss: 0.0048
Epoch [90/100], Step [521/735], Loss: 0.0082
Epoch [90/100], Step [531/735], Loss: 0.0006
Epoch [90/100], Step [541/735], Loss: 0.0001
Epoch [90/100], Step [551/735], Loss: 0.0141
Epoch [90/100], Step [561/735], Loss: 0.0068
Epoch [90/100], Step [571/735], Loss: 0.0145
Epoch [90/100], Step [581/735], Loss: 0.0002
Epoch [90/100], Step [591/735], Loss: 0.0123
Epoch [90/100], Step [601/735], Loss: 0.0001
Epoch [90/100], Step [611/735], Loss: 0.0141
Epoch [90/100], Step [621/735], Loss: 0.0139
Epoch [90/100], Step [631/735], Loss: 0.0137
Epoch [90/100], Step [641/735], Loss: 0.0022
Epoch [90/100], Step [651/735], Loss: 0.0001
Epoch [90/100], Step [661/735], Loss: 0.0087
Epoch [90/100], Step [671/735], Loss: 0.0007
Epoch [90/100], Step [681/735], Loss: 0.0094
Epoch [90/100], Step [691/735], Loss: 0.0000
Epoch [90/100], Step [701/735], Loss: 0.0001
Epoch [90/100], Step [711/735], Loss: 0.0001
Epoch [90/100], Step [721/735], Loss: 0.0139
Epoch [90/100], Step [731/735], Loss: 0.0001
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9238,Val AUC: 0.9576,Val precision: 0.8517, Val recall: 0.8831, Val Loss: 0.0675
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 90 | Time taken: 2230.89s |
| Val CE loss: 0.06748 | Val MSE 0.92380 | Train Loss 0.00720 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 91
Training for epoch 91
Epoch [91/100], Step [1/735], Loss: 0.0001
Epoch [91/100], Step [11/735], Loss: 0.0002
Epoch [91/100], Step [21/735], Loss: 0.0015
Epoch [91/100], Step [31/735], Loss: 0.0277
Epoch [91/100], Step [41/735], Loss: 0.0003
Epoch [91/100], Step [51/735], Loss: 0.0006
Epoch [91/100], Step [61/735], Loss: 0.0003
Epoch [91/100], Step [71/735], Loss: 0.0003
Epoch [91/100], Step [81/735], Loss: 0.0169
Epoch [91/100], Step [91/735], Loss: 0.0084
Epoch [91/100], Step [101/735], Loss: 0.0001
Epoch [91/100], Step [111/735], Loss: 0.0139
Epoch [91/100], Step [121/735], Loss: 0.0004
Epoch [91/100], Step [131/735], Loss: 0.0042
Epoch [91/100], Step [141/735], Loss: 0.0013
Epoch [91/100], Step [151/735], Loss: 0.0017
Epoch [91/100], Step [161/735], Loss: 0.0139
Epoch [91/100], Step [171/735], Loss: 0.0004
Epoch [91/100], Step [181/735], Loss: 0.0001
Epoch [91/100], Step [191/735], Loss: 0.0016
Epoch [91/100], Step [201/735], Loss: 0.0204
Epoch [91/100], Step [211/735], Loss: 0.0005
Epoch [91/100], Step [221/735], Loss: 0.0001
Epoch [91/100], Step [231/735], Loss: 0.0006
Epoch [91/100], Step [241/735], Loss: 0.0150
Epoch [91/100], Step [251/735], Loss: 0.0120
Epoch [91/100], Step [261/735], Loss: 0.0145
Epoch [91/100], Step [271/735], Loss: 0.0001
Epoch [91/100], Step [281/735], Loss: 0.0289
Epoch [91/100], Step [291/735], Loss: 0.0222
Epoch [91/100], Step [301/735], Loss: 0.0091
Epoch [91/100], Step [311/735], Loss: 0.0180
Epoch [91/100], Step [321/735], Loss: 0.0137
Epoch [91/100], Step [331/735], Loss: 0.0011
Epoch [91/100], Step [341/735], Loss: 0.0056
Epoch [91/100], Step [351/735], Loss: 0.0192
Epoch [91/100], Step [361/735], Loss: 0.0113
Epoch [91/100], Step [371/735], Loss: 0.0041
Epoch [91/100], Step [381/735], Loss: 0.0139
Epoch [91/100], Step [391/735], Loss: 0.0049
Epoch [91/100], Step [401/735], Loss: 0.0088
Epoch [91/100], Step [411/735], Loss: 0.0002
Epoch [91/100], Step [421/735], Loss: 0.0124
Epoch [91/100], Step [431/735], Loss: 0.0174
Epoch [91/100], Step [441/735], Loss: 0.0036
Epoch [91/100], Step [451/735], Loss: 0.0001
Epoch [91/100], Step [461/735], Loss: 0.0001
Epoch [91/100], Step [471/735], Loss: 0.0000
Epoch [91/100], Step [481/735], Loss: 0.0193
Epoch [91/100], Step [491/735], Loss: 0.0002
Epoch [91/100], Step [501/735], Loss: 0.0026
Epoch [91/100], Step [511/735], Loss: 0.0130
Epoch [91/100], Step [521/735], Loss: 0.0004
Epoch [91/100], Step [531/735], Loss: 0.0014
Epoch [91/100], Step [541/735], Loss: 0.0138
Epoch [91/100], Step [551/735], Loss: 0.0143
Epoch [91/100], Step [561/735], Loss: 0.0002
Epoch [91/100], Step [571/735], Loss: 0.0005
Epoch [91/100], Step [581/735], Loss: 0.0258
Epoch [91/100], Step [591/735], Loss: 0.0282
Epoch [91/100], Step [601/735], Loss: 0.0001
Epoch [91/100], Step [611/735], Loss: 0.0007
Epoch [91/100], Step [621/735], Loss: 0.0001
Epoch [91/100], Step [631/735], Loss: 0.0354
Epoch [91/100], Step [641/735], Loss: 0.0311
Epoch [91/100], Step [651/735], Loss: 0.0020
Epoch [91/100], Step [661/735], Loss: 0.0210
Epoch [91/100], Step [671/735], Loss: 0.0143
Epoch [91/100], Step [681/735], Loss: 0.0076
Epoch [91/100], Step [691/735], Loss: 0.0198
Epoch [91/100], Step [701/735], Loss: 0.0005
Epoch [91/100], Step [711/735], Loss: 0.0032
Epoch [91/100], Step [721/735], Loss: 0.0002
Epoch [91/100], Step [731/735], Loss: 0.0079
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9209,Val AUC: 0.9544,Val precision: 0.8494, Val recall: 0.8739, Val Loss: 0.0683
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 91 | Time taken: 2272.44s |
| Val CE loss: 0.06828 | Val MSE 0.92085 | Train Loss 0.00835 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 92
Training for epoch 92
Epoch [92/100], Step [1/735], Loss: 0.0002
Epoch [92/100], Step [11/735], Loss: 0.0064
Epoch [92/100], Step [21/735], Loss: 0.0201
Epoch [92/100], Step [31/735], Loss: 0.0003
Epoch [92/100], Step [41/735], Loss: 0.0324
Epoch [92/100], Step [51/735], Loss: 0.0130
Epoch [92/100], Step [61/735], Loss: 0.0076
Epoch [92/100], Step [71/735], Loss: 0.0138
Epoch [92/100], Step [81/735], Loss: 0.0268
Epoch [92/100], Step [91/735], Loss: 0.0001
Epoch [92/100], Step [101/735], Loss: 0.0113
Epoch [92/100], Step [111/735], Loss: 0.0001
Epoch [92/100], Step [121/735], Loss: 0.0153
Epoch [92/100], Step [131/735], Loss: 0.0239
Epoch [92/100], Step [141/735], Loss: 0.0001
Epoch [92/100], Step [151/735], Loss: 0.0071
Epoch [92/100], Step [161/735], Loss: 0.0141
Epoch [92/100], Step [171/735], Loss: 0.0139
Epoch [92/100], Step [181/735], Loss: 0.0025
Epoch [92/100], Step [191/735], Loss: 0.0012
Epoch [92/100], Step [201/735], Loss: 0.0001
Epoch [92/100], Step [211/735], Loss: 0.0001
Epoch [92/100], Step [221/735], Loss: 0.0008
Epoch [92/100], Step [231/735], Loss: 0.0067
Epoch [92/100], Step [241/735], Loss: 0.0000
Epoch [92/100], Step [251/735], Loss: 0.0015
Epoch [92/100], Step [261/735], Loss: 0.0039
Epoch [92/100], Step [271/735], Loss: 0.0277
Epoch [92/100], Step [281/735], Loss: 0.0156
Epoch [92/100], Step [291/735], Loss: 0.0145
Epoch [92/100], Step [301/735], Loss: 0.0139
Epoch [92/100], Step [311/735], Loss: 0.0276
Epoch [92/100], Step [321/735], Loss: 0.0136
Epoch [92/100], Step [331/735], Loss: 0.0043
Epoch [92/100], Step [341/735], Loss: 0.0139
Epoch [92/100], Step [351/735], Loss: 0.0003
Epoch [92/100], Step [361/735], Loss: 0.0135
Epoch [92/100], Step [371/735], Loss: 0.0020
Epoch [92/100], Step [381/735], Loss: 0.0001
Epoch [92/100], Step [391/735], Loss: 0.0000
Epoch [92/100], Step [401/735], Loss: 0.0138
Epoch [92/100], Step [411/735], Loss: 0.0001
Epoch [92/100], Step [421/735], Loss: 0.0000
Epoch [92/100], Step [431/735], Loss: 0.0034
Epoch [92/100], Step [441/735], Loss: 0.0017
Epoch [92/100], Step [451/735], Loss: 0.0130
Epoch [92/100], Step [461/735], Loss: 0.0004
Epoch [92/100], Step [471/735], Loss: 0.0141
Epoch [92/100], Step [481/735], Loss: 0.0001
Epoch [92/100], Step [491/735], Loss: 0.0161
Epoch [92/100], Step [501/735], Loss: 0.0138
Epoch [92/100], Step [511/735], Loss: 0.0040
Epoch [92/100], Step [521/735], Loss: 0.0124
Epoch [92/100], Step [531/735], Loss: 0.0002
Epoch [92/100], Step [541/735], Loss: 0.0129
Epoch [92/100], Step [551/735], Loss: 0.0277
Epoch [92/100], Step [561/735], Loss: 0.0026
Epoch [92/100], Step [571/735], Loss: 0.0172
Epoch [92/100], Step [581/735], Loss: 0.0066
Epoch [92/100], Step [591/735], Loss: 0.0001
Epoch [92/100], Step [601/735], Loss: 0.0000
Epoch [92/100], Step [611/735], Loss: 0.0001
Epoch [92/100], Step [621/735], Loss: 0.0000
Epoch [92/100], Step [631/735], Loss: 0.0130
Epoch [92/100], Step [641/735], Loss: 0.0133
Epoch [92/100], Step [651/735], Loss: 0.0037
Epoch [92/100], Step [661/735], Loss: 0.0001
Epoch [92/100], Step [671/735], Loss: 0.0107
Epoch [92/100], Step [681/735], Loss: 0.0003
Epoch [92/100], Step [691/735], Loss: 0.0035
Epoch [92/100], Step [701/735], Loss: 0.0002
Epoch [92/100], Step [711/735], Loss: 0.0000
Epoch [92/100], Step [721/735], Loss: 0.0276
Epoch [92/100], Step [731/735], Loss: 0.0091
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9198,Val AUC: 0.9569,Val precision: 0.8548, Val recall: 0.8616, Val Loss: 0.0691
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 92 | Time taken: 2263.44s |
| Val CE loss: 0.06905 | Val MSE 0.91981 | Train Loss 0.00709 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 93
Training for epoch 93
Epoch [93/100], Step [1/735], Loss: 0.0005
Epoch [93/100], Step [11/735], Loss: 0.0001
Epoch [93/100], Step [21/735], Loss: 0.0001
Epoch [93/100], Step [31/735], Loss: 0.0156
Epoch [93/100], Step [41/735], Loss: 0.0000
Epoch [93/100], Step [51/735], Loss: 0.0008
Epoch [93/100], Step [61/735], Loss: 0.0053
Epoch [93/100], Step [71/735], Loss: 0.0002
Epoch [93/100], Step [81/735], Loss: 0.0059
Epoch [93/100], Step [91/735], Loss: 0.0043
Epoch [93/100], Step [101/735], Loss: 0.0002
Epoch [93/100], Step [111/735], Loss: 0.0032
Epoch [93/100], Step [121/735], Loss: 0.0000
Epoch [93/100], Step [131/735], Loss: 0.0010
Epoch [93/100], Step [141/735], Loss: 0.0195
Epoch [93/100], Step [151/735], Loss: 0.0002
Epoch [93/100], Step [161/735], Loss: 0.0044
Epoch [93/100], Step [171/735], Loss: 0.0006
Epoch [93/100], Step [181/735], Loss: 0.0000
Epoch [93/100], Step [191/735], Loss: 0.0198
Epoch [93/100], Step [201/735], Loss: 0.0106
Epoch [93/100], Step [211/735], Loss: 0.0133
Epoch [93/100], Step [221/735], Loss: 0.0001
Epoch [93/100], Step [231/735], Loss: 0.0402
Epoch [93/100], Step [241/735], Loss: 0.0137
Epoch [93/100], Step [251/735], Loss: 0.0396
Epoch [93/100], Step [261/735], Loss: 0.0142
Epoch [93/100], Step [271/735], Loss: 0.0011
Epoch [93/100], Step [281/735], Loss: 0.0010
Epoch [93/100], Step [291/735], Loss: 0.0075
Epoch [93/100], Step [301/735], Loss: 0.0001
Epoch [93/100], Step [311/735], Loss: 0.0071
Epoch [93/100], Step [321/735], Loss: 0.0006
Epoch [93/100], Step [331/735], Loss: 0.0009
Epoch [93/100], Step [341/735], Loss: 0.0095
Epoch [93/100], Step [351/735], Loss: 0.0090
Epoch [93/100], Step [361/735], Loss: 0.0095
Epoch [93/100], Step [371/735], Loss: 0.0140
Epoch [93/100], Step [381/735], Loss: 0.0103
Epoch [93/100], Step [391/735], Loss: 0.0000
Epoch [93/100], Step [401/735], Loss: 0.0040
Epoch [93/100], Step [411/735], Loss: 0.0138
Epoch [93/100], Step [421/735], Loss: 0.0002
Epoch [93/100], Step [431/735], Loss: 0.0136
Epoch [93/100], Step [441/735], Loss: 0.0002
Epoch [93/100], Step [451/735], Loss: 0.0267
Epoch [93/100], Step [461/735], Loss: 0.0104
Epoch [93/100], Step [471/735], Loss: 0.0180
Epoch [93/100], Step [481/735], Loss: 0.0199
Epoch [93/100], Step [491/735], Loss: 0.0005
Epoch [93/100], Step [501/735], Loss: 0.0021
Epoch [93/100], Step [511/735], Loss: 0.0104
Epoch [93/100], Step [521/735], Loss: 0.0247
Epoch [93/100], Step [531/735], Loss: 0.0135
Epoch [93/100], Step [541/735], Loss: 0.0144
Epoch [93/100], Step [551/735], Loss: 0.0001
Epoch [93/100], Step [561/735], Loss: 0.0140
Epoch [93/100], Step [571/735], Loss: 0.0004
Epoch [93/100], Step [581/735], Loss: 0.0073
Epoch [93/100], Step [591/735], Loss: 0.0141
Epoch [93/100], Step [601/735], Loss: 0.0040
Epoch [93/100], Step [611/735], Loss: 0.0031
Epoch [93/100], Step [621/735], Loss: 0.0003
Epoch [93/100], Step [631/735], Loss: 0.0183
Epoch [93/100], Step [641/735], Loss: 0.0001
Epoch [93/100], Step [651/735], Loss: 0.0020
Epoch [93/100], Step [661/735], Loss: 0.0071
Epoch [93/100], Step [671/735], Loss: 0.0157
Epoch [93/100], Step [681/735], Loss: 0.0001
Epoch [93/100], Step [691/735], Loss: 0.0005
Epoch [93/100], Step [701/735], Loss: 0.0002
Epoch [93/100], Step [711/735], Loss: 0.0002
Epoch [93/100], Step [721/735], Loss: 0.0001
Epoch [93/100], Step [731/735], Loss: 0.0072
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9167,Val AUC: 0.9539,Val precision: 0.8589, Val recall: 0.8426, Val Loss: 0.0723
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 93 | Time taken: 2252.11s |
| Val CE loss: 0.07234 | Val MSE 0.91670 | Train Loss 0.00700 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 94
Training for epoch 94
Epoch [94/100], Step [1/735], Loss: 0.0238
Epoch [94/100], Step [11/735], Loss: 0.0002
Epoch [94/100], Step [21/735], Loss: 0.0002
Epoch [94/100], Step [31/735], Loss: 0.0081
Epoch [94/100], Step [41/735], Loss: 0.0003
Epoch [94/100], Step [51/735], Loss: 0.0046
Epoch [94/100], Step [61/735], Loss: 0.0000
Epoch [94/100], Step [71/735], Loss: 0.0090
Epoch [94/100], Step [81/735], Loss: 0.0277
Epoch [94/100], Step [91/735], Loss: 0.0001
Epoch [94/100], Step [101/735], Loss: 0.0119
Epoch [94/100], Step [111/735], Loss: 0.0132
Epoch [94/100], Step [121/735], Loss: 0.0007
Epoch [94/100], Step [131/735], Loss: 0.0006
Epoch [94/100], Step [141/735], Loss: 0.0002
Epoch [94/100], Step [151/735], Loss: 0.0001
Epoch [94/100], Step [161/735], Loss: 0.0141
Epoch [94/100], Step [171/735], Loss: 0.0274
Epoch [94/100], Step [181/735], Loss: 0.0002
Epoch [94/100], Step [191/735], Loss: 0.0054
Epoch [94/100], Step [201/735], Loss: 0.0002
Epoch [94/100], Step [211/735], Loss: 0.0017
Epoch [94/100], Step [221/735], Loss: 0.0096
Epoch [94/100], Step [231/735], Loss: 0.0072
Epoch [94/100], Step [241/735], Loss: 0.0025
Epoch [94/100], Step [251/735], Loss: 0.0266
Epoch [94/100], Step [261/735], Loss: 0.0009
Epoch [94/100], Step [271/735], Loss: 0.0040
Epoch [94/100], Step [281/735], Loss: 0.0009
Epoch [94/100], Step [291/735], Loss: 0.0004
Epoch [94/100], Step [301/735], Loss: 0.0071
Epoch [94/100], Step [311/735], Loss: 0.0007
Epoch [94/100], Step [321/735], Loss: 0.0007
Epoch [94/100], Step [331/735], Loss: 0.0027
Epoch [94/100], Step [341/735], Loss: 0.0003
Epoch [94/100], Step [351/735], Loss: 0.0039
Epoch [94/100], Step [361/735], Loss: 0.0006
Epoch [94/100], Step [371/735], Loss: 0.0010
Epoch [94/100], Step [381/735], Loss: 0.0009
Epoch [94/100], Step [391/735], Loss: 0.0119
Epoch [94/100], Step [401/735], Loss: 0.0008
Epoch [94/100], Step [411/735], Loss: 0.0001
Epoch [94/100], Step [421/735], Loss: 0.0037
Epoch [94/100], Step [431/735], Loss: 0.0167
Epoch [94/100], Step [441/735], Loss: 0.0000
Epoch [94/100], Step [451/735], Loss: 0.0000
Epoch [94/100], Step [461/735], Loss: 0.0004
Epoch [94/100], Step [471/735], Loss: 0.0014
Epoch [94/100], Step [481/735], Loss: 0.0003
Epoch [94/100], Step [491/735], Loss: 0.0036
Epoch [94/100], Step [501/735], Loss: 0.0031
Epoch [94/100], Step [511/735], Loss: 0.0144
Epoch [94/100], Step [521/735], Loss: 0.0018
Epoch [94/100], Step [531/735], Loss: 0.0139
Epoch [94/100], Step [541/735], Loss: 0.0136
Epoch [94/100], Step [551/735], Loss: 0.0125
Epoch [94/100], Step [561/735], Loss: 0.0194
Epoch [94/100], Step [571/735], Loss: 0.0001
Epoch [94/100], Step [581/735], Loss: 0.0111
Epoch [94/100], Step [591/735], Loss: 0.0279
Epoch [94/100], Step [601/735], Loss: 0.0138
Epoch [94/100], Step [611/735], Loss: 0.0000
Epoch [94/100], Step [621/735], Loss: 0.0138
Epoch [94/100], Step [631/735], Loss: 0.0001
Epoch [94/100], Step [641/735], Loss: 0.0000
Epoch [94/100], Step [651/735], Loss: 0.0001
Epoch [94/100], Step [661/735], Loss: 0.0140
Epoch [94/100], Step [671/735], Loss: 0.0098
Epoch [94/100], Step [681/735], Loss: 0.0001
Epoch [94/100], Step [691/735], Loss: 0.0163
Epoch [94/100], Step [701/735], Loss: 0.0061
Epoch [94/100], Step [711/735], Loss: 0.0010
Epoch [94/100], Step [721/735], Loss: 0.0002
Epoch [94/100], Step [731/735], Loss: 0.0153
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9186,Val AUC: 0.9582,Val precision: 0.8420, Val recall: 0.8752, Val Loss: 0.0717
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 94 | Time taken: 2212.73s |
| Val CE loss: 0.07171 | Val MSE 0.91860 | Train Loss 0.00690 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 95
Training for epoch 95
Epoch [95/100], Step [1/735], Loss: 0.0021
Epoch [95/100], Step [11/735], Loss: 0.0139
Epoch [95/100], Step [21/735], Loss: 0.0021
Epoch [95/100], Step [31/735], Loss: 0.0137
Epoch [95/100], Step [41/735], Loss: 0.0204
Epoch [95/100], Step [51/735], Loss: 0.0012
Epoch [95/100], Step [61/735], Loss: 0.0012
Epoch [95/100], Step [71/735], Loss: 0.0004
Epoch [95/100], Step [81/735], Loss: 0.0017
Epoch [95/100], Step [91/735], Loss: 0.0032
Epoch [95/100], Step [101/735], Loss: 0.0002
Epoch [95/100], Step [111/735], Loss: 0.0002
Epoch [95/100], Step [121/735], Loss: 0.0001
Epoch [95/100], Step [131/735], Loss: 0.0205
Epoch [95/100], Step [141/735], Loss: 0.0006
Epoch [95/100], Step [151/735], Loss: 0.0014
Epoch [95/100], Step [161/735], Loss: 0.0049
Epoch [95/100], Step [171/735], Loss: 0.0000
Epoch [95/100], Step [181/735], Loss: 0.0005
Epoch [95/100], Step [191/735], Loss: 0.0066
Epoch [95/100], Step [201/735], Loss: 0.0124
Epoch [95/100], Step [211/735], Loss: 0.0000
Epoch [95/100], Step [221/735], Loss: 0.0184
Epoch [95/100], Step [231/735], Loss: 0.0009
Epoch [95/100], Step [241/735], Loss: 0.0000
Epoch [95/100], Step [251/735], Loss: 0.0023
Epoch [95/100], Step [261/735], Loss: 0.0145
Epoch [95/100], Step [271/735], Loss: 0.0104
Epoch [95/100], Step [281/735], Loss: 0.0013
Epoch [95/100], Step [291/735], Loss: 0.0001
Epoch [95/100], Step [301/735], Loss: 0.0001
Epoch [95/100], Step [311/735], Loss: 0.0000
Epoch [95/100], Step [321/735], Loss: 0.0000
Epoch [95/100], Step [331/735], Loss: 0.0000
Epoch [95/100], Step [341/735], Loss: 0.0000
Epoch [95/100], Step [351/735], Loss: 0.0000
Epoch [95/100], Step [361/735], Loss: 0.0121
Epoch [95/100], Step [371/735], Loss: 0.0000
Epoch [95/100], Step [381/735], Loss: 0.0001
Epoch [95/100], Step [391/735], Loss: 0.0411
Epoch [95/100], Step [401/735], Loss: 0.0000
Epoch [95/100], Step [411/735], Loss: 0.0002
Epoch [95/100], Step [421/735], Loss: 0.0000
Epoch [95/100], Step [431/735], Loss: 0.0001
Epoch [95/100], Step [441/735], Loss: 0.0031
Epoch [95/100], Step [451/735], Loss: 0.0160
Epoch [95/100], Step [461/735], Loss: 0.0404
Epoch [95/100], Step [471/735], Loss: 0.0146
Epoch [95/100], Step [481/735], Loss: 0.0030
Epoch [95/100], Step [491/735], Loss: 0.0108
Epoch [95/100], Step [501/735], Loss: 0.0163
Epoch [95/100], Step [511/735], Loss: 0.0029
Epoch [95/100], Step [521/735], Loss: 0.0215
Epoch [95/100], Step [531/735], Loss: 0.0151
Epoch [95/100], Step [541/735], Loss: 0.0131
Epoch [95/100], Step [551/735], Loss: 0.0076
Epoch [95/100], Step [561/735], Loss: 0.0141
Epoch [95/100], Step [571/735], Loss: 0.0040
Epoch [95/100], Step [581/735], Loss: 0.0002
Epoch [95/100], Step [591/735], Loss: 0.0042
Epoch [95/100], Step [601/735], Loss: 0.0001
Epoch [95/100], Step [611/735], Loss: 0.0018
Epoch [95/100], Step [621/735], Loss: 0.0024
Epoch [95/100], Step [631/735], Loss: 0.0001
Epoch [95/100], Step [641/735], Loss: 0.0110
Epoch [95/100], Step [651/735], Loss: 0.0153
Epoch [95/100], Step [661/735], Loss: 0.0001
Epoch [95/100], Step [671/735], Loss: 0.0266
Epoch [95/100], Step [681/735], Loss: 0.0190
Epoch [95/100], Step [691/735], Loss: 0.0002
Epoch [95/100], Step [701/735], Loss: 0.0014
Epoch [95/100], Step [711/735], Loss: 0.0002
Epoch [95/100], Step [721/735], Loss: 0.0135
Epoch [95/100], Step [731/735], Loss: 0.0003
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9234,Val AUC: 0.9574,Val precision: 0.8677, Val recall: 0.8592, Val Loss: 0.0680
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 95 | Time taken: 2211.60s |
| Val CE loss: 0.06797 | Val MSE 0.92345 | Train Loss 0.00751 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 96
Training for epoch 96
Epoch [96/100], Step [1/735], Loss: 0.0018
Epoch [96/100], Step [11/735], Loss: 0.0055
Epoch [96/100], Step [21/735], Loss: 0.0001
Epoch [96/100], Step [31/735], Loss: 0.0000
Epoch [96/100], Step [41/735], Loss: 0.0000
Epoch [96/100], Step [51/735], Loss: 0.0015
Epoch [96/100], Step [61/735], Loss: 0.0001
Epoch [96/100], Step [71/735], Loss: 0.0002
Epoch [96/100], Step [81/735], Loss: 0.0005
Epoch [96/100], Step [91/735], Loss: 0.0169
Epoch [96/100], Step [101/735], Loss: 0.0001
Epoch [96/100], Step [111/735], Loss: 0.0001
Epoch [96/100], Step [121/735], Loss: 0.0004
Epoch [96/100], Step [131/735], Loss: 0.0135
Epoch [96/100], Step [141/735], Loss: 0.0006
Epoch [96/100], Step [151/735], Loss: 0.0280
Epoch [96/100], Step [161/735], Loss: 0.0004
Epoch [96/100], Step [171/735], Loss: 0.0090
Epoch [96/100], Step [181/735], Loss: 0.0002
Epoch [96/100], Step [191/735], Loss: 0.0008
Epoch [96/100], Step [201/735], Loss: 0.0062
Epoch [96/100], Step [211/735], Loss: 0.0043
Epoch [96/100], Step [221/735], Loss: 0.0029
Epoch [96/100], Step [231/735], Loss: 0.0114
Epoch [96/100], Step [241/735], Loss: 0.0111
Epoch [96/100], Step [251/735], Loss: 0.0000
Epoch [96/100], Step [261/735], Loss: 0.0064
Epoch [96/100], Step [271/735], Loss: 0.0001
Epoch [96/100], Step [281/735], Loss: 0.0000
Epoch [96/100], Step [291/735], Loss: 0.0328
Epoch [96/100], Step [301/735], Loss: 0.0001
Epoch [96/100], Step [311/735], Loss: 0.0001
Epoch [96/100], Step [321/735], Loss: 0.0107
Epoch [96/100], Step [331/735], Loss: 0.0001
Epoch [96/100], Step [341/735], Loss: 0.0038
Epoch [96/100], Step [351/735], Loss: 0.0002
Epoch [96/100], Step [361/735], Loss: 0.0016
Epoch [96/100], Step [371/735], Loss: 0.0000
Epoch [96/100], Step [381/735], Loss: 0.0001
Epoch [96/100], Step [391/735], Loss: 0.0009
Epoch [96/100], Step [401/735], Loss: 0.0051
Epoch [96/100], Step [411/735], Loss: 0.0006
Epoch [96/100], Step [421/735], Loss: 0.0003
Epoch [96/100], Step [431/735], Loss: 0.0002
Epoch [96/100], Step [441/735], Loss: 0.0000
Epoch [96/100], Step [451/735], Loss: 0.0050
Epoch [96/100], Step [461/735], Loss: 0.0167
Epoch [96/100], Step [471/735], Loss: 0.0255
Epoch [96/100], Step [481/735], Loss: 0.0007
Epoch [96/100], Step [491/735], Loss: 0.0005
Epoch [96/100], Step [501/735], Loss: 0.0191
Epoch [96/100], Step [511/735], Loss: 0.0078
Epoch [96/100], Step [521/735], Loss: 0.0002
Epoch [96/100], Step [531/735], Loss: 0.0002
Epoch [96/100], Step [541/735], Loss: 0.0003
Epoch [96/100], Step [551/735], Loss: 0.0144
Epoch [96/100], Step [561/735], Loss: 0.0268
Epoch [96/100], Step [571/735], Loss: 0.0141
Epoch [96/100], Step [581/735], Loss: 0.0000
Epoch [96/100], Step [591/735], Loss: 0.0100
Epoch [96/100], Step [601/735], Loss: 0.0095
Epoch [96/100], Step [611/735], Loss: 0.0001
Epoch [96/100], Step [621/735], Loss: 0.0033
Epoch [96/100], Step [631/735], Loss: 0.0014
Epoch [96/100], Step [641/735], Loss: 0.0017
Epoch [96/100], Step [651/735], Loss: 0.0001
Epoch [96/100], Step [661/735], Loss: 0.0044
Epoch [96/100], Step [671/735], Loss: 0.0207
Epoch [96/100], Step [681/735], Loss: 0.0001
Epoch [96/100], Step [691/735], Loss: 0.0126
Epoch [96/100], Step [701/735], Loss: 0.0011
Epoch [96/100], Step [711/735], Loss: 0.0003
Epoch [96/100], Step [721/735], Loss: 0.0001
Epoch [96/100], Step [731/735], Loss: 0.0130
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9238,Val AUC: 0.9600,Val precision: 0.8577, Val recall: 0.8745, Val Loss: 0.0673
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 96 | Time taken: 2232.16s |
| Val CE loss: 0.06734 | Val MSE 0.92380 | Train Loss 0.00630 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 97
Training for epoch 97
Epoch [97/100], Step [1/735], Loss: 0.0005
Epoch [97/100], Step [11/735], Loss: 0.0180
Epoch [97/100], Step [21/735], Loss: 0.0000
Epoch [97/100], Step [31/735], Loss: 0.0001
Epoch [97/100], Step [41/735], Loss: 0.0022
Epoch [97/100], Step [51/735], Loss: 0.0002
Epoch [97/100], Step [61/735], Loss: 0.0001
Epoch [97/100], Step [71/735], Loss: 0.0002
Epoch [97/100], Step [81/735], Loss: 0.0026
Epoch [97/100], Step [91/735], Loss: 0.0035
Epoch [97/100], Step [101/735], Loss: 0.0001
Epoch [97/100], Step [111/735], Loss: 0.0069
Epoch [97/100], Step [121/735], Loss: 0.0079
Epoch [97/100], Step [131/735], Loss: 0.0137
Epoch [97/100], Step [141/735], Loss: 0.0000
Epoch [97/100], Step [151/735], Loss: 0.0106
Epoch [97/100], Step [161/735], Loss: 0.0001
Epoch [97/100], Step [171/735], Loss: 0.0259
Epoch [97/100], Step [181/735], Loss: 0.0038
Epoch [97/100], Step [191/735], Loss: 0.0000
Epoch [97/100], Step [201/735], Loss: 0.0138
Epoch [97/100], Step [211/735], Loss: 0.0366
Epoch [97/100], Step [221/735], Loss: 0.0036
Epoch [97/100], Step [231/735], Loss: 0.0104
Epoch [97/100], Step [241/735], Loss: 0.0189
Epoch [97/100], Step [251/735], Loss: 0.0001
Epoch [97/100], Step [261/735], Loss: 0.0001
Epoch [97/100], Step [271/735], Loss: 0.0139
Epoch [97/100], Step [281/735], Loss: 0.0209
Epoch [97/100], Step [291/735], Loss: 0.0001
Epoch [97/100], Step [301/735], Loss: 0.0000
Epoch [97/100], Step [311/735], Loss: 0.0001
Epoch [97/100], Step [321/735], Loss: 0.0163
Epoch [97/100], Step [331/735], Loss: 0.0131
Epoch [97/100], Step [341/735], Loss: 0.0001
Epoch [97/100], Step [351/735], Loss: 0.0001
Epoch [97/100], Step [361/735], Loss: 0.0008
Epoch [97/100], Step [371/735], Loss: 0.0005
Epoch [97/100], Step [381/735], Loss: 0.0012
Epoch [97/100], Step [391/735], Loss: 0.0258
Epoch [97/100], Step [401/735], Loss: 0.0004
Epoch [97/100], Step [411/735], Loss: 0.0000
Epoch [97/100], Step [421/735], Loss: 0.0109
Epoch [97/100], Step [431/735], Loss: 0.0173
Epoch [97/100], Step [441/735], Loss: 0.0140
Epoch [97/100], Step [451/735], Loss: 0.0023
Epoch [97/100], Step [461/735], Loss: 0.0282
Epoch [97/100], Step [471/735], Loss: 0.0103
Epoch [97/100], Step [481/735], Loss: 0.0001
Epoch [97/100], Step [491/735], Loss: 0.0139
Epoch [97/100], Step [501/735], Loss: 0.0070
Epoch [97/100], Step [511/735], Loss: 0.0076
Epoch [97/100], Step [521/735], Loss: 0.0098
Epoch [97/100], Step [531/735], Loss: 0.0021
Epoch [97/100], Step [541/735], Loss: 0.0004
Epoch [97/100], Step [551/735], Loss: 0.0001
Epoch [97/100], Step [561/735], Loss: 0.0004
Epoch [97/100], Step [571/735], Loss: 0.0087
Epoch [97/100], Step [581/735], Loss: 0.0114
Epoch [97/100], Step [591/735], Loss: 0.0001
Epoch [97/100], Step [601/735], Loss: 0.0003
Epoch [97/100], Step [611/735], Loss: 0.0004
Epoch [97/100], Step [621/735], Loss: 0.0000
Epoch [97/100], Step [631/735], Loss: 0.0002
Epoch [97/100], Step [641/735], Loss: 0.0004
Epoch [97/100], Step [651/735], Loss: 0.0049
Epoch [97/100], Step [661/735], Loss: 0.0053
Epoch [97/100], Step [671/735], Loss: 0.0000
Epoch [97/100], Step [681/735], Loss: 0.0000
Epoch [97/100], Step [691/735], Loss: 0.0001
Epoch [97/100], Step [701/735], Loss: 0.0000
Epoch [97/100], Step [711/735], Loss: 0.0000
Epoch [97/100], Step [721/735], Loss: 0.0015
Epoch [97/100], Step [731/735], Loss: 0.0148
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9286,Val AUC: 0.9568,Val precision: 0.8803, Val recall: 0.8641, Val Loss: 0.0646
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 97 | Time taken: 2237.69s |
| Val CE loss: 0.06459 | Val MSE 0.92865 | Train Loss 0.00672 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 98
Training for epoch 98
Epoch [98/100], Step [1/735], Loss: 0.0108
Epoch [98/100], Step [11/735], Loss: 0.0123
Epoch [98/100], Step [21/735], Loss: 0.0000
Epoch [98/100], Step [31/735], Loss: 0.0224
Epoch [98/100], Step [41/735], Loss: 0.0000
Epoch [98/100], Step [51/735], Loss: 0.0001
Epoch [98/100], Step [61/735], Loss: 0.0063
Epoch [98/100], Step [71/735], Loss: 0.0029
Epoch [98/100], Step [81/735], Loss: 0.0138
Epoch [98/100], Step [91/735], Loss: 0.0078
Epoch [98/100], Step [101/735], Loss: 0.0146
Epoch [98/100], Step [111/735], Loss: 0.0140
Epoch [98/100], Step [121/735], Loss: 0.0232
Epoch [98/100], Step [131/735], Loss: 0.0160
Epoch [98/100], Step [141/735], Loss: 0.0011
Epoch [98/100], Step [151/735], Loss: 0.0000
Epoch [98/100], Step [161/735], Loss: 0.0003
Epoch [98/100], Step [171/735], Loss: 0.0006
Epoch [98/100], Step [181/735], Loss: 0.0001
Epoch [98/100], Step [191/735], Loss: 0.0001
Epoch [98/100], Step [201/735], Loss: 0.0003
Epoch [98/100], Step [211/735], Loss: 0.0207
Epoch [98/100], Step [221/735], Loss: 0.0057
Epoch [98/100], Step [231/735], Loss: 0.0251
Epoch [98/100], Step [241/735], Loss: 0.0002
Epoch [98/100], Step [251/735], Loss: 0.0106
Epoch [98/100], Step [261/735], Loss: 0.0144
Epoch [98/100], Step [271/735], Loss: 0.0026
Epoch [98/100], Step [281/735], Loss: 0.0004
Epoch [98/100], Step [291/735], Loss: 0.0116
Epoch [98/100], Step [301/735], Loss: 0.0203
Epoch [98/100], Step [311/735], Loss: 0.0001
Epoch [98/100], Step [321/735], Loss: 0.0025
Epoch [98/100], Step [331/735], Loss: 0.0156
Epoch [98/100], Step [341/735], Loss: 0.0001
Epoch [98/100], Step [351/735], Loss: 0.0001
Epoch [98/100], Step [361/735], Loss: 0.0316
Epoch [98/100], Step [371/735], Loss: 0.0182
Epoch [98/100], Step [381/735], Loss: 0.0139
Epoch [98/100], Step [391/735], Loss: 0.0000
Epoch [98/100], Step [401/735], Loss: 0.0001
Epoch [98/100], Step [411/735], Loss: 0.0055
Epoch [98/100], Step [421/735], Loss: 0.0002
Epoch [98/100], Step [431/735], Loss: 0.0000
Epoch [98/100], Step [441/735], Loss: 0.0020
Epoch [98/100], Step [451/735], Loss: 0.0019
Epoch [98/100], Step [461/735], Loss: 0.0001
Epoch [98/100], Step [471/735], Loss: 0.0139
Epoch [98/100], Step [481/735], Loss: 0.0037
Epoch [98/100], Step [491/735], Loss: 0.0009
Epoch [98/100], Step [501/735], Loss: 0.0032
Epoch [98/100], Step [511/735], Loss: 0.0086
Epoch [98/100], Step [521/735], Loss: 0.0000
Epoch [98/100], Step [531/735], Loss: 0.0147
Epoch [98/100], Step [541/735], Loss: 0.0110
Epoch [98/100], Step [551/735], Loss: 0.0147
Epoch [98/100], Step [561/735], Loss: 0.0140
Epoch [98/100], Step [571/735], Loss: 0.0003
Epoch [98/100], Step [581/735], Loss: 0.0066
Epoch [98/100], Step [591/735], Loss: 0.0000
Epoch [98/100], Step [601/735], Loss: 0.0000
Epoch [98/100], Step [611/735], Loss: 0.0002
Epoch [98/100], Step [621/735], Loss: 0.0278
Epoch [98/100], Step [631/735], Loss: 0.0001
Epoch [98/100], Step [641/735], Loss: 0.0006
Epoch [98/100], Step [651/735], Loss: 0.0141
Epoch [98/100], Step [661/735], Loss: 0.0323
Epoch [98/100], Step [671/735], Loss: 0.0012
Epoch [98/100], Step [681/735], Loss: 0.0001
Epoch [98/100], Step [691/735], Loss: 0.0057
Epoch [98/100], Step [701/735], Loss: 0.0047
Epoch [98/100], Step [711/735], Loss: 0.0003
Epoch [98/100], Step [721/735], Loss: 0.0000
Epoch [98/100], Step [731/735], Loss: 0.0132
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9228,Val AUC: 0.9585,Val precision: 0.8620, Val recall: 0.8641, Val Loss: 0.0678
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 98 | Time taken: 2257.57s |
| Val CE loss: 0.06783 | Val MSE 0.92276 | Train Loss 0.00687 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 99
Training for epoch 99
Epoch [99/100], Step [1/735], Loss: 0.0002
Epoch [99/100], Step [11/735], Loss: 0.0001
Epoch [99/100], Step [21/735], Loss: 0.0191
Epoch [99/100], Step [31/735], Loss: 0.0137
Epoch [99/100], Step [41/735], Loss: 0.0005
Epoch [99/100], Step [51/735], Loss: 0.0092
Epoch [99/100], Step [61/735], Loss: 0.0000
Epoch [99/100], Step [71/735], Loss: 0.0133
Epoch [99/100], Step [81/735], Loss: 0.0015
Epoch [99/100], Step [91/735], Loss: 0.0002
Epoch [99/100], Step [101/735], Loss: 0.0126
Epoch [99/100], Step [111/735], Loss: 0.0033
Epoch [99/100], Step [121/735], Loss: 0.0004
Epoch [99/100], Step [131/735], Loss: 0.0032
Epoch [99/100], Step [141/735], Loss: 0.0082
Epoch [99/100], Step [151/735], Loss: 0.0176
Epoch [99/100], Step [161/735], Loss: 0.0099
Epoch [99/100], Step [171/735], Loss: 0.0026
Epoch [99/100], Step [181/735], Loss: 0.0001
Epoch [99/100], Step [191/735], Loss: 0.0016
Epoch [99/100], Step [201/735], Loss: 0.0003
Epoch [99/100], Step [211/735], Loss: 0.0008
Epoch [99/100], Step [221/735], Loss: 0.0154
Epoch [99/100], Step [231/735], Loss: 0.0018
Epoch [99/100], Step [241/735], Loss: 0.0002
Epoch [99/100], Step [251/735], Loss: 0.0001
Epoch [99/100], Step [261/735], Loss: 0.0049
Epoch [99/100], Step [271/735], Loss: 0.0285
Epoch [99/100], Step [281/735], Loss: 0.0008
Epoch [99/100], Step [291/735], Loss: 0.0033
Epoch [99/100], Step [301/735], Loss: 0.0001
Epoch [99/100], Step [311/735], Loss: 0.0006
Epoch [99/100], Step [321/735], Loss: 0.0000
Epoch [99/100], Step [331/735], Loss: 0.0004
Epoch [99/100], Step [341/735], Loss: 0.0072
Epoch [99/100], Step [351/735], Loss: 0.0058
Epoch [99/100], Step [361/735], Loss: 0.0002
Epoch [99/100], Step [371/735], Loss: 0.0251
Epoch [99/100], Step [381/735], Loss: 0.0056
Epoch [99/100], Step [391/735], Loss: 0.0137
Epoch [99/100], Step [401/735], Loss: 0.0000
Epoch [99/100], Step [411/735], Loss: 0.0010
Epoch [99/100], Step [421/735], Loss: 0.0029
Epoch [99/100], Step [431/735], Loss: 0.0001
Epoch [99/100], Step [441/735], Loss: 0.0005
Epoch [99/100], Step [451/735], Loss: 0.0133
Epoch [99/100], Step [461/735], Loss: 0.0139
Epoch [99/100], Step [471/735], Loss: 0.0177
Epoch [99/100], Step [481/735], Loss: 0.0276
Epoch [99/100], Step [491/735], Loss: 0.0001
Epoch [99/100], Step [501/735], Loss: 0.0001
Epoch [99/100], Step [511/735], Loss: 0.0002
Epoch [99/100], Step [521/735], Loss: 0.0000
Epoch [99/100], Step [531/735], Loss: 0.0000
Epoch [99/100], Step [541/735], Loss: 0.0004
Epoch [99/100], Step [551/735], Loss: 0.0072
Epoch [99/100], Step [561/735], Loss: 0.0059
Epoch [99/100], Step [571/735], Loss: 0.0001
Epoch [99/100], Step [581/735], Loss: 0.0001
Epoch [99/100], Step [591/735], Loss: 0.0001
Epoch [99/100], Step [601/735], Loss: 0.0000
Epoch [99/100], Step [611/735], Loss: 0.0001
Epoch [99/100], Step [621/735], Loss: 0.0000
Epoch [99/100], Step [631/735], Loss: 0.0200
Epoch [99/100], Step [641/735], Loss: 0.0032
Epoch [99/100], Step [651/735], Loss: 0.0118
Epoch [99/100], Step [661/735], Loss: 0.0004
Epoch [99/100], Step [671/735], Loss: 0.0138
Epoch [99/100], Step [681/735], Loss: 0.0001
Epoch [99/100], Step [691/735], Loss: 0.0145
Epoch [99/100], Step [701/735], Loss: 0.0000
Epoch [99/100], Step [711/735], Loss: 0.0141
Epoch [99/100], Step [721/735], Loss: 0.0014
Epoch [99/100], Step [731/735], Loss: 0.0001
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9274,Val AUC: 0.9600,Val precision: 0.8714, Val recall: 0.8708, Val Loss: 0.0653
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 99 | Time taken: 2242.27s |
| Val CE loss: 0.06527 | Val MSE 0.92743 | Train Loss 0.00653 |
--------------------------------------------------------------------------------
Loading dataset to cuda:0
Loading dataloader
Training started for epoch: 100
Training for epoch 100
Epoch [100/100], Step [1/735], Loss: 0.0013
Epoch [100/100], Step [11/735], Loss: 0.0118
Epoch [100/100], Step [21/735], Loss: 0.0000
Epoch [100/100], Step [31/735], Loss: 0.0113
Epoch [100/100], Step [41/735], Loss: 0.0037
Epoch [100/100], Step [51/735], Loss: 0.0000
Epoch [100/100], Step [61/735], Loss: 0.0130
Epoch [100/100], Step [71/735], Loss: 0.0000
Epoch [100/100], Step [81/735], Loss: 0.0103
Epoch [100/100], Step [91/735], Loss: 0.0000
Epoch [100/100], Step [101/735], Loss: 0.0001
Epoch [100/100], Step [111/735], Loss: 0.0172
Epoch [100/100], Step [121/735], Loss: 0.0002
Epoch [100/100], Step [131/735], Loss: 0.0001
Epoch [100/100], Step [141/735], Loss: 0.0011
Epoch [100/100], Step [151/735], Loss: 0.0053
Epoch [100/100], Step [161/735], Loss: 0.0038
Epoch [100/100], Step [171/735], Loss: 0.0236
Epoch [100/100], Step [181/735], Loss: 0.0000
Epoch [100/100], Step [191/735], Loss: 0.0125
Epoch [100/100], Step [201/735], Loss: 0.0136
Epoch [100/100], Step [211/735], Loss: 0.0213
Epoch [100/100], Step [221/735], Loss: 0.0047
Epoch [100/100], Step [231/735], Loss: 0.0037
Epoch [100/100], Step [241/735], Loss: 0.0001
Epoch [100/100], Step [251/735], Loss: 0.0000
Epoch [100/100], Step [261/735], Loss: 0.0017
Epoch [100/100], Step [271/735], Loss: 0.0014
Epoch [100/100], Step [281/735], Loss: 0.0183
Epoch [100/100], Step [291/735], Loss: 0.0003
Epoch [100/100], Step [301/735], Loss: 0.0137
Epoch [100/100], Step [311/735], Loss: 0.0000
Epoch [100/100], Step [321/735], Loss: 0.0096
Epoch [100/100], Step [331/735], Loss: 0.0000
Epoch [100/100], Step [341/735], Loss: 0.0001
Epoch [100/100], Step [351/735], Loss: 0.0034
Epoch [100/100], Step [361/735], Loss: 0.0140
Epoch [100/100], Step [371/735], Loss: 0.0001
Epoch [100/100], Step [381/735], Loss: 0.0145
Epoch [100/100], Step [391/735], Loss: 0.0118
Epoch [100/100], Step [401/735], Loss: 0.0032
Epoch [100/100], Step [411/735], Loss: 0.0022
Epoch [100/100], Step [421/735], Loss: 0.0013
Epoch [100/100], Step [431/735], Loss: 0.0000
Epoch [100/100], Step [441/735], Loss: 0.0005
Epoch [100/100], Step [451/735], Loss: 0.0002
Epoch [100/100], Step [461/735], Loss: 0.0004
Epoch [100/100], Step [471/735], Loss: 0.0008
Epoch [100/100], Step [481/735], Loss: 0.0072
Epoch [100/100], Step [491/735], Loss: 0.0000
Epoch [100/100], Step [501/735], Loss: 0.0001
Epoch [100/100], Step [511/735], Loss: 0.0037
Epoch [100/100], Step [521/735], Loss: 0.0247
Epoch [100/100], Step [531/735], Loss: 0.0016
Epoch [100/100], Step [541/735], Loss: 0.0032
Epoch [100/100], Step [551/735], Loss: 0.0000
Epoch [100/100], Step [561/735], Loss: 0.0068
Epoch [100/100], Step [571/735], Loss: 0.0135
Epoch [100/100], Step [581/735], Loss: 0.0011
Epoch [100/100], Step [591/735], Loss: 0.0075
Epoch [100/100], Step [601/735], Loss: 0.0003
Epoch [100/100], Step [611/735], Loss: 0.0001
Epoch [100/100], Step [621/735], Loss: 0.0000
Epoch [100/100], Step [631/735], Loss: 0.0001
Epoch [100/100], Step [641/735], Loss: 0.0002
Epoch [100/100], Step [651/735], Loss: 0.0003
Epoch [100/100], Step [661/735], Loss: 0.0077
Epoch [100/100], Step [671/735], Loss: 0.0025
Epoch [100/100], Step [681/735], Loss: 0.0000
Epoch [100/100], Step [691/735], Loss: 0.0047
Epoch [100/100], Step [701/735], Loss: 0.0142
Epoch [100/100], Step [711/735], Loss: 0.0004
Epoch [100/100], Step [721/735], Loss: 0.0002
Epoch [100/100], Step [731/735], Loss: 0.0000
Training complete
Val performance:
Evaluating
Val Accuracy: 0.9229,Val AUC: 0.9597,Val precision: 0.8647, Val recall: 0.8610, Val Loss: 0.0677
Evaluation complete
--------------------------------------------------------------------------------
| Device id: 0 | End of epoch: 100 | Time taken: 2243.07s |
| Val CE loss: 0.06773 | Val MSE 0.92293 | Train Loss 0.00629 |
--------------------------------------------------------------------------------
